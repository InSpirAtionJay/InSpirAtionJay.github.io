<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[OpenCV Descriptor SIFT]]></title>
    <url>%2F2019%2F07%2F18%2FOpenCV-Descriptor-SIFT%2F</url>
    <content type="text"><![CDATA[1. SIFT 简介$\quad$SIFT的全称是Scale Invariant Feature Transform，尺度不变特征变换，由加拿大教授David G.Lowe提出的。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。 1.1 SIFT算法具有的特点 图像的局部特征，对旋转、尺度缩放、亮度变化保持不变，对视角变化、仿射变换、噪声也保持一定程度的稳定性。 独特性好，信息量丰富，适用于海量特征库进行快速、准确的匹配。 多量性，即使是很少几个物体也可以产生大量的SIFT特征。 高速性，经优化的SIFT匹配算法甚至可以达到实时性。 扩招性，可以很方便的与其他的特征向量进行联合。 1.2 SIFT特征检测的步骤 尺度空间的极值检测 搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和旋转不变的兴趣点。 特征点定位 在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。 特征方向赋值 基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。 特征点描述 在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。 1.3 SIFT算法中的一些符号说明$I(x,y)$表示原图像。$G(x,y,\sigma)$表示高斯滤波器，其中$G(x, y, \sigma)=\frac{1}{2 \pi \sigma^{2}} \exp \left(-\left(x^{2}+y^{2}\right) / 2 \sigma^{2}\right)$。$L(x,y,\sigma)$表示由一个高斯滤波器与原图像卷积而生成的图像，即$L(x, y, \sigma)=G(x, y, \sigma) \otimes I(x, y)$。一系列的$\sigma_{i}$，则可以生成一系列的$L(x,y,\sigma)$图像，此时我们把这一系列的$L(x,y,\sigma)$图像称为原图像的一个尺度空间表示。$DOG$表示高斯差分（Difference of Gaussians)，尺度为$\sigma$的高斯差分图像由尺度为$k\sigma$与尺度为$\sigma$的$L$图像生成的，$k$为两相邻尺度空间倍数的常数。$D(x, y, \sigma)=(G(x, y, k \sigma)-G(x, y, \sigma)) \otimes I(x, y)=L(x, y, k \sigma)-L(x, y, \sigma)$。$O$：高斯金字塔的组数（Octave），其中值得注意的是，在实际构建中，第一组的索引可以为0也可以为-1，这个在后面解释原理。$S$：高斯金字塔每一组的层数。在实际最开始构建尺度空间图像，即$L$图像的时候，构建了$S+3$层，一定要把这个$S+3$与$S$区分开，为什么是$S+3$后面分析。 2. 构建高斯差分金字塔$\quad$在一定的范围内，无论物体是大还是小，人眼都可以分辨出来。然而计算机要有相同的能力却不是那么的容易，在未知的场景中，计算机视觉并不能提供物体的尺度大小，其中的一种方法是把物体不同尺度下的图像都提供给机器，让机器能够对物体在不同的尺度下有一个统一的认知。在建立统一认知的过程中，要考虑的就是在图像在不同的尺度下都存在的特征点。 2.1 多分辨率图像金字塔$\quad$在早期图像的多尺度通常使用图像金字塔表示形式。$\quad$图像金字塔是同一图像在不同的分辨率下得到的一组结果，其生成过程一般包括两个步骤： 对原始图像进行平滑. 对处理后的图像进行降采样（通常是水平、垂直方向的1/2.降采样后得到一系列不断尺寸缩小的图像。显然，一个传统的金字塔中，每一层的图像是其上一层图像长、高的各一半。多分辨率的图像金字塔虽然生成简单，但其本质是降采样，图像的局部特征则难以保持，也就是无法保持特征的尺度不变性。 2.2 高斯尺度空间$\quad$我们还可以通过图像的模糊程度来模拟人在距离物体由远到近时物体在视网膜上成像过程，距离物体越近其尺寸越大图像也越模糊，这就是高斯尺度空间，使用不同的参数模糊图像（分辨率不变），是尺度空间的另一种表现形式。$\quad$我们知道图像和高斯函数进行卷积运算能够对图像进行模糊，使用不同的“高斯核”可得到不同模糊程度的图像。一副图像其高斯尺度空间可由其和不同的高斯卷积得到： L(x, y, \sigma)=G(x, y, \sigma) \otimes I(x, y)$\quad$其中，$G(x,y,\sigma)$是高斯核函数。 G(x, y, \sigma)=\frac{1}{2 \pi \sigma^{2}} e^{\frac{x^{2}+y^{2}}{2 \sigma^{2}}}$\quad$$\sigma$称为尺度空间因子，它是高斯正态分布的标准差，反映了图像被模糊的程度，其值越大图像越模糊，对应的尺度也就越大。$L(x,y,\sigma)$代表着图像的高斯尺度空间。构建尺度空间的目的是为了检测出在不同的尺度下都存在的特征点，而检测特征点较好的算子是Δ2G(高斯拉普拉斯,LoG） \Delta^{2}=\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}$\quad$使用LoG虽然能较好的检测到图像中的特征点，但是其运算量过大，通常可使用DoG（差分高斯，Difference of Gaussina）来近似计算LoG[Marr and Hidreth]。设k为相邻两个高斯尺度空间的比例因子，则DoG的定义为： \begin{aligned} D(x, y, \sigma) &=[G(x, y, k \sigma)-G(x, y, \sigma)] * I(x, y) \\ &=L(x, y, k \sigma)-L(x, y, \sigma) \end{aligned}$\quad$从上式可以知道，将相邻的两个高斯空间的图像相减就得到了DoG的响应图像。为了得到DoG图像，先要构建高斯尺度空间，而高斯的尺度空间可以在图像金字塔降采样的基础上加上高斯滤波得到，也就是对图像金字塔的每层图像使用不同的参数σ进行高斯模糊，使每层金字塔有多张高斯模糊过的图像。降采样时，金字塔上边一组图像的第一张是由其下面一组图像倒数第三张降采样得到。$\quad$易知，高斯金字塔有多组，每组又有多层。一组中的多个层之间的尺度是不一样的（也就是使用的高斯参数$\sigma$是不同的），相邻两层之间的尺度相差一个比例因子$k$。如果每组有$S$层，则： k=2^{\frac{1}{s}}$\quad$上一组图像的最底层图像是由下一组中尺度为2σ的图像进行因子为2的降采样得到的（高斯金字塔先从底层建立）。高斯金字塔构建完成后，将相邻的高斯金字塔相减就得到了DoG金字塔。$\quad$高斯金字塔的组数一般是： o=\left[\log _{2} \min (m, n)\right]-a$\quad$$o$表示高斯金字塔的层数，$m,n$分别是图像的行和列。减去的系数$a$可以为下列式子中的任意值： 0,1,2...\cdots \log{2}{\min(m,n)}$\quad$和具体需要的金字塔的顶层图像的大小有关。$\quad$高斯模糊参数$\sigma$(尺度空间），可由下面关系式得： \sigma(o, s)=\sigma_{0} \cdot 2^{\frac{o+s}{s}}$\quad$其中o为所在的组，s为所在的层，$\sigma_0$为初始的尺度，S为每组的层数。$\quad$在Lowe的算法实现中$\sigma_0=1.6,O_min=−1,S=3$就是首先将原图像的长和宽各扩展一倍。$\quad$从上面可以得知同一组内相邻层的图像尺度关系： \sigma_{s+1}=k \cdot \sigma_{s}=2^{\frac{1}{s}} \cdot \sigma_{s}$\quad$相邻组之间的尺度关系： \sigma_{o+1}=2 \sigma_{o}2.3 第一组第一层图像的生成$\quad$很多初涉SIFT的都会被这个问题所困惑，这里要分两种情况：其一是把第一组的索引定为0；其二是把第一组的索引定为-1。$\quad$我们先考虑第一组索引为0的情况，我们知道第一组第一层的图像是由原图像与$\sigma_0$（一般设置为1.6）的高斯滤波器卷积生成，那么原图像是谁呢？是$I(x,y)$吗？不是！为了图像反走样的需要，通常假设输入图像是经过高斯平滑处理的，其值为$\sigma_n=0.5$，即半个像元。意思就是说我们采集到的图像$I(x,y)$，已经被$\sigma=\sigma_n=0.5$的高斯滤波器平滑过了。所以我们不能直接对$I(x,y)$用$\sigma_0$的高斯滤波器平滑，而应该用$\sigma=\sqrt{\sigma_{0}^{2}-\sigma_{n}^{2}}$的高斯滤波器去平滑$I(x,y)$，即 FirstLayer(x, y)=I(x, y) \otimes G\left(x, y, \sqrt{\sigma_{0}^{2}-\sigma_{n}^{2}}\right)$\quad$其中$FirstLayer(x,y)$表示整个尺度空间为第1组第1层的图像，$\sigma_0$一般取1.6，$\sigma_n=0.5$。$\quad$现在我们来考虑把第一组的索引定为-1的情况。那么首先第一个问题便是为什么要把索引定为-1。如果索引为0，如上面那种情况所示，整个尺度空间的第1组的第1层图像已经是由原图像模糊生成的了，那么也就是说已经丢失了细节信息，那么原图像我们完全没有利用上。基于这种考虑，我们先将图像放大2倍，这样原图像的细节就隐藏在了其中。由上面一种情况分析，我们已经知道了$I(x,y)$看成是已经被$\sigma_n=0.5$模糊过的图像，那么将$I(x,y)$放大2倍后得到$I_s(x,y)$，则可以看为是被$2\sigma=1$的高斯核模糊过的图像。那么由$I_s$生成第1组第1层的图像用的高斯滤波器的$\sigma=\sqrt{\sigma_{0}^{2}-(2\sigma_{n})^{2}}$。可以表示为 FirstLayer(x, y)=I(x, y) \otimes G\left(x, y, \sqrt{\sigma_{0}^{2}-(2\sigma_{n})^{2}}\right)$\quad$其中$FirstLayer(x,y)$表示整个尺度空间为第1组第1层的图像，$I_s(x,y)$是由$I(x,y)$用双线性插值放大后的图像。$\sigma_0$一般取1.6，$\sigma_n=0.5$。 2.4 尺度空间中生成了多少幅图像$\quad$我们知道$S$是我们最终构建出来的用来寻找特征点的高斯差分图像，而特征点的寻找需要查找的是空间局部极小值，即在某一层上查找局部极值点的时候需要用到上一层与下一层的高斯差分图像，所以如果我们需要查找$S$层的特征点，需要$S+2$层高斯差分图像，然后查找其中的第2层到第$S+1$层。$\quad$而每一个高斯差分图像$G(x,y,\sigma)$都需要两幅尺度空间的图像$L(x,y,k\sigma)$与$L(x,y,\sigma)$进行差分生成，这里假设$S =3$，则我们需要的高斯差分图像有$S+2 = 5$张，分别为 G(x,y,\sigma),G(x,y,k\sigma),G(x,y,k^2\sigma),G(x,y,k^3\sigma),G(x,y,k^4\sigma)其中的$G(x,y,k\sigma),G(x,y,k^2\sigma),G(x,y,k^3\sigma)$这三张图像是我们用来查找局部极值点的图像。那么我们则需要$S+3 = 6$张尺度空间图像来生成上面那些高斯差分图像，它们分别为： L(x,y,\sigma),L(x,y,k\sigma),L(x,y,k^2\sigma),L(x,y,k^3\sigma),L(x,y,k^4\sigma),L(x,y,k^5\sigma)$\quad$从上面的分析，我们知道对于尺度空间来说，我们一共需要S+3层图像来构建出来S+2层高斯差分图像。所以，如果整个尺度空间一共有O组，每组有S+3层图像。共O*(S+3)张尺度图像，如果我们查找OpenCV中的SIFT源码，则很容易找到如下代码来说明问题：1pyr.resize(nOctaves*(nOctaveLayers + 3)); $\quad$上面代码中的pyr代表了整个尺度空间的图像，nOctaves为组数，nOctaveLayers即为我们定义的S。 2.5 为什么是倒数第3张$\quad$相信你在看很多SIFT算法描述里都这样写着，取上一张的倒数第3张图像隔行采样后作为下一组的第一张图像。答案是为了保证尺度空间的连续性，我们下面来仔细分析。$\quad$我们知道对于尺度空间第$o$组，第$s$层的图像，它的尺度为$\sigma=\sigma_0k^{(o+s/S)}$，其中，$k=1 / 2, o \in[0,1,2, \ldots, \text { nOctave }-1], s \in[0,1,2, \ldots, S+2]$。那么我们从第0组开始，看它各层的尺度。第0组：$\sigma_{o} \rightarrow 2^{1 / 3} \sigma_{0} \rightarrow 2^{2 / 3} \sigma_{0} \rightarrow 2^{3 / 3} \sigma_{0} \rightarrow 2^{4 / 3} \sigma_{0} \rightarrow 2^{5 / 3} \sigma_{0}$第1组：$2\sigma_{o} \rightarrow 2 \ast 2^{1 / 3} \sigma_{0} \rightarrow 2 \ast 2^{2 / 3} \sigma_{0} \rightarrow 2 \ast 2^{3 / 3} \sigma_{0} \rightarrow 2 \ast 2^{4 / 3} \sigma_{0} \rightarrow 2 \ast 2^{5 / 3} \sigma_{0}$$\quad$我们只分析2组便可以看出，第1组的第0层图像恰好与第0组的倒数第三幅图像一致，尺度都为$ 2 \sigma $，所以我们不需要再根据原图来重新卷积生成每组的第0张图像，只需采用上一层的倒数第3张来降采样即可。$\quad$我们也可以继续分析，第0组尺度空间得到的高斯差分图像的尺度为：$\sigma_{0} \rightarrow 2^{1 / 3} \sigma_{0} \rightarrow 2^{2 / 3} \sigma_{0} \rightarrow 2^{3 / 3} \sigma_{0} \rightarrow 2^{4 / 3} \sigma_{0}$而第1组尺度空间得到的高斯差分图像的尺度为：$2\sigma_{0} \rightarrow 2 \ast 2^{1 / 3} \sigma_{0} \rightarrow 2 \ast 2^{2 / 3} \sigma_{0} \rightarrow 2 \ast 2^{3 / 3} \sigma_{0} \rightarrow 2 \ast 2^{4 / 3} \sigma_{0}$如果我们把它们的中间三项取出来拼在一起，则尺度为$2^{1 / 3} \sigma_{0} \rightarrow 2^{2 / 3} \sigma_{0} \rightarrow 2^{3 / 3} \sigma_{0} \rightarrow 2 \ast 2^{1 / 3} \sigma_{0} \rightarrow 2 \ast 2^{2 / 3} \sigma_{0} \rightarrow 2 \ast 2^{3 / 3} \sigma_{0} $，正好连续！！这一效果带来的直接的好处是在尺度空间的极值点确定过程中，我们不会漏掉任何一个尺度上的极值点，而是能够综合考虑量化的尺度因子。 2.6 用第i-1层的图像生成第i层的图像$\quad$值得注意的是，在SITF的源码里，尺度空间里的每一层的图像（除了第1层）都是由其前面一层的图像和一个相对$\sigma$的高斯滤波器卷积生成，而不是由原图和对应尺度的高斯滤波器生成的，这一方面是因为我前面提到的不存在所谓意思上的“原图”，我们的输入图像$I(x,y)$已经是尺度为$\sigma$的图像了。另一方面是由于如果用原图计算，那么相邻两层之间相差的尺度实际上非常小，这样会造成在做高斯差分图像的时候，大部分值都趋近于0，以致于后面我们很难检测到特征点。$\quad$基于上面两点原因（个人认为原因1是最主要的，原因2只是根据实际尝试后的一个猜想，并无理论依据），所以对于每一组的第i+1层的图像，都是由第i层的图像和一个相对尺度的高斯滤波器卷积生成。$\quad$那么相对尺度如何计算呢，我们首先考虑第0组，它们的第i+1层图像与第i层图像之间的相对尺度为$\sigma_{Diff_i}=\sqrt{\left(\sigma_{0} k^{i+1}\right)^{2}-\left(\sigma_{0} k^{i}\right)^{2}}$，为了保持尺度的连续性，后面的每一组都用这样一样相对尺度（SIFT实际代码里是这样做的）。 3. 特征点的搜索3.1 搜索策略$\quad$角点的搜索是通过同一组内各DoG相邻层之间比较完成的。为了寻找尺度空间的极值点，每一个采样点要和它所有的相邻点进行比较，看其是否比它的图像域和尺度域的相邻点大或小。对于其中的任意一个检测点都要和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像位置空间都检测到极值点。也就是，比较是在一个3×3的立方体内进行。搜索过程从每组的第二层开始，以第二层为当前层，对第二层的DoG图像中的每个点取一个3×3的立方体，立方体上下层为第一层与第三层。这样，搜索得到的极值点既有位置坐标（DoG的图像坐标），又有空间尺度坐标（层坐标）。当第二层搜索完成后，再以第三层作为当前层，其过程与第二层的搜索类似。当S=3时，每组里面要搜索3层。 3.2 子像元插值并剔除不好的极值点$\quad$通过比较检测得到的DoG的局部极值点实在离散的空间搜索得到的，由于离散空间是对连续空间采样得到的结果，因此在离散空间找到的极值点不一定是真正意义上的极值点，因此要设法将不满足条件的点剔除掉。可以通过尺度空间DoG函数进行曲线拟合寻找极值点，这一步的本质是去掉DoG局部曲率非常不对称的点。下图显示了一维信号离散空间得到的极值点与连续空间的极值点之间的差别。利用已知的离散空间点插值到连续空间极值点的方法叫子像元插值。$\quad$首先我们来看一个一维函数插值的例子。我们已经知道$f(x)$上几个点的函数值$f(−1)=1,f(0)=6,f(1)=5$，求$f(x)$在$[−1,1]$上的最大值。$\quad$如果我们只考虑离散的情况，那么只用简单比较一下，便知最大值为$f(0)=6$，下面我们用子像元插值法来考虑连续区间的上情况：$\quad$利用泰勒级数，可以将$f(x)$在$f(0)$附近展开为： f(x) \approx f(0)+f^{\prime}(0) x+\frac{f^{\prime \prime}(0)}{2} x^{2}$\quad$另外我们知道$f(x)$在$x$处的导数写成离散的形式为$f^{\prime}(x)=\frac{f(x+1)-f(x)}{2}$，二阶导数写成离散形式为$f^{\prime \prime}(x)=f(x+1)+f(x-1)-2 f(x)$。 $\quad$所以，我们可以算出$f(x) \approx 6+2 x+\frac{-6}{2} x^{2}=6+2 x-3 x^{2}$$\quad$求取函数$f(x)$的极大值和极大值所在的位置： \begin{array}{c}{f^{\prime}(x)=2-6 x=0, \quad \hat{x}=\frac{1}{3}} \\ {f(\hat{x})=6+2 \times \frac{1}{3}-3 \times\left(\frac{1}{3}\right)^{2}=6 \frac{1}{3}}\end{array}$\quad$现在回到我们SIFT点检测中来，我们要考虑的是一个三维问题，假设我们在尺度为$\sigma$的尺度图像$D(x,y)$上检测到了一个局部极值点，空间位置为$(x,y,\sigma)$，由上面的分析我们知道，它只是一个离散情况下的极值点，连续情况下，极值点可能落在了$(x,y,\sigma)$的附近，设其偏离了$(x,y,\sigma)$的坐标为$(x + \Delta x,y + \Delta y,\sigma + \Delta \sigma)$。则对$(x + \Delta x,y + \Delta y,\sigma + \Delta \sigma)$可以表示为在点$(x,y,\sigma)$处的泰勒展开： D(x + \Delta x, y + \Delta y, \sigma + \Delta \sigma)=D(x, y, \sigma)+\left[\begin{array}{ccc}{\frac{\partial D}{x}} & {\frac{\partial D}{y}} & {\frac{\partial D}{\sigma}}\end{array}\right]\left[\begin{array}{c}{\Delta x} \\ {\Delta y} \\ {\Delta \sigma}\end{array}\right] \\ +\frac{1}{2}\begin{bmatrix}\Delta x \Delta y \Delta \sigma \end{bmatrix} \begin{bmatrix} \frac{\partial^{2} D}{\partial x^{2}} & \frac{\partial^{2} D}{\partial x \partial y} & \frac{\partial^{2} D}{\partial x \partial \sigma}\\ \frac{\partial^{2} D}{\partial y d x} & \frac{\partial^{2} D}{\partial y^{2}} & \frac{\partial^{2} D}{\partial y \partial \sigma}\\ \frac{\partial^{2} D}{\partial \sigma \partial x} & \frac{\partial^{2} D}{\partial \sigma \partial y} & \frac{\partial^{2} D}{\partial \sigma^{2}} \end{bmatrix} \left[\begin{array}{l}{\Delta x} \\ {\Delta y} \\ {\Delta \sigma}\end{array}\right]$\quad$可以将上式写成矢量形式如下： D(x)=D+\frac{\partial D^{T}}{\partial x} \Delta x+\frac{1}{2} \Delta x^{T} \frac{\partial^{2} D^{T}}{\partial x^{2}} \Delta x$\quad$令上式的一阶导数等于0，可以求得$\Delta x=-\frac{\partial^{2} D^{-1}}{\partial x^{2}} \frac{\partial D(x)}{\partial x}$$\quad$然后再把求得的Δx代入到D(x)的泰勒展开式中：$\quad$通过多次迭代(Lowe算法里最多迭代5次)，得到最终候选点的精确位置与尺度$\hat{x}$，将其代入公式 D(\hat{x})=D+\frac{1}{2} \frac{\partial D^{T}}{\partial x} \hat{x}$\quad$求得$D(\hat{x})$，设对比度的阈值为$T$，若$|D(\hat{x})|&gt;=T$，则该特征点保留，否则剔除。 3.3 删除边缘效应$\quad$为了得到稳定的特征点，只是删除DoG响应值低的点是不够的。由于DoG对图像中的边缘有比较强的响应值，而一旦特征点落在图像的边缘上，这些点就是不稳定的点。一方面图像边缘上的点是很难定位的，具有定位歧义性；另一方面这样的点很容易受到噪声的干扰而变得不稳定。$\quad$一个平坦的DoG响应峰值往往在横跨边缘的地方有较大的主曲率，而在垂直边缘的方向有较小的主曲率。而主曲率可以通过2×2的Hessian矩阵H求出： H(x, y)=\left[\begin{array}{ll}{D_{x x}(x, y)} & {D_{x y}(x, y)} \\ {D_{x y}(x, y)} & {D_{y y}(x, y)}\end{array}\right]$\quad$上式中，D值可以通过求取邻近点像素的差分得到。H的特征值与D的主曲率成正比例。我们可以避免求取具体的特征值，因为我们只关心特征值的比例。令$\alpha=\lambda_{max}$为最大的特征值，$\beta=\lambda_{min}$为最小的特征值，那么，我们通过H矩阵直迹计算它们的和，通过H矩阵的行列式计算它们的乘积： \begin{array}{c}{\operatorname{Tr}(H)=D_{x x}+D_{y y}=\alpha+\beta} \\ {\operatorname{Det}(H)=D_{x x} D_{y y}-\left(D_{x y}\right)^{2}=\alpha \beta}\end{array}$\quad$如果$\gamma$为最大特征值与最小特征值之间的比例，那么$\alpha=\gamma \beta$，这样便有 \frac{T r(H)^{2}}{\operatorname{Det}(H)}=\frac{(\alpha+\beta)^{2}}{\alpha \beta}=\frac{(\gamma+1)^{2}}{\gamma}$\quad$上式的结果只与两个特征值的比例有关，而与具体特征值无关。当两个特征值相等时,$\frac{(\gamma+1)^{2}}{\gamma}$最小。随着$\gamma$的增加，$\frac{(\gamma+1)^{2}}{\gamma}$的值也增加。所以要想检查主曲率的比例小于某一阈值$\gamma$，只要检查下式是否成立： \frac{\operatorname{Tr}(H)^{2}}{\operatorname{Det}(H)}]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV Descriptor FAST]]></title>
    <url>%2F2019%2F07%2F18%2FOpenCV-Descriptor-FAST%2F</url>
    <content type="text"><![CDATA[1. 基本原理 FAST 只是一种特征点检测的算法，并不涉及特征点的特征描述。 若某像素与其周围邻域内足够多的像素点相差较大，则该像素可能是角点。 算法步骤: 从图片中选取一个像素P，我们首先把它的亮度值设为Ip。 设定一个阈值t。 考虑以该像素点为中心的一个半径等于3像素的离散化的Bresenham圆，这个圆的边界上有16个像素（如图1所示）。 现在，如果在这个大小为16个像素的圆上有n个连续的像素点，它们的像素值要么都比Ip+t大，要么都比Ip−t小，那么它就是一个角点。（如图1中的白色虚线所示）。n的值可以设置为12或者9，实验证明选择9可能会有更好的效果。 2. high-speed-test$\quad$上面的算法中，对于图像中的每一个点，我们都要去遍历其邻域圆上的16个点的像素，效率较低。我们下面提出了一种高效的测试（high-speed test）来快速排除一大部分非角点的像素。该方法仅仅检查在位置1，9，5和13四个位置的像素，首先检测位置1和位置9，如果它们都比阈值暗或比阈值亮，再检测位置5和位置13。如果P是一个角点，那么上述四个像素点中至少有3个应该必须都大于Ip+t或者小于Ip−t，因为若是一个角点，超过四分之三圆的部分应该满足判断条件。如果不满足，那么p不可能是一个角点。对于所有点做上面这一部分初步的检测后，符合条件的将成为候选的角点，我们再对候选的角点，做完整的测试，即检测圆上的所有点。$\quad$上面的算法效率实际上是很高的，但是有点一些缺点： 当我们设置n&lt;12时，就不能使用快速算法来过滤非角点的点； 检测出来的角点不是最优的，这是因为它的效率取决于问题的排序与角点的分布，这种检测方法暗含了对特征周围的像素分布的假定； 对于角点分析的结果被丢弃了，略了上述的前4个检测的结果分析； 多个特征点容易挤在一起。 3. 改进算法 一个以像素p为中心，亮度值为Ip，半径为3的圆上，有16个像素点（p1、p2、…、p16）。 定义一个阈值t，计算p1、p9与中心p的像素差，若它们绝对值都小于阈值，则p点不可能是特征点，直接pass掉；否则，当做候选点，有待进一步考察； 若p是候选点，则计算p1、p9、p5、p13与中心p的像素差，若它们的绝对值有至少3个超过阈值，则当做候选点，再进行下一步考察；否则，直接pass掉； 若p是候选点，则计算p1到p16这16个点与中心p的像素差，若它们至少有连续9个超过阈值，则是特征点；否则，直接pass掉。 对图像进行非极大值抑制：计算特征点出的FAST得分值（即score值，也即s值），判断以特征点p为中心的一个邻域（如3x3或5x5）内。计算若有多个特征点，则判断每个特征点的s值（16个点与中心差值的绝对值总和），若p是邻域所有特征点中响应值最大的，则保留；否则，抑制。若邻域内只有一个特征点（角点），则保留。得分计算公式如下（公式中用V表示得分，t表示阈值）： V=\max \left\{\begin{array}{l}{\sum(\text { pixel values }-p) \text { if }(\text { value }-p)>t} \\ {\sum(p-\text { pixel values }) \text { if }(p-\text { value })>t}\end{array}\right.上面是FAST-9，当然FAST-10、FAST-11、FAST-12也是一样的，只是步骤4中，超过阈值的个数不一样。FAST算法实现起来简单，尤其是以速度快著称。 4. 利用机器学习方法 首先选取你进行角点提取的应用场景下很多张的测试图片。 在每个图像中运行FAST算法以查找特征点。 对于每个角点，我们把它邻域圆上的16个点存储下来保存在一个vector内，处理所有步骤2中得到的角点，并把它们存储在P中。 这16个像素中的每个像素x（比如说）可以具有以下三种状态之一： S_{p-x}=\left\{\begin{array}{lll}{d,} & {I_{p-x} \leq I_{p}-t} & {\text { (darker) }} \\ {s,} & {I_{p}-t]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV Descriptor Class Introduction]]></title>
    <url>%2F2019%2F07%2F16%2FOpenCV-Descriptor-Class-Introduction%2F</url>
    <content type="text"><![CDATA[KeyPoint 类1234567891011121314151617181920212223242526272829class cv::KeyPoint&#123;public: cv::Point2f pt; // 特征点的坐标 float size; // 特征点领域空间或者半径说明，与描述符有关 float angle; // 特征点的主方向，-1如果没有 float response; // 特征点的评分，表明一个特征点好坏的指标，可以采用harris float octave; // 特征点在金字塔的层数 int class_id; // 特征点所属的聚类 // 构造函数 cv::KeyPoint( cv::Point2f _pt, float _size, float _angle=-1, float _response=0, int _octave=0, int _class_id=-1 ); cv::KeyPoint( float x, float y, float _size, float _angle=-1, float _response=0, int _octave=0, int _class_id=-1 );&#125; KeyPoint 是特征点的类，特征点类主要包含点的坐标，描述符半径（点的半径），特征点的主方向，特征点的评分，特征点在金字塔的层数以及特征点在图像特征聚类时所属的类ID。特征点是Feature2D中最基本的数据类。 2. Feature2D 类Feature2D类用于特征点的检测以及描述符的提取。detect用于特征点的提取，compute用于描述符的提取，detectAndCompute可以同时检测特征点并提取特征。 3. DMatch 类DMatch 表示描述符匹配数据结构，queryIdx表示特征点描述符在左图中的index，trainIdx表示特征点描述符在右图中的index，imgIdx表示右图在字典中的序号，distance表示描述符之间的距离。 4. DescriptorMatcher 类DescriptorMatcher是用于匹配描述符的类，它可以用作一个训练集的识别，也可以在两个描述符列表中进行匹配。match用于特征描述符的匹配，结果存放在输入的DMatch Vector引用中，knnMatch用于找到找到得分前k的匹配，按得分升序排列。radiusmatch用于找到描述符距离小于maxDistance的匹配。描述符匹配比较策略。 5. GFTTDetector 类GFTTDector继承于Feature2D，可以直接调用其detect等，这是一个基于Harris角点检测建立的特征检测类，特征点的检测也可以使用Shi-Tomasi。]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV Descriptor Pyramid Lucas-Kanade]]></title>
    <url>%2F2019%2F07%2F16%2FOpenCV-Descriptor-Pyramid-Lucas-Kanade%2F</url>
    <content type="text"><![CDATA[1. LK 光流的原理LK光流基于以下三个假设 光度一致性假设。一个像素点的灰度值在相邻帧之间移动时保持不变。 时间一致性假设。假设在同一平面的像素patch变化都很缓慢。 空间一致性假设。在一个场景中相邻的像素点属于同一平面，具有相同的运动。 $\quad$在LK光流中，我们认为来自相机的图像是随时间变化的。图像可以看作时间的函数:$I(t)$。那么，一个在$t$时刻,位于$(x,y)$处的像素，它的灰度可以写成$I(x,y,t)$。对于$t$时刻位于$(x,y)$处的像素,我们设$t+dt$时刻，它运动到$(x+dx,y+dy)$处。由于灰度不变，我们有: \boldsymbol{I}(x+\mathrm{d} x, y+\mathrm{d} y, t+\mathrm{d} t)=\boldsymbol{I}(x, y, t)$\quad$灰度不变假设是一个很强的假设，实际当中很可能不成立。事实上，由于物体的材质不同，像素会出现高光和阴影部分；有时，相机会自动调整曝光参数，使得图像整体变亮或变暗。这些时候灰度不变假设都是不成立的，因此光流的结果也不一定可靠。然而，从另一方面来说，所有算法都是在一定假设下工作的。如果我们什么假设都不做，就没法设计实用的算法。所以，暂且让我们认为该假设成立，看看如何计算像素的运动。对左边进行泰勒展开，保留一阶项，得： I(x+\mathrm{d} x, y+\mathrm{d} y, t+\mathrm{d} t) \approx \boldsymbol{I}(x, y, t)+\frac{\partial I}{\partial x} \mathrm{d} x+\frac{\partial I}{\partial y} \mathrm{d} y+\frac{\partial I}{\partial t} \mathrm{d} t$\quad$因为我们假设了灰度不变，于是下一个时刻的灰度等于之前的灰度，从而 \frac{\partial \boldsymbol{I}}{\partial x} \mathrm{d} x+\frac{\partial \boldsymbol{I}}{\partial y} \mathrm{d} y+\frac{\partial \boldsymbol{I}}{\partial t} \mathrm{d} t=0$\quad$两边除以$dt$，得： \frac{\partial \boldsymbol{I}}{\partial x} \frac{\mathrm{d} x}{\mathrm{d} t}+\frac{\partial \boldsymbol{I}}{\partial y} \frac{\mathrm{d} y}{\mathrm{d} t}=-\frac{\partial \boldsymbol{I}}{\partial t}$\quad$其中$\mathrm{d} x / \mathrm{d} t$为像素在$x$轴上运动速度，而$\mathrm{d} y / \mathrm{d} t$ 为$y$轴速度，把它们记为$u,v$。同时 $\partial \boldsymbol{I} / \partial x$为图像在该点处$x$方向的梯度，另一项则是在$y$方向的梯度，记为$I_x,I_y$。把图像灰度对时间的变化量记为$I_t$写成矩阵形式，有： \left[\begin{array}{ll}{\boldsymbol{I}_{x}} & {\boldsymbol{I}_{y}}\end{array}\right]\left[\begin{array}{l}{u} \\ {v}\end{array}\right]=-\boldsymbol{I}_{t}$\quad$我们想计算的是像素的运动$u,v$，但是该式是带有两个变量的一次方程，仅凭它无法计算出$u,v$。因此，必须引入额外的约束来计算$u,v$。在LK光流中，我们假设某一个窗口内的像素具有相同的运动。考虑一个大小为$w \times w$大小的窗口，它含有$w^2$数量的像素。由于该窗口内像素具有同样的运动，因此我们共有$w^2$个方程: \left[\begin{array}{ll}{\boldsymbol{I}_{x}} & {\boldsymbol{I}_{y}}\end{array}\right]_{k}\left[\begin{array}{c}{u} \\ {v}\end{array}\right]=-\boldsymbol{I}_{t k}, \quad k=1, \ldots, w^{2}记： \boldsymbol{A}=\left[\begin{array}{c}{\left[\boldsymbol{I}_{x}, \boldsymbol{I}_{y}\right]_{1}} \\ {\vdots} \\ {\left[\boldsymbol{I}_{x}, \boldsymbol{I}_{y}\right]_{k}}\end{array}\right], \boldsymbol{b}=\left[\begin{array}{c}{\boldsymbol{I}_{t 1}} \\ {\vdots} \\ {\boldsymbol{I}_{t k}}\end{array}\right]于是整个方程为： A\left[\begin{array}{l}{u} \\ {v}\end{array}\right]=-b这是一个关于$u,v$的超定线性方程，传统解法是求最小二乘解。最小二乘在很多时候都用到过: \left[\begin{array}{l}{u} \\ {v}\end{array}\right]^{*}=-\left(\boldsymbol{A}^{T} \boldsymbol{A}\right)^{-1} \boldsymbol{A}^{T} \boldsymbol{b}这样就得到了像素在图像间的运动速度$u,v$。当$t$取离散的时刻而不是连续时间时，我们可以估计某块像素在若干个图像中出现的位置。由于像素梯度仅在局部有效，所以如果一次迭代不够好的话，我们会多迭代几次这个方程。在SLAM中，LK光流常被用来跟踪角点的运动，我们不妨通过程序体会一下。 2. OpenCV 函数]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV Descriptor SubPix]]></title>
    <url>%2F2019%2F07%2F15%2FOpenCV-Descriptor-SubPix%2F</url>
    <content type="text"><![CDATA[1. 问题$\quad$求出角点，下一步往往需要求亚像素点。即，从一个整数坐标，求出一个小数坐标。从科学上来讲，精度提高了。——“精确到了小数点后X位”。如何求？本文基于《LearningOpenCV》一书第十章“SubpixelCorner”一节写就。 2.解答2.1 如何从整数算出小数$\quad$如何从整数算出小数？图像本来都是像素点，用整数来表达坐标最自然。为什么会有小数坐标呢？这其实是引入数学手段，进行计算的结果。那是什么数学方法呢？最小二乘法。 2.2 如何构造方程最小二乘法需要得到$Ax=b$，才有方程可解。在亚像素角点的求解中，列方程用到了“垂直向量，乘积为0”这一性质。那是哪两个向量相乘呢？看图 q，即待求的亚像素点，很神秘，未知。 pi,即q周围的点，属于群众，坐标是已知的(自行选取) (pi-q)，即是第一个向量 pi处的梯度，Gi，即是第二个向量 为什么$G_i\times (p_i -q)=0$考虑以下两种情况： p0这种情况，位于一块白色区域，此时，梯度为0 p1这种情况，位于边缘，即黑白相交处，此时，梯度不为0，但是，与p1-q相垂直！ 所以，无论哪种情况，都会导致： G_i\times (p_i -q)=02.3 转换到最小二乘法的矩阵形式将上面的方程展开移项，得： G_{i} \times q=G_{i} \times p_{i}即： q=\left(G_{i}^{T} G_{i}\right)^{-1} \times \left(G_{i}^{T} G_{i} p_{i}\right)2.4 从理论到代码的对应将上面的方程展开移项，得： G_{i} \times q=G_{i} \times p_{i}最小二乘法求解： G_{i}^{T} G_{i} q=G_{i}^{T} G_{i} p_{i}即： q=\left(G_{i}^{T} G_{i}\right)^{-1} \times \left(G_{i}^{T} G_{i} p_{i}\right)2.4.1 如何选取$p_i$?初始的角点，整数坐标，设为$q_0$，以$q_0$为中心，选取一个窗口。尺寸可自选，如11，(5 + 1 + 5)*(5 + 1 + 5)。这个窗口中的每一点，构成了$p_i。 2.4.2 如何计算梯度？求梯度在图像处理里，用Sobel算子做卷积即可。对于$p_i$点有：(1) $G_i$，对每个点的梯度，$\begin{bmatrix}d_x &amp; d_y\end{bmatrix}$(2) $G_i^T$，梯度的转置，$\begin{bmatrix}d_x \ d_y\end{bmatrix}$(3) $G_i^T*G_i$，即$\begin{bmatrix}d_xd_x &amp; d_xd_y\\dxdy &amp; dydy\end{bmatrix}$ 2.4.3 求和的处理$q$点只有一个，$p_i$点却有多个。所以，对于各点处的梯度，要求和。严格地来写，公式2是不正确的，因为少了求和符号，加上后： q=\sum_{i=0}^{N}\left(G_{i}^{T} G_{i}\right)^{-1} *\left(G_{i}^{T} G_{i} p_{i}\right)2.4.4 权重的引入采用多点进行计算，本是为了更精确。但各点离中心距离不一，所以不可一视同仁，要引入权重，如高斯权重。假设$p_i$处权重为$w_i$，上式进一步修正为： q=\sum_{i=0}^{N}\left(G_{i}^{T} G_{i} \omega_{i}\right)^{-1} *\left(G_{i}^{T} G_{i} \omega_{i}p_{i}\right)2.4.5 迭代与终止条件？求解一次后，即可得到一个亚像素点$q(q_x,q_y)$。如果以q为中心点，再次： 选取窗口，得到新的一组pi 对pi求梯度 用最小二乘法求解即得到新的点，q1。如此多迭代几次，会得出一系列亚像素点$q_2,q_3,\cdots,q_n$。那什么时候终止呢？OpenCV中的做法是： 指定迭代次数，比如，迭代10次后，不再进行计算，认为得到最优解。 指定结果精度，比如，设定ε=1.0e-6，如果qn-qn-1&lt;=ε，即认为qn是最优解。 3 总结 亚像素角点是纯数学方法计算出来的。 计算手段是用最小二乘法。 最小二乘法的计算过程，相当于选村长的过程： 从一点（原始角点）开始，选取周围有投票权的群众 群众的选取规则：离所有人的距离方差最小 选出的新村长（亚像素点）与在原村长周围，但不一样。 与OpenCV源码相比，文中简化了选取“群众”pi的过程。没有用插值法。 4. OpenCV 函数1234567void cv::cornerSubPix(cv::InputArray image, // Input imagecv::InputOutputArray corners, // Guesses in, and results outcv::Size winSize, // Area is NXN; N=(winSize*2+1)cv::Size zeroZone, // Size(-1,-1) to ignorecv::TermCriteria criteria // When to stop refinement);]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV Descriptor Shi-Tomasi]]></title>
    <url>%2F2019%2F07%2F15%2FOpenCV-Descriptor-Shi-Tomasi%2F</url>
    <content type="text"><![CDATA[1. 基本原理OpenCV goodFeaturesToTrack()是cornerHarris() 函数升级版。该函数的角点检测效果与cornerHarris()函数效果差不多。Harris 角点检测的打分公式为： R=\lambda_{1} \lambda_{2}-k\left(\lambda_{1}+\lambda_{2}\right)^{2}Shi-Tomasi 使用的打分函数为： R=\min \left(\lambda_{1}, \lambda_{2}\right)如果打分超过阈值，我们就认为它是一个角点。我们可以把它绘制到 λ1～λ2空间中，就会得到下图：(角点：绿色区域）可对比上图得出差异) 2. OpenCV 函数1234567891011121314151617void cv::goodFeaturesToTrack( cv::InputArray image, // 输入图像（CV_8UC1 CV_32FC1） cv::OutputArray corners, // 输出角点 vector int maxCorners, // 最大角点数目 double qualityLevel, // 质量水平系数（小于1.0的正数，一般在0.01-0.1之间） double minDistance, // 最小距离，小于此距离的点忽略 // 以下为可选参数 cv::InputArray mask = noArray(), //指定感兴趣区域。 mask=0的点忽略 int blockSize = 3, // 使用的邻域数：计算协方差矩阵时的窗口大小 bool useHarrisDetector = false, // false ='Shi Tomasi metric' double k = 0.04 // Harris角点检测时使用 ); // 常用如下参数： void cv::goodFeaturesToTrack(image,corner, 500, // 最多检测到的角点数 0.01, // 阈值系数 10); // 角点间的最小距离]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV Descriptor Harris]]></title>
    <url>%2F2019%2F07%2F15%2FOpenCV-Descriptor-Harris%2F</url>
    <content type="text"><![CDATA[1. 基本原理Harris角点检测的基本思想是使用一个固定窗口在图像上进行任意方向上的滑动，比较滑动前与滑动后两种情况，窗口中的像素灰度变化程度，如果存在任意方向上的滑动，都有着较大灰度变化，那么我们可以认为该窗口中存在角点。 E(u, v)=\sum_{x, y}\underbrace{w(x, y)}_{\text {window function shifted intensity }} [\underbrace{I(x+u,y+v)}_{\text {shifted intensity}}-\underbrace{I(x, y)}_{\text {intensity}}]^{2}公式解释： [u,v]是窗口的偏移量 (x,y)是窗口内所对应的像素坐标位置，窗口有多大，就有多少个位置 w(x,y)是窗口函数，最简单情形就是窗口内的所有像素所对应的w权重系数均为1。但有时候，我们会将w(x,y)函数设定为以窗口中心为原点的二元正态分布。如果窗口中心点是角点时，移动前与移动后，该点的灰度变化应该最为剧烈，所以该点权重系数可以设定大些，表示窗口移动时，该点在灰度变化贡献较大；而离窗口中心(角点)较远的点，这些点的灰度变化几近平缓，这些点的权重系数，可以设定小点，以示该点对灰度变化贡献较小，那么我们自然想到使用二元高斯函数来表示窗口函数。窗口函数(Sobel求导中使用的窗口) ：可以是正常的矩形窗口（窗口内权值为1，窗口外权值为0），也可以是对每一个像素给予不同权重的高斯窗口。 根据上述表达式，当窗口处在平坦区域上滑动，可以想象的到，灰度不会发生变化，那么$E(u,v) = 0$；如果窗口处在比纹理比较丰富的区域上滑动，那么灰度变化会很大。算法最终思想就是计算灰度发生较大变化时所对应的位置，当然这个较大是指对任意方向上的滑动，并非单指某个方向。 2. 泰勒近似M判别矩阵根据泰勒展式，有： f(x+u, y+v) \approx f(x, y)+u f_{x}(x, y)+v f_{y}(x, y)于是： \begin{aligned} & \sum[I(x+u, y+v)-I(x, y)]^{2} \\[2ex] \approx & \sum\left[I(x, y)+u I_{x}+v I_{y}-I(x, y)\right]^{2} \\[2ex] =& \sum u^{2} I_{x}^{2}+2 u v I_{x} I_{y}+v^{2} I_{y}^{2} \end{aligned}令： M=\sum_{x, y} w(x, y)\left[\begin{array}{cc}{I_{x}^{2}} & {I_{x} I_{y}} \\[2ex] {I_{x} I_{y}} & {I_{y}^{2}}\end{array}\right]所以： E(u, v) \cong[u, v] M\left[\begin{array}{l}{u} \\[2ex] {v}\end{array}\right]$\quad$不知道大家有没有注意到这三种区域的特点，平坦区域上的每个像素点所对应的(IX,IY)坐标分布在原点附近，其实也很好理解，针对平坦区域的像素点，他们的梯度方向虽然各异，但是其幅值都不是很大，所以均聚集在原点附近；边缘区域有一坐标轴分布较散，至于是哪一个坐标上的数据分布较散不能一概而论，这要视边缘在图像上的具体位置而定，如果边缘是水平或者垂直方向，那么Iy轴方向或者Ix方向上的数据分布就比较散；角点区域的x、y方向上的梯度分布都比较散。我们是不是可以根据这些特征来判断哪些区域存在角点呢？ 虽然我们利用E(u,v)来描述角点的基本思想，然而最终我们仅仅使用的是矩阵M。让我们看看矩阵M形式，是不是跟协方差矩阵形式很像，像归像，但是还是有些不同，哪儿不同？一般协方差矩阵对应维的随机变量需要减去该维随机变量的均值，但矩阵M中并没有这样做，所以在矩阵M里，我们先进行各维的均值化处理，那么各维所对应的随机变量的均值为0，协方差矩阵就大大简化了，简化的最终结果就是矩阵M，是否明白了？我们的目的是分析数据的主要成分，相信了解PCA原理的，应该都了解均值化的作用。 如果我们对协方差矩阵M进行对角化，很明显，特征值就是主分量上的方差，这点大家应该明白吧？不明白的话可以复习下PCA原理。如果存在两个主分量所对应的特征值都比较大，说明什么？ 像素点的梯度分布比较散，梯度变化程度比较大，符合角点在窗口区域的特点；如果是平坦区域，那么像素点的梯度所构成的点集比较集中在原点附近，因为窗口区域内的像素点的梯度幅值非常小，此时矩阵M的对角化的两个特征值比较小；如果是边缘区域，在计算像素点的x、y方向上的梯度时，边缘上的像素点的某个方向的梯度幅值变化比较明显，另一个方向上的梯度幅值变化较弱，其余部分的点都还是集中原点附近，这样M对角化后的两个特征值理论应该是一个比较大，一个比较小，当然对于边缘这种情况，可能是呈45°的边缘，致使计算出的特征值并不是都特别的大，总之跟含有角点的窗口的分布情况还是不同的。 注：M为协方差矩阵，需要大家自己去理解下，窗口中的像素集构成一个矩阵（2*n，假设这里有n个像素点），使用该矩阵乘以该矩阵的转置，即是协方差矩阵 因此可以得出下列结论： 特征值都比较大时，即窗口中含有角点。 特征值一个较大，一个较小，窗口中含有边缘。 特征值都比较小，窗口处在平坦区域。 R=\operatorname{det} M-k(\operatorname{trace} M)^{2} \begin{aligned} \operatorname{det} M &=\lambda_{1} \lambda_{2} \\[2ex] \operatorname{trace} M &=\lambda_{1}+\lambda_{2} \end{aligned}λ1 和 λ2是矩阵 M 的特征值：我们可以判断一个区域是否是角点，边界或者是平面。 当 λ1 和 λ2 都小时，|R|也小，这个区域就是一个平坦区域。 当 λ1 ≫ λ2 或者λ1≪λ2时，R 小于 0，这个区域是边缘。 当 λ1 和 λ2 都很大，并且λ1 ～λ2 时，R也很大，（λ1 和λ2 中的最小值都大于阈值）说明这个区域是角点。 3. Harris 角点的性质 该算法对亮度和对比度的变化不敏感。 该算子具有旋转不变性。 该算子不具有尺度不变性。 3. OpenCV3 函数实现12345678910cv2.cornerHarris(src=gray, blockSize, ksize, k, dst=None, borderType=None) """cornerHarris参数： src - 数据类型为 float32 的输入图像。(输入单通道图) Input array CV_8UC1 blockSize - 角点检测中要考虑的领域大小。也就是计算协方差矩阵时的窗口大小 Result array CV_32FC1 ksize - Sobel求导中使用的窗口大小 k - Harris 角点检测方程中的自由参数,取值参数为 [0.04,0.06]. 默认值0.4 dst - 输出图像 borderType - 边界的类型""" 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace cv;#define WINDOW_NAME1 "窗口1"#define WINDOW_NAME2 "窗口2"Mat g_srcImage, g_srcImage1, g_grayImage;int g_nThresh = 30; //当前阀值int g_nMaxThresh = 175;void on_fCornerHarris(int, void *) &#123; Mat dstImage; //目标图 Mat normImage; //归一化后的图 Mat scaledImage; //线性变换后的八位无符号整形的图 // 置零当前需要显示的两幅图，即清除上一次调用此函数时他们的值 dstImage = Mat::zeros(g_srcImage.size(), CV_32FC1); g_srcImage1 = g_srcImage.clone(); //角点检测 cornerHarris(g_grayImage, dstImage, 2, 3, 0.04, BORDER_DEFAULT); normalize(dstImage, normImage, 0, 255, NORM_MINMAX, CV_32FC1, Mat()); //将归一化后的图线性变换成8位无符号整形 convertScaleAbs(normImage, scaledImage); //将检测到的，且符合阀值条件的角点绘制出来 for (int i = 0; i &lt; normImage.rows; i++) &#123; for (int j = 0; j &lt; normImage.cols; j++) &#123; if ((int) normImage.at&lt;float&gt;(i, j) &gt; g_nThresh + 80) &#123; circle(g_srcImage1, Point(j, i), 5, Scalar(10, 10, 255), 2, 8, 0); circle(scaledImage, Point(j, i), 5, Scalar(0, 10, 255), 2, 8, 0); &#125; &#125; &#125; imshow(WINDOW_NAME1, g_srcImage1); imshow(WINDOW_NAME2, scaledImage);&#125;int main() &#123; g_srcImage = imread("1.png"); g_srcImage.copyTo(g_srcImage1); cvtColor(g_srcImage1, g_grayImage, COLOR_BGR2GRAY); namedWindow(WINDOW_NAME1, WINDOW_AUTOSIZE); createTrackbar("阀值：", WINDOW_NAME1, &amp;g_nThresh, g_nMaxThresh, on_fCornerHarris); on_fCornerHarris(0, NULL); waitKey(0); return 0;&#125; 4. 存在极大值抑制问题]]></content>
      <categories>
        <category>Descriptors</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Descriptors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵导数分析]]></title>
    <url>%2F2019%2F07%2F12%2F%E7%9F%A9%E9%98%B5%E5%AF%BC%E6%95%B0%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. 向量映射关于向量的导数（1）设$x=\left(x_{1}, x_{2}, \cdots, x_{n}\right)^{T}, \quad g=g\left(x_{1}, x_{2}, \cdots, x_{n}\right)$，定义： \frac{d g}{d x}=\left(\frac{\partial g}{\partial x_{1}} \cdots \frac{\partial g}{\partial x_{n}}\right)^{T} ; \frac{d g}{d x^{r}}=\left(\frac{\partial g}{\partial x_{1}} \cdots \frac{\partial g}{\partial x_{n}}\right)通常称上述两个式子分别为函数 $g$ 关于列向量 $x$ 与行向量 $x^T$ 的梯度。数量函数对行向量的梯度是行向量，对列向量的梯度也是列向量（2）数量函数$f(x)=x^{T} A x$关于向量$x$的导数为： \frac{d f}{d x}=\left(A+A^{T}\right) x证明因为 f(x)=x^{T} A x=\sum_{i, j=1}^{n} a_{i j} x_{i} x_{j}所以]]></content>
  </entry>
  <entry>
    <title><![CDATA[优化方法一：最小二乘法]]></title>
    <url>%2F2019%2F07%2F12%2F%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 非线性最小二乘$\quad$我们先来考虑一个简单的最小二乘问题: \min _{x} \frac{1}{2}\|f(\boldsymbol{x})\|_{2}^{2}$\quad$这里自变量$\boldsymbol{x} \in \mathbb{R}^{n}$，$f$是任意一个非线性函数，我们设它有$m$维：$f(\boldsymbol{x}) \in \mathbb{R}^{m}$ 。下面讨论如何求解这样一个优化问题。如果$f$是个数学形式上很简单的函数，那问题也许可以用解析形式来求。令目标函数的导数为零，然后求解$x$的最优值，就和一个求二元函数的极值一样： \frac{\mathrm{d} f}{\mathrm{d} \boldsymbol{x}}=\mathbf{0}$\quad$解此方程，就得到了导数为零处的极值。它们可能是极大、极小或鞍点处的值，只要挨个儿比较它们的函数值大小即可。但是，这个方程是否容易求解呢?这取决于$f$导函数的形式。在SLAM中，我们使用李代数来表示机器人的旋转和位移。对于不方便直接求解的最小二乘问题，我们可以用迭代的方式，从一个初始值出发，不断地更新当前的优化变量，使目标函数下降。具体步骤可列写如下:$\quad$这让求解导函数为零的问题，变成了一个不断寻找梯度并下降的过程。直到某个时刻增量非常小，无法再使函数下降。此时算法收敛，目标达到了一个极小，我们完成了寻找极小值的过程。在这个过程中，我们只要找到迭代点的梯度方向即可，而无需寻找全局导函数为零的情况。$\quad$接下来的问题是，增量$\Delta x_{k}$如何确定?——实际上，研究者们已经花费了大量精力探索增量的求解方式。我们将介绍两类办法，它们用不同的手段来寻找这个增量。目前这两种方法在视觉SLAM的优化问题上也被广泛采用，大多数优化库都可以使用它们。 2. 一阶和二阶梯度法求解增量最直观的方式是将目标函数在$x$附近进行泰勒展开： \|f(\boldsymbol{x}+\Delta \boldsymbol{x})\|_{2}^{2} \approx\|f(\boldsymbol{x})\|_{2}^{2}+\boldsymbol{J}(\boldsymbol{x}) \Delta \boldsymbol{x}+\frac{1}{2} \Delta \boldsymbol{x}^{T} \boldsymbol{H} \Delta \boldsymbol{x}]]></content>
      <categories>
        <category>Optimization</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[鲁棒性方法二：M-Estimation]]></title>
    <url>%2F2019%2F07%2F12%2F%E9%B2%81%E6%A3%92%E6%80%A7%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%9AM-Estimation%2F</url>
    <content type="text"><![CDATA[1. M-Estimation的引出$\quad$在代数方法与几何方法中，约束问题在形式上它们都是最小化下述函数： \sum_{j} r_{j}^{2}\left(\boldsymbol{x}_{j}, \boldsymbol{p}\right)$\quad$其中$p$为模型参数，$r_{i}\left(\boldsymbol{x}_{i}, \boldsymbol{p}\right)$是模型$\mathrm{M}_{p}$在数据点$\boldsymbol{x}_{i}$的残差(在代数方法中，$r_{i}\left(\boldsymbol{x}_{i}, \boldsymbol{p}\right)$是代数残差，即测量点到估计点的代数距离；在几何方法中，$r_{i}\left(\boldsymbol{x}_{i}, \boldsymbol{p}\right)$是几何残差，即测量点到估计点的几何距离) 。一旦测量数据中有外点 ( 错误数据点 ) ，这些方法是不鲁棒的，因为它们在最小化过程中将内点与外点不加区别而同等对待。$\quad$在M-估计方法中，用残差的函数代替残差。在形式上，M-估计方法是最小化下述函数: \sum_{j} \rho\left(r_{i}\left(\boldsymbol{x}_{i}, \boldsymbol{p}\right) ; \sigma\right)$\quad$在最小化过程中，函数$\rho(t, \sigma)$必须具有抑制外点的作用，使得外点对最小化几乎不起作用。这样的函数，我们称为M-估计子。 2. Huber估计子$\quad$Huber给出的估计子是： \rho(t ; \sigma)=\left\{\begin{array}{l}{t^{2},|t|]]></content>
      <categories>
        <category>Optimization</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
        <tag>Fundamental Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[鲁棒性方法一：RANSAC估计]]></title>
    <url>%2F2019%2F07%2F12%2F%E9%B2%81%E6%A3%92%E6%80%A7%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9ARANSAC%E4%BC%B0%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[1. 直线的RANSAC估计方法RANSAC(RANdom SAmple Consensus)方法是由Fischler和Bolles于1981年所引入的鲁棒方法。最初它被用于三点确定摄像机姿态的估计，现在无论在计算机视觉领域还是在其它学科的估计问题中都有广泛的应用。对于处理大比例的外点，RANSAC是十分有效的。我们先从直线估计的简单例子来说明RANSAC的基本思想。在几何上，鲁棒估计一条直线可描述为：给定一组二维测量数据点，寻找一条直线使得测量点到该直线的几何距离的平方和达到最小，即该直线最小化测量点到直线的几何距离平方和，并且使得内点偏离该直线的距离小于$t$个单位。因此，这个问题有两个要求: 用一条直线拟合测量数据点； 根据阈值 t 将测量数据分为内点与外点； 其中，阈值$t$是根据测量噪声而设置的，具体做法将在下文中讨论。 RANSAC直线拟合的思想是比较简单的，主要有以下几步： 随机选择两点(确定一条直线所需要的最小点集)；由这两个点确定一条线l； 根据阈值t，确定与直线 l 的几何距离小于 t 的数据点集S(l)，并称它为直线 l 的一致集； 重复若干次随机选择，得到直线l1,l2,l3,…,ln和相应的一致集S(1),S(2),S(3),…,S(n)； 使用几何距离，求最大一致集的最佳拟合直线，作为数据点的最佳匹配直线。 如果随机选择的两点中存在外点，则这两点所确定的直线一般不会有大的一致集，所以根据一致集的大小对所估计的直线进行评价有利于获取得更好的拟合直线，如图所示。正如Fischler和Bolles所指出：RANSAC与通常的数据最佳拟合技术相反，不是用尽可能多的数据点去获得模型的估计，而是用尽可能少的可行数据并尽量地扩大一致性数据集。 2. RANSAC一般估计方法根据上节估计直线的思想，对于一般模型$M$和给定的测量数据点集$D$，RANSAC估计模型参数$p$的一般步骤如下: 确定求解模型 M ，即确定模型参数 p ，所需要的最小数据点的个数 n 。由 n 个数据点组成的子集称为模型 M 的一个样本; 从数据点集 D 中随机地抽取一个样本 J由该样本计算模型的一个实例 M_p(J) ，确定与M_p(J) 之间几何距离 &lt; 阈值 t 的数据点所构成的集合，并记为 S(M_p(J)),称为实例M_p(J)的一致集; 如果在一致集 S(M_p(J))中数据点的个数#S(M_p(J)) &gt; 阈值 T, 则用 S(M_p(J))重新估计模型 M，并输出结果；如果#S(M_p(J)) &lt; 阈值 T，返回到步骤 2; 经过 K 次随机抽样,选择最大的一致集S(M_p(J)) ,用S(M_p(J)) 重新估计模型 M，并输出结果。 3. 抽样次数样本由从测量数据集中均匀随机抽取的子集所构成，每个样本所包含数据点的个数$n$是确定模型参数所需要数据点的最小数目。例如:直线最少需要两个数据点才能确定，即 $n = 2$；圆最少需要3 个数据点，即 $n = 3$ 。至于为什么要选择最小数目，下文将给出解释。为了陈述方便，称不包含外点的样本为好样本，否则称为坏样本。在执行 RANSAC 时，通常没有必要尝试每一种可能的抽样，实际上尝试每一种可能的抽样在计算上也是不可行的。只要选择足够多的抽样次数$K$，保证至少能得一个好样本就可以了。假定数据点集中含有内点的比例是$wE$，那么一个样本为好样本的概率$p=w^n$ 。于是，为了得到一个好样本需要抽样次数 K 的期望为： E(K)=1 \cdot p_{1}+2 \cdot p_{2}+3 \cdot p_{3}+\ldots其中, $p_j$为在$j$次抽样中得到一个好样本的概率，显然， p_{j}=\left(1-w^{n}\right)^{j-1} w^{n}因此， \begin{aligned} & E(K)=w^{n}+2\left(1-w^{n}\right) w^{n}+3\left(1-w^{n}\right)^{2} w^{n}+\ldots \\=& w^{n}\left(1+2\left(1-w^{n}\right)+3\left(1-w^{n}\right)^{2}+\ldots\right) \\=& w^{n}\left.\left(\frac{x}{1-x}\right)^{\prime}\right|_{x=1-w^{n}}=w^{-n} \end{aligned}所以，为了保证得到一个好样本，抽样次数$K$应大于$w^{-n}$。这很自然地联系到$K$的标准差$SD[K]$，即抽样次数$K=E[K]+S D[K]$，就能保证得到一个好样本。不难计算 S D[K]=\frac{\sqrt{1-w^{n}}}{w^{n}}因此， K=\frac{1+\sqrt{1-w^{n}}}{w^{n}}处理这个问题的另一种方法，是使得在K次抽样中所有样本均为坏样本的概率非常小，以保证获得一个好样本的概率非常大。记$z$为在$K$次抽样中所有样本均为坏样本的概率，则 z=\left(1-w^{n}\right)^{K}所以， K=\frac{\log z}{\log \left(1-w^{n}\right)}换句话说，在$K=\frac{\log z}{\log \left(1-w^{n}\right)}$抽样中得到一个好样本的概率为$1-z$。取$w = 0.45$( 内点的比例为 45%)，$z =0.02$( 以 0.98 的概率获得一个好样本 ) ，表 (17.1.1) 给出了样本所含数据点个数$n$与抽样次数$K$的一些对应值。可以看出，随$n$增加抽样次数$K$将急剧增加，因此所需要数据点总数也将急剧增加，这就是为什么在执行 RANSAC 时需要对模型进行最小参数化使得样本由尽可能少的数据组成的原因。值得说明的是，抽样次数$K$与外点的比例不是正相关的，抽样的计算代价即使在外点数目很大的时候也是可以被接受的。图 17.1.2 给出 $n = 5$ 时，抽样次数$K$与外点的比例$(1 − w )$之间的变化关系。 3. 距离阈值待补。。。 4. 终止阈值$\quad$终止阈值是难以设置的问题。经验的做法是：给出内点比例$w$的一个估计值$\varepsilon$，如果一致集大小相当于数据集的内点规模则终止。由于很难给出内点比例$w$的一个准确估计，所以经验做法往往不能获得较好的估计结果。由于终止阈值仅仅是用来终止 RANSAC 的抽样，所以通常的做法是:初始时，给出内点比例$w$的一个最保守的估计，然后在抽样过程中不断地修正它，并利用公式$K=\frac{\log z}{\log \left(1-w^{n}\right)}$估计为了得到一个好样本所需要的抽样次数$K$，一旦当前的抽样次数达到或超过这个估计值$K$时，就终止抽样，结束 RANSAC 的抽样过程。在初始时，抽样次数$K$的估计值可能是非常大的，但随着抽样过程对内点比例$w$的更新，抽样次数的估计值将迅速的减小。这种终止抽样的方法是自适应的，详尽的算法如下所述。 自适应算法(终止 RANSAC 抽样): 对内点比例作最保守估计w = w_0(如w_0 = 0.1，这意味着在数据点集中可能有90%的外点，这确实是一个保守估计)，应用公式（17.1.2），得到抽样次数K的初始值K_0； 抽样并更新w_0，K_0：令当前抽样的一致集所含数据点占整个数据点的比例为w，若w&gt;w_0，则更新 w_0 := w ，并且应用公式 (17.1.2) 更新抽样数 K_0 ；否则，保持原来的 w_0，K_0； 如果抽样次数已达到或超过 K_0，则终止抽样；否则，返回步骤 2。不难看出，抽样次数在更新过程中是单调下降的，所以抽样过程必终止。注意：自适应算法同时还保证了有足够多次抽样，是一种值得推荐的自适应算法。 5. 最终估计$\quad$RANSAC方法将数据分为内点(最大一致集)和外点(剩下的数据)两个不相交的子集，同时给出模型的估计$M_{p0}$，它由最大一致集所对应的样本计算出来。RANSAC 的最后一步是用所有的内点(最大一致集中的数据点)重新估计模型，该估计要涉及到代数方法或几何方法，最好使用几何方法(为了简化计算也可以应用 Sampson 几何近似)，它们需要迭代最小化，而$M_{p0}$可作为最小化的初始点。$\quad$这个过程的唯一缺点是内点与外点的分类变得不明确。这是因为将距离阈值应用于当前最大一致集所估计的$M_{p}$时，很可能有些点变为内点。解决这个问题的方法是：由内点得到模型估计$M_{p}$；由$M_{p}$应用(17.1.4)重新划分内点与外点；继续这个过程直至内点集收敛。最后,值得指出的是, RANSAC 方法被实践证明是一种非常有效的鲁棒性方法。在可能的情况下,建议读者使用这种方法。 6. 基本矩阵的 RANSAC 估计作为一个例子，将 RANSAC 用于基本矩阵的估计。我们只需要 定义样本; 给定样本，求该样本所对应的基本矩阵; 由最大一致集重新估计基本矩阵。 定义样本令$D=\left\{\boldsymbol{m}_{j} \leftrightarrow \boldsymbol{m}_{j}^{\prime} | 1 \leq j \leq n\right\}$是给定的两幅图像的点对应集。由于确定基本矩阵的最低限度需要7个点对应，所以定义点对应集$D$中的7个对应点构成的子集为一个样本，所有样本的集合简称为样本集。 求样本$k$所对应的基本矩阵$F_k$由于样本$k$中仅有7个点对应，根据基本矩阵的7-点算法，可能得到基本矩阵的3个解$F_{k}^{(1)}, F_{k}^{(2)}, F_{k}^{(3)}$，将一致集最大的解作为该次抽样的基本矩阵。具体方法如下：根据下述公式计算$F_{k}^{(1)}, F_{k}^{(2)}, F_{k}^{(3)}$的一致集： S\left(F_{k}^{(j)}\right)=\left\{\left(m \leftrightarrow m^{\prime}\right) \in D | d^{2}\left(m^{\prime}, F_{k}^{(j)} m\right)+d^{2}\left(m,\left(F_{k}^{(j)}\right)^{T} m^{\prime}\right)]]></content>
      <categories>
        <category>Optimization</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
        <tag>Fundamental Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IMU预积分二：残差及其Jacobian]]></title>
    <url>%2F2019%2F07%2F08%2FIMU%E9%A2%84%E7%A7%AF%E5%88%86%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[1. bias更新时的预积分测量值更新在第一篇的介绍当中，都是在假设积分区间内陀螺和加计的bias恒定的基础上推导的。当bias发生变化时，若按照前述公式，预积分测量值需要重新计算一遍，这将非常的computational expensive。为了解决这个问题，提出了利用线性化来进行bias变化时预积分项的一阶近似更新方法。下面先给出各更新公式，然后再做推导。令$\overline{\mathbf{b}}_{i}^{g}$和$\overline{\mathbf{b}}_{i}^{a}$为旧的bias，新的bias（$\hat{\mathbf{b}}_{i}^{g}$和$\hat{\mathbf{b}}_{i}^{a}$）由旧的bias与更新量（$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$）相加得到，即$\hat{\mathbf{b}}_{i}^{g} \leftarrow \overline{\mathbf{b}}_{i}^{g}+\delta \mathbf{b}_{i}^{g}$、$\hat{\mathbf{b}}_{i}^{a} \leftarrow \overline{\mathbf{b}}_{i}^{a}+\delta \mathbf{b}_{i}^{a}$。于是有预积分关于bias估计值的一阶近似更新公式如下： \begin{array}{l} \Delta \tilde{\mathbf{R}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}\right) \approx \Delta \tilde{\mathbf{R}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}\right) \cdot \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)\\[2ex] {\Delta \tilde{\mathbf{v}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right) \approx \Delta \tilde{\mathbf{v}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}, \overline{\mathbf{b}}_{i}^{a}\right)+\frac{\partial \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}} \\[2ex] {\Delta \tilde{\mathbf{p}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right) \approx \Delta \tilde{\mathbf{p}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}, \overline{\mathbf{b}}_{i}^{a}\right)+\frac{\partial \Delta \overline{\boldsymbol{p}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}}\end{array}做符号化简如下： \begin{array}{l}{\Delta \hat{\mathbf{R}}_{i j} \triangleq \Delta \tilde{\mathbf{R}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}\right), \Delta \overline{\mathbf{R}}_{i j} \triangleq \Delta \tilde{\mathbf{R}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}\right)} \\[2ex] {\Delta \hat{\mathbf{v}}_{i j} \triangleq \Delta \tilde{\mathbf{v}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right), \Delta \overline{\mathbf{v}}_{i j} \triangleq \Delta \tilde{\mathbf{v}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}, \overline{\mathbf{b}}_{i}^{a}\right)} \\[2ex] {\Delta \hat{\mathbf{p}}_{i j} \triangleq \Delta \tilde{\mathbf{p}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right), \Delta \overline{\mathbf{p}}_{i j}=\Delta \tilde{\mathbf{p}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}, \overline{\mathbf{b}}_{i}^{a}\right)}\end{array}于是前面的更新公式可简化为： \begin{array}{l} {\Delta \hat{\mathbf{R}}_{i j} \approx \Delta \overline{\mathbf{R}}_{i j} \cdot \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)} \\[2ex] {\Delta \hat{\mathbf{v}}_{i j} \approx \Delta \overline{\mathbf{v}}_{i j}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}} \\[2ex] {\Delta \hat{\mathbf{p}}_{i j} \approx \Delta \overline{\mathbf{p}}_{i j}+\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}}\end{array}接下来推导各式中的偏导项。 （1）${\Delta \hat{\mathbf{R}}_{i j} \approx \Delta \overline{\mathbf{R}}_{i j} \cdot \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)}$中的偏导项$\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}$ \begin{aligned} \Delta \hat{\mathbf{R}}_{i j} &=\Delta \tilde{\mathbf{R}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}\right) \\[2ex] &=\prod_{k=1}^{j-1} \operatorname{Exp}\left(\left(\tilde{\boldsymbol{\omega}}_{k}-\hat{\mathbf{b}}_{i}^{g}\right) \Delta t\right) \\[2ex] &=\prod_{k=1}^{j-1} \operatorname{Exp}\left(\left(\tilde{\mathbf{\omega}}_{k}-\left(\overline{\mathbf{b}}_{i}^{g}+\delta \mathbf{b}_{i}^{g}\right)\right) \Delta t\right) \\[2ex] &=\prod_{k=i}^{j-1} \operatorname{Exp}\left(\left(\tilde{\mathbf{\omega}}_{k}-\overline{\mathbf{b}}_{i}^{g}\right) \Delta t-\delta \mathbf{b}_{i}^{g} \Delta t\right)\\[2ex] &\approx \prod_{k=i}^{j-1}\left(\operatorname{Exp}\left(\left(\tilde{\mathbf{\omega}}_{k}-\overline{\mathbf{b}}_{i}^{g}\right) \Delta t\right) \cdot \operatorname{Exp}\left(-\mathbf{J}_{r}^{k} \delta \mathbf{b}_{i}^{g} \Delta t\right)\right) \\[2ex] &=\Delta \overline{\mathbf{R}}_{i j} \prod_{k=i}^{j-1} \operatorname{Exp}\left(-\Delta \overline{\mathbf{R}}_{k+1 j}^{T} \mathbf{J}_{r}^{k} \delta \mathbf{b}_{i}^{g} \Delta t\right) \end{aligned}于是 \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}}=\sum_{k=i}^{j-1}\left(-\Delta \overline{\mathbf{R}}_{k+1 j}^{T} \mathbf{J}_{r}^{k} \Delta t\right)其中 \mathbf{J}_{r}^{k}=\mathbf{J}_{r}\left(\left(\tilde{\boldsymbol{\omega}}_{k}-\mathbf{b}_{i}^{g}\right) \Delta t\right) （2）${\Delta \hat{\mathbf{v}}_{i j} \approx \Delta \overline{\mathbf{v}}_{i j}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}}$中的偏导项$\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{g}}$和$\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{a}}$： \begin{aligned} \Delta \hat{\mathbf{v}}_{i j} &=\Delta \tilde{\mathbf{v}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g},\hat{\mathbf{b}}_{i}^{a}\right) \\[2ex] &=\sum_{k=i}^{j-1}\left[\Delta \tilde{\mathbf{R}}_{i k}\left(\hat{\mathbf{b}}_{i}^{g}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\hat{\mathbf{b}}_{i}^{a}\right) \Delta t\right] \\[2ex] &\approx \sum_{k=i}^{j-1}\left[\Delta \overline{\mathbf{R}}_{i k} \cdot \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}-\delta \mathbf{b}_{i}^{a}\right) \Delta t\right]\\[2ex] &\approx \sum_{k=i}^{j-1}\left[\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\mathbf{I}+\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)^{\wedge}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}-\delta \mathbf{b}_{i}^{a}\right) \Delta t\right]\\[2ex] &\begin{aligned}=\sum_{k=i}^{j-1} &\left[\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right) \Delta t-\Delta \overline{\mathbf{R}}_{i k} \delta \mathbf{b}_{i}^{a} \Delta t\right.\\[2ex] &+\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)^{\wedge}\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right) \Delta t \\[2ex] &\left. -\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)^{\wedge} \delta \mathbf{b}_{i}^{a} \Delta t \right] \end{aligned}\\[2ex] &\approx \Delta \overline{\mathbf{v}}_{i j}+\sum_{k=i}^{j-1}\left\{-\left[\Delta \overline{\mathbf{R}}_{i k} \Delta t\right] \delta \mathbf{b}_{i}^{a}-\left[\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t\right] \delta \mathbf{b}_{i}^{g}\right\}\\[2ex] &= \Delta \overline{\mathbf{v}}_{i j}-\sum_{k=i}^{j-1} \Delta \overline{\mathbf{R}}_{i k} \Delta t \delta \mathbf{b}_{i}^{a}-\sum_{k=i}^{j-1} \Delta \overline{\mathbf{R}}_{i k}\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \mathbf{b}^{g}} \Delta t \delta \mathbf{b}_{i}^{g}\\[2ex] &=\Delta \overline{\mathbf{v}}_{i j}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \mathbf{b}^{a}} \delta \mathbf{b}_{i}^{a}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \mathbf{b}^{g}} \delta \mathbf{b}_{i}^{g} \end{aligned}所以有： \begin{aligned} \frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{\overline{g}}} &=-\sum_{k=1}^{j-1}\left(\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t\right) \\ \frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} &=-\sum_{k=1}^{j-1}\left(\Delta \overline{\mathbf{R}}_{i k} \Delta t\right) \end{aligned} （3）$\Delta \hat{\mathbf{p}}_{i j} \approx \Delta \overline{\mathbf{p}}_{i j}+\frac{\partial \Delta \mathbf{p}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \mathbf{p}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}$中的偏导项$\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{g}}$和$\frac{\partial \Delta \overline{\mathbf{p}}_{j}}{\partial \overline{\mathbf{b}}^{a}}$： \begin{aligned} \Delta \hat{\mathbf{p}}_{i j} &=\Delta \tilde{\mathbf{p}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right) \\[2ex] &=\sum_{k=1}^{j-1}\left[\Delta \tilde{\mathbf{v}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right) \Delta t+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k}\left(\hat{\mathbf{b}}_{i}^{g}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\hat{\mathbf{b}}_{i}^{a}\right) \Delta t^{2}\right]\\[2ex] &=\sum_{k=i}^{j-1}\left[\Delta \tilde{\mathbf{v}}_{i j}\left(\hat{\mathbf{b}}_{i}^{g}, \hat{\mathbf{b}}_{i}^{a}\right) \Delta t\right]+\frac{1}{2} \sum_{k=i}^{j-1}\left[\Delta \tilde{\mathbf{R}}_{i k}\left(\hat{\mathbf{b}}_{i}^{g}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\hat{\mathbf{b}}_{i}^{a}\right) \Delta t^{2}\right] \\[2ex] &=\sum_{k=i}^{j-1}\left[\left(\Delta \overline{\mathbf{v}}_{i k}+\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}\right) \Delta t\right] + \frac{\Delta t^{2}}{2} \sum_{k=i}^{j-1}\left[\Delta \tilde{\mathbf{R}}_{i k}\left(\hat{\mathbf{b}}_{i}^{g}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\hat{\mathbf{b}}_{i}^{a}\right)\right] \\[2ex] &=\sum_{k=1}^{j-1}\left[\Delta \overline{\mathbf{v}}_{i k} \Delta t+\left(\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t\right) \delta \mathbf{b}_{i}^{g}+\left(\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \Delta t\right) \delta \mathbf{b}_{i}^{a}\right]\\[2ex] &\quad +\frac{\Delta t^{2}}{2} \sum_{k=i}^{j-1}\left[\Delta \overline{\mathbf{R}}_{i k} \cdot \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}-\delta \mathbf{b}_{i}^{a}\right)\right] \\[2ex] &=\sum_{k=1}^{j-1}\left[\Delta \overline{\mathbf{v}}_{i k} \Delta t+\left(\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t\right) \delta \mathbf{b}_{i}^{g}+\left(\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \Delta t\right) \delta \mathbf{b}_{i}^{a}\right]\\[2ex] &\quad +\frac{\Delta t^{2}}{2} \sum_{k=i}^{j-1}\left[\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\mathbf{I}+\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)^{\wedge}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}-\delta \mathbf{b}_{i}^{a}\right)\right] \\[2ex] &=\sum_{k=1}^{j-1}\left[\Delta \overline{\mathbf{v}}_{i k} \Delta t+\left(\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t\right) \delta \mathbf{b}_{i}^{g}+\left(\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \Delta t\right) \delta \mathbf{b}_{i}^{a}\right]\\[2ex] &\quad +\frac{\Delta t^{2}}{2} \sum_{k=i}^{j-1}\left[\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)-\Delta \overline{\mathbf{R}}_{i k} \delta \mathbf{b}_{i}^{a}-\Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right] \\[2ex] &=\sum_{k=i}^{j-1}\left\{\left[\Delta \overline{\mathbf{v}}_{i k} \Delta t+\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right) \Delta t^{2}\right]\right.\\[2ex] &\quad+\left[\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t-\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t^{2}\right] \delta \mathbf{b}_{i}^{g} \\[2ex] &\quad+ \left. \left[\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \Delta t-\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \Delta t^{2}\right] \delta \mathbf{b}_{i}^{a} \right\} \\[2ex] &=\Delta \overline{\mathbf{p}}_{i j} \\[2ex] &\quad+\left\{\sum_{k=i}^{j-1}\left[\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t-\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t^{2}\right]\right\} \delta \mathbf{b}_{i}^{g}\\[2ex] &\quad+ \left\{\sum_{k=i}^{j-1}\left[\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \Delta t-\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \Delta t^{2}\right]\right\} \delta \mathbf{b}_{i}^{a}\\[2ex] \end{aligned}所以有： \begin{aligned} \frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} &=\sum_{k=i}^{j-1}\left[\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t-\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\overline{\mathbf{b}}_{i}^{a}\right)^{\wedge} \frac{\partial \Delta \overline{\mathbf{R}}_{i k}}{\partial \overline{\mathbf{b}}^{g}} \Delta t^{2}\right] \\[2ex] \frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} &=\sum_{k=i}^{j-1}\left[\frac{\partial \Delta \overline{\mathbf{v}}_{i k}}{\partial \overline{\mathbf{b}}^{a}} \Delta t-\frac{1}{2} \Delta \overline{\mathbf{R}}_{i k} \Delta t^{2}\right] \end{aligned} 2. 残差残差指的是预积分计算值（由非IMU的其他方式估计的预积分值）与测量值的差距。根据各预积分的定义，可得 $\Delta \mathbf{R}_{i j}$、$\Delta \mathbf{v}_{i j}$ 和 $\Delta \mathbf{p}_{i j}$ 的理想值表达式如下： \begin{array}{l}{\Delta \mathbf{R}_{i j}=\mathbf{R}_{i}^{T} \mathbf{R}_{j}} \\[2ex] {\Delta \mathbf{v}_{i j}=\mathbf{R}_{i}^{T}\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)} \\[2ex] {\Delta \mathbf{p}_{i j}=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)}\end{array}则有三项残差项如下： \begin{array}{l} \begin{aligned} \mathbf{r}_{\Delta \mathbf{R}_{i j}} & \triangleq \log \left\{\left[\Delta \tilde{\mathbf{R}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}\right) \cdot \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)\right]^{T} \cdot \mathbf{R}_{i}^{T} \mathbf{R}_{j}\right\} \\[2ex] & \triangleq \log \left[\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T} \Delta \mathbf{R}_{i j}\right] \end{aligned} \\[2ex] \begin{aligned} \mathbf{r}_{\Delta \mathbf{v}_{i j}} \triangleq & \mathbf{R}_{i}^{T}\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right) \\[2ex] &-\left[\Delta \tilde{\mathbf{v}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}, \overline{\mathbf{b}}_{i}^{a}\right)+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}\right] \\[2ex] \triangleq & \Delta \mathbf{v}_{i j}-\Delta \hat{\mathbf{v}}_{i j} \end{aligned} \\[2ex] \begin{aligned} \mathbf{r}_{\Delta \mathbf{p}_{i j}} \triangleq & \mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right) \\[2ex] &-\left[\Delta \tilde{\mathbf{p}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}, \overline{\mathbf{b}}_{i}^{a}\right)+\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}+\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \overline{\mathbf{b}}^{a}} \delta \mathbf{b}_{i}^{a}\right]\\[2ex] \triangleq &\Delta \mathbf{p}_{i j}-\Delta \hat{\mathbf{p}}_{i j} \end{aligned} \end{array}在状态估计中，通常以等为导航求解的目标，同时由于bias的作用在以mems器件为基础的应用中不可忽略，因此bias 也常常被当做是状态量进行估计，但估计中经常采取的是估计bias的偏差的方式，即估计$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$，所以，全部的导航状态应该是$\mathbf{R}_{i}, \mathbf{p}_{i}, \mathbf{v}_{i}, \mathbf{R}_{j}, \mathbf{p}_{j}, \mathbf{v}_{j}, \delta \mathbf{b}_{i}^{g}, \delta \mathbf{b}_{i}^{a}$。在非线性最小二乘计算过程中，通常需要“增量”来更新状态，最终计算指标（一般即残差$\mathbf{r}_{\Delta \mathbf{R}_{i j}}$、$\mathbf{r}_{\Delta \mathbf{v}_{i j}}$和$\mathbf{r}_{\Delta \mathbf{p}_{i j}}$），这个过程叫做“lifting”，对于上述的导航状态，需要进行如下的“lifting”操作： \begin{array}{l}{\mathbf{R}_{i} \leftarrow \mathbf{R}_{i} \cdot \operatorname{Exp}\left(\delta \vec{\phi}_{i}\right) ; \mathbf{p}_{i} \leftarrow \mathbf{p}_{i}+\mathbf{R}_{i} \cdot \delta \mathbf{p}_{i} ; \mathbf{v}_{i} \leftarrow \mathbf{v}_{i}+\delta \mathbf{v}_{i}} \\ {\mathbf{R}_{j} \leftarrow \mathbf{R}_{j} \cdot \operatorname{Exp}\left(\delta \vec{\phi}_{j}\right) ; \mathbf{p}_{j} \leftarrow \mathbf{p}_{j}+\mathbf{R}_{j} \cdot \delta \mathbf{p}_{j} ; \mathbf{v}_{j} \leftarrow \mathbf{v}_{j}+\delta \mathbf{v}_{j}} \\ {\delta \mathbf{b}_{i}^{g} \leftarrow \delta \mathbf{b}_{i}^{g}+\widetilde{\delta \mathbf{b}_{i}^{g}} ; \delta \mathbf{b}_{i}^{a} \leftarrow \delta \mathbf{b}_{i}^{a}+\widetilde{\delta \mathbf{b}_{i}^{a}}}\end{array}下面开始求各残差项关于各状态增量的Jacobian。 3. 残差的Jacobian （1）Jacobian of $\mathbf{r}_{\Delta \mathbf{R}_{i j}}$零项：$\mathbf{r}_{\Delta \mathbf{R}_{i j}}$不含有变量$\mathbf{p}_{i}, \mathbf{p}_{j}, \mathbf{v}_{i}, \mathbf{v}_{j}$以及$\delta \mathbf{b}_{i}^{a}$，因此$\mathbf{r}_{\Delta \mathbf{R}_{i j}}$关于这些状态的增量的Jacobian都为0（零矩阵）： \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial \mathbf{p}_{i}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial \mathbf{p}_{j}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial \mathbf{v}_{i}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial \mathbf{v}_{j}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial {\delta} \mathbf{b}_{i}^{a}}=\mathbf{0}无线性项：复杂项：对于$\phi_i$： \begin{aligned} \mathbf{r}_{\Delta \mathbf{R}_{i j}}\left(\mathbf{R}_{i} \operatorname{Exp}\left(\delta {\phi}_{i}\right)\right)& = \log \left[\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T}\left(\mathbf{R}_{i} \operatorname{Exp}\left(\delta {\phi}_{i}\right)\right)^{T} \mathbf{R}_{j}\right]\\[2ex] &=\log \left[\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T} \operatorname{Exp}\left(-\delta {\phi}_{i}\right) \mathbf{R}_{i}^{T} \mathbf{R}_{j}\right]\\[2ex] &=\log \left[\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T} \mathbf{R}_{i}^{T} \mathbf{R}_{j} \operatorname{Exp}\left(-\mathbf{R}_{j}^{T} \mathbf{R}_{i} \delta {\phi}_{i}\right)\right]\\[2ex] &=\log \left\{\operatorname{Exp}\left[\log \left(\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T} \mathbf{R}_{i}^{T} \mathbf{R}_{j}\right)\right] \cdot \operatorname{Exp}\left(\mathbf{-} \mathbf{R}_{j}^{T} \mathbf{R}_{i} \delta {\phi}_{i}\right)\right\}\\[2ex] &=\log \left[\operatorname{Exp}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\left(\mathbf{R}_{i}\right)\right) \cdot \operatorname{Exp}\left(-\mathbf{R}_{j}^{T} \mathbf{R}_{i} \delta {\phi}_{i}\right)\right]\\[2ex] &\approx \mathbf{r}_{\Delta R_{i j}}\left(\mathbf{R}_{i}\right)-\mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\left(\mathbf{R}_{i}\right)\right) \mathbf{R}_{j}^{T} \mathbf{R}_{i} \delta {\phi}_{i}\\[2ex] &=\mathbf{r}_{\Delta \mathbf{R}_{i j}}-\mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\right) \mathbf{R}_{j}^{T} \mathbf{R}_{i} \delta {\phi}_{i} \end{aligned}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial {\phi}_{i}}=-\mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\right) \mathbf{R}_{j}^{T} \mathbf{R}_{i}对于$\phi_j$： \begin{array}{l}{\mathbf{r}_{\Delta \mathbf{R}_{i j}}\left(\mathbf{R}_{j} \operatorname{Exp}\left(\delta {\phi}_{j}\right)\right)} \\[2ex] {=\log \left[\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T} \mathbf{R}_{i}^{T} \mathbf{R}_{j} \operatorname{Exp}\left(\delta {\phi}_{j}\right)\right]} \\[2ex] {=\log \left\{\operatorname{Exp}\left[\log \left(\left(\Delta \hat{\mathbf{R}}_{i j}\right)^{T} \mathbf{R}_{i}^{T} \mathbf{R}_{j}\right)\right] \cdot \operatorname{Exp}\left(\delta {\phi}_{j}\right)\right\}}\\[2ex] =\mathbf{r}_{\Delta \mathbf{R}_{i j}}\left(\mathbf{R}_{j}\right)+\mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\left(\mathbf{R}_{j}\right)\right) \delta {\phi}_{j}\\[2ex] =\mathbf{r}_{\Delta \mathbf{R}_{i j}}+\mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\right) \delta {\phi}_{j} \end{array}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial \delta {\phi}_{j}}=\mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\right)对于$\delta b^g_i$： \begin{array}{l} \mathbf{r}_{\Delta R_{i j}}\left(\delta \mathbf{b}_{i}^{g}+\widetilde{\delta \mathbf{b}_{i}^{g}}\right)\\[2ex] =\log \left\{\left[\Delta \tilde{\mathbf{R}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}\right) \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}}\left(\delta \mathbf{b}_{i}^{g}+\widetilde{\delta \mathbf{b}_{i}^{g}}\right)\right)\right]^{T} \mathbf{R}_{i}^{T} \mathbf{R}_{j}\right\}\\[2ex] =\log \left\{ \left[\Delta \tilde{\mathbf{R}}_{i j}\left(\overline{\mathbf{b}}_{i}^{g}\right) \operatorname{Exp}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right)\operatorname{Exp}\left(\mathbf{J}_{r}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right) \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\right)\right]^{T}\Delta \mathbf{R}_{i j}\right\}\\[2ex] =\log\left\{\left[\Delta \hat{\mathbf{R}}_{i j}\operatorname{Exp}\left(\varepsilon \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\right)\right]^T\Delta \mathbf{R}_{i j}\right\} \\[2ex] =\log\left[ \operatorname{Exp}\left(- \varepsilon \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\right) \Delta \hat{\mathbf{R}}_{i j}^T \Delta \mathbf{R}_{i j}\right]\\[2ex] =\log\left[ \operatorname{Exp}\left(- \varepsilon \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\right) \operatorname{Exp}\left(\log\left(\Delta \hat{\mathbf{R}}_{i j}^T \Delta \mathbf{R}_{i j}\right)\right)\right]\\[2ex] =\log\left[ \operatorname{Exp}\left(- \varepsilon \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\right) \operatorname{Exp}\left( \mathbf{r}_{\Delta \mathbf{R}_{i j}} \left( \delta \mathbf{b}_{i}^{g}\right)\right)\right]\\[2ex] =\log\left[ \operatorname{Exp}\left( \mathbf{r}_{\Delta \mathbf{R}_{i j}} \left( \delta \mathbf{b}_{i}^{g}\right)\right)\operatorname{Exp}\left(- \operatorname{Exp}\left( \mathbf{r}_{\Delta \mathbf{R}_{i j}} \left( \delta \mathbf{b}_{i}^{g}\right)\right)\varepsilon \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\right)\right]\\[2ex] \approx \mathbf{r}_{\Delta \mathbf{R}_{i j}} \left( \delta \mathbf{b}_{i}^{g}\right) - \mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\left( \delta \mathbf{b}_{i}^{g} \right)\right)\operatorname{Exp}\left(- \mathbf{r}_{\Delta \mathbf{R}_{i j}} \left( \delta \mathbf{b}_{i}^{g}\right)\right)\varepsilon \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\\[2ex] = \mathbf{r}_{\Delta \mathbf{R}_{i j}} - \mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\right)\operatorname{Exp}\left(- \mathbf{r}_{\Delta \mathbf{R}_{i j}}\right)\mathbf{J}_{r}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right) \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \widetilde{\delta \mathbf{b}_{i}^{g}}\\[2ex] \end{array}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{R}_{i j}}}{\partial \delta {b}_{i}^g}=- \mathbf{J}_{r}^{-1}\left(\mathbf{r}_{\Delta \mathbf{R}_{i j}}\right)\operatorname{Exp}\left(- \mathbf{r}_{\Delta \mathbf{R}_{i j}}\right)\mathbf{J}_{r}\left(\frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} \delta \mathbf{b}_{i}^{g}\right) \frac{\partial \Delta \overline{\mathbf{R}}_{i j}}{\partial \overline{\mathbf{b}}^{g}} （2）Jacobian of $\mathbf{r}_{\Delta \mathbf{v}_{i j}}$零项：$\mathbf{r}_{\Delta \mathbf{v}_{i j}}$不含有变量$\mathbf{R}_{j}, \mathbf{p}_{i}, \mathbf{p}_{j}$，因此$\mathbf{r}_{\Delta \mathbf{v}_{i j}}$，关于这些状态的增量的Jacobian都为0（零矩阵）： \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial \mathbf{p}_{i}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial \mathbf{p}_{j}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial \mathbf{\phi}_{i}}=\mathbf{0}线性项：$\mathbf{r}_{\Delta \mathbf{v}_{i j}}$关于$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$是线性的，$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$的lifting也是线性的，因此$\mathbf{r}_{\Delta \mathbf{v}_{i j}}$关于$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$的增量的Jacobian可直接由线性系数求得： \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial {\delta \mathbf{b}_{i}^{g}}}=-\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \mathbf{b}^{g}},\frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial {\delta \mathbf{b}_{i}^{a}}}=-\frac{\partial \Delta \overline{\mathbf{v}}_{i j}}{\partial \mathbf{b}^{a}},复杂项：对于$\delta \mathbf{v}_{i}$的jacobian： \begin{aligned} \mathbf{r}_{\Delta \mathbf{v}_{i j}}\left(\mathbf{v}_{i}+\delta \mathbf{v}_{i}\right) &=\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\delta \mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j} \\ &=\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j}-\mathbf{R}_{i}^{T} \delta \mathbf{v}_{i} \\ &=\mathbf{r}_{\Delta \mathbf{v}_{i j}}\left(\mathbf{v}_{i}\right)-\mathbf{R}_{i}^{T} \delta \mathbf{v}_{i} \end{aligned}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial \delta \mathbf{v}_{i}}=-\mathbf{R}_{i}^{T}对于$\delta \mathbf{v}_{j}$的jacobian： \begin{aligned} \mathbf{r}_{\Delta \mathbf{v}_{i j}}\left(\mathbf{v}_{j}+\delta \mathbf{v}_{j}\right) &=\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}+\delta \mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j} \\ &=\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j}+\mathbf{R}_{i}^{T} \delta \mathbf{v}_{j} \\ &=\mathbf{r}_{\Delta \mathbf{v}_{i j}}\left(\mathbf{v}_{j}\right)+\mathbf{R}_{i}^{T} \delta \mathbf{v}_{j} \end{aligned}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial \delta \mathbf{v}_{j}}=\mathbf{R}_{i}^{T}对于$\delta \phi_i$的Jacobian： \begin{aligned} \mathbf{r}_{\Delta \mathbf{v}_{i j}}\left(\mathbf{R}_{i} \operatorname{Exp}\left(\delta {\phi}_{i}\right)\right) &= \left(\mathbf{R}_{i} \operatorname{Exp}\left(\delta {\phi}_{i}\right)\right)^{T}\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j} \\[2ex] &= \operatorname{Exp}\left(-\delta {\phi}_{i}\right) \cdot \mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j}\\[2ex] &\approx \left(\mathbf{I}-\left(\delta {\phi}_{i}\right)^{\wedge}\right) \cdot \mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j}\\[2ex] &=\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)-\Delta \hat{\mathbf{v}}_{i j}-\left(\delta {\phi}_{i}\right)^{\wedge} \cdot \mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)\\[2ex] &=\mathbf{r}_{\Delta \mathbf{v}_{i j}}\left(\mathbf{R}_{i}\right)+\left[\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)\right]^{\wedge} \cdot \delta {\phi}_{i}\\[2ex] &=\mathbf{r}_{\Delta \mathbf{v}_{i j}}+\left[\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)\right]^{\wedge} \cdot \delta {\phi}_{i} \end{aligned}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{v}_{i j}}}{\partial \delta \phi_i}=\left[\mathbf{R}_{i}^{T} \cdot\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)\right]^{\wedge} （3）Jacobian of $\mathbf{r}_{\Delta \mathbf{p}_{i j}}$零项：$\mathbf{r}_{\Delta \mathbf{p}_{i j}}$不含有变量$\mathbf{R}_{j}, \mathbf{v}_{j}$，因此$\mathbf{r}_{\Delta \mathbf{p}_{i j}}$关于这些状态的增量的Jacobian都为0（零矩阵）： \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial \mathbf{\phi}_{j}}=\mathbf{0}, \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial \mathbf{v}_{j}}=\mathbf{0},线性项：$\mathbf{r}_{\Delta \mathbf{p}_{i j}}$关于$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$是线性的，$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$的lifting也是线性的，因此$\mathbf{r}_{\Delta \mathbf{p}_{i j}}$关于$\delta \mathbf{b}_{i}^{g}$和$\delta \mathbf{b}_{i}^{a}$的增量的Jacobian可直接由线性系数求得： \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial {\delta \mathbf{b}_{i}^{g}}}=-\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \mathbf{b}^{g}},\frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial {\delta \mathbf{b}_{i}^{a}}}=-\frac{\partial \Delta \overline{\mathbf{p}}_{i j}}{\partial \mathbf{b}^{a}},复杂项：对于$\delta \mathbf{p}_{i}$的jacobian： \begin{array}{l}{\mathbf{r}_{\Delta \mathbf{p}_{i j}}\left(\mathbf{p}_{i}+\mathbf{R}_{i} \cdot \delta \mathbf{p}_{i}\right)} \\[2ex] {=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{R}_{i} \cdot \delta \mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}} \\[2ex] {=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}-\mathbf{I} \cdot \delta \mathbf{p}_{i}} \\[2ex] {=\mathbf{r}_{\Delta \mathbf{p}_{i j}}\left(\mathbf{p}_{i}\right)-\mathbf{I} \cdot \delta \mathbf{p}_{i}}\\[2ex] =\mathbf{r}_{\Delta p_{i j}}-\mathbf{I} \cdot \delta \mathbf{p}_{i} \end{array}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial \mathbf{p}_{i}}=-\mathbf{I}对于$\delta \mathbf{p}_{j}$的jacobian： \begin{array}{l}{\mathbf{r}_{\Delta \mathrm{p}_{i j}}\left(\mathbf{p}_{j}+\mathbf{R}_{j} \cdot \delta \mathbf{p}_{j}\right)} \\[2ex] {=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}+\mathbf{R}_{j} \cdot \delta \mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}} \\[2ex] {=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}+\mathbf{R}_{i}^{T} \mathbf{R}_{j} \cdot \delta \mathbf{p}_{j}} \\[2ex] {=\mathbf{r}_{\Delta \mathrm{p}_{i j}}\left(\mathbf{p}_{j}\right)+\mathbf{R}_{i}^{T} \mathbf{R}_{j} \cdot \delta \mathbf{p}_{j}}\end{array}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial \mathbf{p}_{j}}=\mathbf{R}_{i}^{T} \mathbf{R}_{j}对于$\delta \mathbf{v}_{i}$的jacobian： \begin{array}{l}{\mathbf{r}_{\Delta \mathbf{p}_{i j}}\left(\mathbf{v}_{i}+\delta \mathbf{v}_{i}\right)} \\[2ex] {=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\delta \mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}} \\[2ex] {=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}-\mathbf{R}_{i}^{T} \Delta t_{i j} \cdot \delta \mathbf{v}_{i}} \\[2ex] {=\mathbf{r}_{\Delta \mathbf{p}_{i j}}\left(\mathbf{v}_{i}\right)-\mathbf{R}_{i}^{T} \Delta t_{i j} \cdot \delta \mathbf{v}_{i}}\\[2ex] =\mathbf{r}_{\Delta \mathbf{p}_{i j}}-\mathbf{R}_{i}^{T} \Delta t_{i j} \cdot \delta \mathbf{v}_{i} \end{array}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial \mathbf{v}_{i}}=-\mathbf{R}_{i}^{T} \Delta t_{i j}对于$\delta \mathbf{\phi}_{i}$的jacobian： \begin{array}{l}{\mathbf{r}_{\Delta \mathbf{p}_{i j}}\left(\mathbf{R}_{i} \operatorname{Exp}\left(\delta {\phi}_{i}\right)\right)} \\[2ex] =\left(\mathbf{R}_{i} \operatorname{Exp}\left(\delta {\phi}_{i}\right)\right)^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}\\[2ex] =\operatorname{Exp}\left(-\delta {\phi}_{i}\right) \cdot \mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j} \\[2ex] =\left(\mathbf{I}-\left(\delta {\phi}_{i}\right)^{\wedge}\right) \cdot \mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j}\\[2ex] \begin{aligned}=& \mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)-\Delta \hat{\mathbf{p}}_{i j} \\ &-\left(\delta {\phi}_{i}\right)^{\wedge} \mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right) \end{aligned}\\[2ex] =\mathbf{r}_{\Delta \mathbf{p}_{i j}}\left(\mathbf{R}_{i}\right)+\left[\mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)\right]^{\wedge} \cdot \delta {\phi}_{i}\\[2ex] =\mathbf{r}_{\Delta \mathbf{p}_{i j}}+\left[\mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta_{i j}^{2}\right)\right]^{\wedge} \cdot \delta {\phi}_{i} \end{array}所以有： \frac{\partial \mathbf{r}_{\Delta \mathbf{p}_{i j}}}{\partial \delta \mathbf{\phi}_{i}}=\left[\mathbf{R}_{i}^{T} \cdot\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)\right]^{\wedge}]]></content>
      <categories>
        <category>IMU</category>
      </categories>
      <tags>
        <tag>Camera</tag>
        <tag>IMU</tag>
        <tag>Preintegration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IMU预积分一：基本原理和白噪声]]></title>
    <url>%2F2019%2F07%2F01%2FIMU%E9%A2%84%E7%A7%AF%E5%88%86%E4%B8%80%2F</url>
    <content type="text"><![CDATA[1. IMU 测量模型（Sensor Model）和运动学模型（Kinetic Model）一个IMU惯导测量装置包括3个轴的加速度测量仪和三个轴的角速度测量仪，在VIO系统中，世界坐标系通常认为是一个惯性系，且一般会选择初始时刻水平地理系。由于SLAM的运行场景一般较小（重力变化不大），运行时间也不会太长，且使用的IMU器件一般为mems器件（精度低，陀螺仪静置时无法敏感地感知地球自转）。因此不会像传统的捷联INS解算中，考虑地球自转、根据位置更新重力矢量等，常常忽略地球自转（认为地球是个static world），并假设运行区域水平面是平面，重力矢量$\sideset{_w}{}{g}$的指向固定且模值恒定. 陀螺测量模型： \sideset { _b}{_{wb}} {\tilde{\omega}} (t)= \sideset { _b}{_{wb}}{\omega}(t) + b^g(t)+ \eta^g(t)其中$b^g$是随时间缓慢变化的仪器测量偏差bias，$\eta^g$是角速度白噪声。$\sideset { _b}{_{wb}}{\omega}(t)$是角速度真实值，$\sideset { _b}{_{wb}} {\tilde{\omega}} (t)$角速度测量值，测量值是相对于IMU的b参考系来说的. 加速度计量器测量模型： \sideset { _b}{} {\tilde{\alpha}} (t) = R_{wb}^T(t)(\sideset { _b}{} {\alpha} (t)- \sideset{_w}{}{g}) + b^a(t)+ \eta^a(t)其中$b^g$是随时间缓慢变化的仪器测量偏差bias，$\eta^a$是加速度白噪声。$_w\alpha(t)$是加速度真实值，相对于世界坐标系，减去重力加速度后可以转化到b参考系，$_b {\tilde{\alpha}}(t)$加速度测量值，相对于IMU的b参考系 运动模型的微分方程： \begin{array} \dot{R}_{wb}= R_{wb}(\omega_{wb})\hat{}, & \sideset{_w}{}{\dot{v}} =\sideset{_w}{}{a}, & \sideset{_w}{}{\dot{p}} =\sideset{_w}{}{v} \\ \end{array} 使用欧拉积分可得到运动方程的离散形式如下： \begin{align} R_{wb}(t+\Delta t) &= R_{wb}(t)Exp(\int_{t}^{t+\Delta t}\sideset { _b}{_{wb}}{\omega}(\tau) d\tau )\\[2ex] \sideset{ _w}{}{v}(t+\Delta t) &= \sideset{ _w}{}{v}(t) + \int_{t}^{t+\Delta t}\sideset { _w}{}{\alpha}(\tau) d\tau \\[2ex] \sideset{ _w}{}{p}(t+\Delta t) &= \sideset{ _w}{}{p}(t) + \int_{t}^{t+\Delta t}\sideset { _w}{}{v}(\tau) d\tau + \iint_{t}^{t+\Delta t} \sideset { _w}{}{\alpha}(\tau) d\tau^2\\[2ex] \end{align}假定在$t$到$t+\Delta t$这段时间内$\sideset { _w}{}{\alpha}$和$\sideset { _b}{_{wb}}{\omega}$保持不变，那么上式积分可以写成： \begin{align} R_{wb}(t+\Delta t) &= R_{wb}(t)Exp(\sideset { _b}{_{wb}}{\omega}(t)\Delta t)\\[2ex] \sideset{ _w}{}{v}(t+\Delta t) &= \sideset{ _w}{}{v}(t) + \sideset { _w}{}{\alpha}(t)\Delta t \\[2ex] \sideset{ _w}{}{p}(t+\Delta t) &= \sideset{ _w}{}{p}(t) + \sideset { _w}{}{v}(t) \Delta t + \frac{1}{2} \sideset { _w}{}{\alpha}(t) \Delta t^2\\[2ex] \end{align}再将测量模型带入进去并省略下标得到： \begin{align} R(t+\Delta t) &= R(t)Exp(( \tilde{\omega}(t) - b^g(t) -\eta^{gd}(t))\Delta t)\\[2ex] v(t+\Delta t) &= v(t) + g\Delta t +R(t)(\tilde{\alpha}(t) -b^{\alpha}(t)-\eta^{\alpha d}(t))\Delta t \\[2ex] p(t+\Delta t) &= p(t) + v(t) \Delta t + \frac{1}{2} g \Delta t^2 + \frac{1}{2} R(t)(\tilde{\alpha}(t) -b^{\alpha}(t)-\eta^{\alpha d}(t)) \Delta t^2\\[2ex] \end{align}上述公式中，注意到噪声项采用$\eta^{gd}$和$\eta^{\alpha d}$，它们与连续噪声项$\eta^{g}$和$\eta^{\alpha}$是不同的，离散噪声和连续噪声的协方差有如下关系： \begin{align} Cov(\eta^{gd}(t)) &= \frac{1}{\Delta t}Cov(\eta^{g}(t)) \\[2ex] Cov(\eta^{\alpha d}(t)) &= \frac{1}{\Delta t}Cov(\eta^{\alpha}(t)) \end{align}2. 测量预测更新利用$k=i$时刻到$k=j-1$时刻的所有IMU测量，来由$k=i$时刻的$R_i,v_i,p_i$直接更新得到$k=j$时刻的$R_j,v_j,p_j$： \begin{align} R_j &=R_i\prod_{k=i}^{j-1} Exp\left(\left( \tilde{\omega}_k - b^g_k -\eta^{gd}_k\right)\Delta t\right)\\[2ex] v_j &= v_i + g\Delta t_{ij} + \sum_{k=i}^{j-1}R_k\left(\tilde{\alpha}_k -b^{\alpha}_k-\eta^{\alpha d}_k\right)\Delta t \\[2ex] p_j &= p_i + \sum_{k=i}^{j-1} \left[v_k \Delta t + \frac{1}{2} g \Delta t^2 + \frac{1}{2} R_k\left(\tilde{\alpha}_k -b^{\alpha}_k-\eta^{\alpha d}_k\right) \Delta t^2\right]\\[2ex] \end{align}其中，$\Delta t_{ij}=\sum_{k=i}^{j-1}\Delta t$，这里的$R_j,v_j,p_j$都是理想测量真实值（实际值，不含误差项）。于是，为了避免每次更新初始的$R_i,v_i,p_i$都要重新积分求解$R_i,v_i,p_i$，引出预积分项如下： \begin{align} \Delta R_{ij} & \dot{=} R_i^T R_j =\prod_{k=i}^{j-1} Exp\left(\left( \tilde{\omega}_k - b^g_k -\eta^{gd}_k\right)\Delta t\right)\\[2ex] \Delta v_{ij} & \dot{=} R_i^T(v_j - v_i - g\Delta t_{ij}) = \sum_{k=i}^{j-1}\Delta R_{ik}\left(\tilde{\alpha}_k -b^{\alpha}_k-\eta^{\alpha d}_k\right)\Delta t \\[2ex] \Delta p_{ij} & \dot{=} R_i^T \left (p_j - p_i - v_i\Delta t_{ij} - \frac{1}{2} g \Delta t_{ij}^2 \right) = \sum_{k=i}^{j-1} \left[\Delta v_{ik} \Delta t +\frac{1}{2} \Delta R_{ik}\left(\tilde{\alpha}_k -b^{\alpha}_k-\eta^{\alpha d}_k\right) \Delta t^2\right]\\[2ex] \end{align}上述三个预计分公式中，前两个都是显而易见的，现在证明第三个式子：证明 $\Delta p_{ij}$：记$\xi_k=\tilde{\alpha}_k -b^{\alpha}_k-\eta^{\alpha d}_k$ \begin{align} \Delta p_{ij} & \dot{=} R_i^T\left(p_j - p_i - v_i\Delta t_{ij} - \frac{1}{2}g \Delta t_{ij}^2 \right) \\[2ex] &= R_i^T\left[\sum_{k=i}^{j-1} \left(v_k \Delta t +\frac{1}{2} g \Delta t^2 + \frac{1}{2}R_k\xi_k\Delta t^2\right)-\sum_{k=i}^{j-1}v_i\Delta t- \frac{(j-i)^2}{2}g\Delta t^2 \right] \\[2ex] &= R_i^T\left[\sum_{k=i}^{j-1} \left(\left(v_k -v_i\right) \Delta t + \frac{1}{2}R_k\xi_k\Delta t^2\right)+\left(\frac{j-i}{2}-\frac{(j-i)^2}{2}\right)g\Delta t^2 \right] \\[2ex] &= R_i^T\left[\sum_{k=i}^{j-1} \left(\left(v_k -v_i\right) \Delta t + \frac{1}{2}R_k\xi_k\Delta t^2\right)-\sum_{k=i}^{j-1}\left(k-i\right)g\Delta t^2 \right] \\[2ex] &= R_i^T\left[\sum_{k=i}^{j-1} \left(\left(v_k -v_i-\left(k-i\right)g\Delta t\right) \Delta t + \frac{1}{2}R_k\xi_k\Delta t^2\right) \right] \\[2ex] &= R_i^T\left[\sum_{k=i}^{j-1} \left(\left(v_k -v_i-g\Delta t_{ik}\right) \Delta t + \frac{1}{2}R_k\xi_k\Delta t^2\right) \right] \\[2ex] &= \sum_{k=i}^{j-1} \left[R_i^T\left(v_k -v_i-g\Delta t_{ik}\right) \Delta t + \frac{1}{2}R_i^TR_k\xi_k\Delta t^2\right] \\[2ex] &= \sum_{k=i}^{j-1} \left[\Delta v_{ik} \Delta t + \frac{1}{2}\Delta R_{ik}\xi_k\Delta t^2\right] \\[2ex] \end{align}其中公式（20）利用了 \frac{j-i}{2}-\frac{(j-i)^2}{2}=-\frac{(j-i)[j-(i+1)]}{2}=-\sum_{k=i}^{j-1}(k-i)3. 白噪声预分离将噪声项$\eta^{gd}_k$和$\eta^{\alpha d}_k$从预积分理想值中分离出来，使得预积分测量值（由IMU测量数据计算得到）具有理想“加”白噪声的形式。这里做一个假设，认为预积分区间内（和视觉融合时，通常是两帧之间）的bias相等，即有$b_i^g=b_{i+1}^g=\cdots=b_j^g$以及$b_i^a=b_{i+1}^a=\cdots=b_j^a$ 项$\Delta R_{ij}$：令$J_r^k=J_r\left(\left(\tilde{\omega}_k - b^g_i\right)\Delta t\right),\Delta \tilde{R}_{ij}=\prod_{k=i}^{j-1} Exp\left[\left(\tilde{\omega}_k - b^g_i\right)\Delta t\right],Exp\left(-\delta \phi_{ij}\right) = Exp\left(-\Delta {\tilde{R}^T_{k+1j}J^k_r\eta_k^{gd}\Delta t}\right)$ \begin{align} \Delta R_{ij}&=\prod_{k=i}^{j-1} Exp\left[\left(\tilde{\omega}_k - b^g_i -\eta^{gd}_k\right)\Delta t\right] \\[2ex] &=\prod_{k=i}^{j-1} Exp\left[\left(\tilde{\omega}_k - b^g_i\right)\Delta t -\eta^{gd}_k\Delta t\right] \\[2ex] & \approx \prod_{k=i}^{j-1} \left\{Exp\left[\left(\tilde{\omega}_k - b^g_i\right)\Delta t\right] Exp\left[-J_r\left(\left(\tilde{\omega}_k - b^g_i\right)\Delta t\right)\eta^{gd}_k\Delta t\right]\right\} \\[2ex] & = \Delta {\tilde{R}_{ij}} \prod_{k=i}^{j-1}Exp\left(-\Delta {\tilde{R}^T_{k+1j}J^k_r\eta_k^{gd}\Delta t}\right)\\[2ex] & =\Delta {\tilde{R}_{ij}}Exp\left(-\delta \phi_{ij}\right) \end{align} $\Delta {\tilde{R}_{ij}}$表示实际测量值，$ Exp\left(-\delta \phi_{ij}\right) $表示测量白噪声，$\Delta R_{ij}$表示理想测量值 项$\Delta v_{ij}$：令$\Delta \tilde{v}_{ij}=\sum_{k=i}^{j-1} \left[\tilde{R}_{ik} \left(\tilde{\alpha}_k- b^{\alpha}_i\right)\Delta t\right],\delta v_{ij} =\sum_{k=i}^{j-1} \left[\tilde{R}_{ik}\eta_k^{ad}\Delta t - \tilde{R}_{ik}\left(\tilde{\alpha}_k- b^{\alpha}_i\right)\hat{} \delta \phi_{ik}\Delta t\right]$ \begin{align} \Delta v_{ij}&=\sum_{k=i}^{j-1} \left[\Delta R_{ik} \left(\tilde{\alpha}_k- b^{\alpha}_i -\eta^{ad}_k\right)\Delta t\right]\\[2ex] &\approx \sum_{k=i}^{j-1} \Delta {\tilde{R}_{ik}}Exp\left(-\delta \phi_{ik}\right)\left(\tilde{\alpha}_k- b^{\alpha}_i -\eta^{ad}_k\right)\Delta t \\[2ex] &\approx \sum_{k=i}^{j-1} \Delta {\tilde{R}_{ik}}\left( I -\delta \phi_{ik}\hat{}\right)\left(\tilde{\alpha}_k- b^{\alpha}_i -\eta^{ad}_k\right)\Delta t \\[2ex] &\approx \sum_{k=i}^{j-1} \left[\Delta {\tilde{R}_{ik}}\left( I -\delta \phi_{ik}\hat{}\right)\left(\tilde{\alpha}_k- b^{\alpha}_i\right)\Delta t-\Delta {\tilde{R}_{ik}}\eta^{ad}_k\Delta t \right] \\[2ex] &= \sum_{k=i}^{j-1} \left[\Delta {\tilde{R}_{ik}}\left(\tilde{\alpha}_k- b^{\alpha}_i\right)\Delta t + \Delta {\tilde{R}_{ik}}\left(\tilde{\alpha}_k- b^{\alpha}_i\right)\hat{}\delta \phi_{ik}\Delta t-\Delta {\tilde{R}_{ik}}\eta^{ad}_k\Delta t \right] \\[2ex] &= \sum_{k=i}^{j-1} \left[\Delta {\tilde{R}_{ik}}\left(\tilde{\alpha}_k- b^{\alpha}_i\right)\Delta t\right] + \sum_{k=i}^{j-1} \left[ \Delta {\tilde{R}_{ik}}\left(\tilde{\alpha}_k- b^{\alpha}_i\right)\hat{}\delta \phi_{ik}\Delta t-\Delta {\tilde{R}_{ik}}\eta^{ad}_k\Delta t \right] \\[2ex] &=\Delta \tilde{v}_{ij}-\delta v_{ij} \end{align}$\Delta \tilde{v}_{ij}$即速度增量预积分测量值，它有IMU测量值和对bias的估计计算得到。$\delta v_{ij}$即其测量噪声。 项$\Delta p_{ij}$：将$\Delta R_{ij}=\Delta {\tilde{R}_{ij}}Exp\left(-\delta \phi_{ij}\right)$ 以及 $\Delta v_{ij}= \Delta \tilde{v}_{ij}-\delta v_{ij}$带入$\Delta p_{ij}$的公式中 \begin{align} \Delta p_{ij}&=\sum_{k=i}^{j-1} \left[\Delta v_{ik} \Delta t + \frac{1}{2}\Delta R_{ik}\left(\tilde{\alpha}_k- b^{\alpha}_i-\eta_k^{ad}\right)\Delta t^2\right]\\[2ex] &\approx \sum_{k=i}^{j-1}\left(\Delta \tilde{\mathbf{v}}_{i k}-\delta \mathbf{v}_{i k}\right) \cdot \Delta t+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot \operatorname{Exp}\left(-\delta {\phi}_{i k}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}-\mathbf{\eta}_{k}^{a d}\right) \cdot \Delta t^{2} ]\\[2ex] &\approx \sum_{k=1}^{j-1}\left[\left(\Delta \tilde{\mathbf{v}}_{i k}-\delta \mathbf{v}_{i k}\right) \cdot \Delta t+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\mathbf{I}-\delta {\phi}_{i k}^{\wedge}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}-\mathbf{\eta}_{k}^{a d}\right) \cdot \Delta t^{2}\right] \\[2ex] &\approx {\sum_{k=i}^{j-1}\left[\left(\Delta \tilde{\mathbf{v}}_{i k}-\delta \mathbf{v}_{i k}\right) \cdot \Delta t\right.}{+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\mathbf{I}-\delta {\phi}_{i k}^{\wedge}\right) \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right) \cdot \Delta t^{2}-\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \mathbf{\eta}_{k}^{a d} \Delta t^{2} ]} \\[2ex] &= \begin{array}{l}{\sum_{k=1}^{j-1}\left[\Delta \tilde{\mathbf{v}}_{i k} \Delta t+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right) \Delta t^{2}\right.} \\ {\quad+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \delta {\phi}_{i k} \Delta t^{2}-\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \mathbf{\eta}_{k}^{a d} \Delta t^{2}-\delta \mathbf{v}_{i k} \Delta t ]}\\[2ex]\end{array} \end{align} 再令： \begin{array}{l}{\Delta \tilde{\mathbf{p}}_{i j} \triangleq \sum_{k=1}^{j-1}\left[\Delta \tilde{\mathbf{v}}_{i k} \Delta t+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right) \Delta t^{2}\right]} \\[2ex] {\delta \mathbf{p}_{i j} \triangleq \sum_{k=1}^{j-1}\left[\delta \mathbf{v}_{i k} \Delta t-\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \delta {\phi}_{i k} \Delta t^{2}+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \mathbf{\eta}_{k}^{a d} \Delta t^{2}\right]}\end{array}可得： \Delta \mathbf{p}_{i j} \triangleq \Delta \tilde{\mathbf{p}}_{i j}-\delta \mathbf{p}_{i j}$\tilde{\mathbf{p}}_{i j}$即位置增量预积分测量值，它由IMU测量值和对bias的估计计算得到。$\delta \mathbf{p}_{i j}$即其测量噪声。 总结得到预积分理想值和测量值的关系如下： \begin{array}{l} \Delta \mathbf{R}_{i j} \triangleq \Delta \tilde{\mathbf{R}}_{i j} \cdot \operatorname{Exp}\left(-\delta {\phi}_{i j}\right)\\[2ex] \Delta \mathbf{v}_{i j} \triangleq \Delta \tilde{\mathbf{v}}_{i j}-\delta \mathbf{v}_{i j}\\[2ex] \Delta \mathbf{p}_{i j} \triangleq \Delta \tilde{\mathbf{p}}_{i j}-\delta \mathbf{p}_{i j} \end{array}带入预积分理想值的表达式： \begin{array}{l} \Delta \mathbf{R}_{i j} \triangleq \mathbf{R}_{i}^{T} \mathbf{R}_{j}\\[2ex] \Delta \mathbf{v}_{i j} \triangleq \mathbf{R}_{i}^{T}\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right) \\[2ex] \Delta \mathbf{p}_{i j} \triangleq \mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)\end{array}则有： \begin{array}{l} {\Delta \tilde{\mathbf{R}}_{i j} \approx \Delta \mathbf{R}_{i j} \operatorname{Exp}\left(\delta {\phi}_{i j}\right)=\mathbf{R}_{i}^{T} \mathbf{R}_{j} \operatorname{Exp}\left(\delta {\phi}_{i j}\right)} \\[2ex] {\Delta \tilde{\mathbf{v}}_{i j} \approx \Delta \mathbf{v}_{i j}+\delta \mathbf{v}_{i j}=\mathbf{R}_{i}^{T}\left(\mathbf{v}_{j}-\mathbf{v}_{i}-\mathbf{g} \cdot \Delta t_{i j}\right)+\delta \mathbf{v}_{i j}} \\[2ex] {\Delta \tilde{\mathbf{p}}_{i j} \approx \Delta \mathbf{p}_{i j}+\delta \mathbf{p}_{i j}=\mathbf{R}_{i}^{T}\left(\mathbf{p}_{j}-\mathbf{p}_{i}-\mathbf{v}_{i} \cdot \Delta t_{i j}-\frac{1}{2} \mathbf{g} \cdot \Delta t_{i j}^{2}\right)+\delta \mathbf{p}_{i j}}\end{array}上式表达式为预积分测量值（$\Delta \tilde{\mathbf{R}}_{i j}$含IMU测量值以及仪器bias）与理想值之间的关系，理想值($\Delta \mathbf{R}_{i j}$含测量值仪器、bias以及白噪声)，即形如“测量值=理想值+噪声”的形式。 4. 预积分白噪声分布分析令预积分白噪声为 \mathbf{\eta}_{i j}^{\Delta} \triangleq\left[\begin{array}{ccc}{\delta {\phi}_{i j}^{T}} & {\delta \mathbf{v}_{i j}^{T}} & {\delta \mathbf{p}_{i j}^{T}}\end{array}\right]^{T}我们希望其满足高斯分布，即$\mathbf{\eta}_{i j}^{\Delta} \sim N\left(\mathbf{0}_{9 \times 1}, \mathbf{\Sigma}_{i j}\right)$。由于$\mathbf{\eta}_{i j}^{\Delta}$是$\delta {\phi}_{i j}^{T}$、${\delta \mathbf{v}_{i j}^{T}}$以及${\delta \mathbf{p}_{i j}^{T}}$的线性组合，下面分别对这三个噪声项的分布进行分析。 (1)$\delta {\phi}_{i j}$的分布形式 \delta {\phi}_{i j} \approx \sum_{k=i}^{j-1} \Delta \tilde{\mathbf{R}}_{k+1 j}^{T} \mathbf{J}_{r}^{k} \mathbf{\eta}_{k}^{g d} \Delta t由于$\Delta \tilde{\mathbf{R}}_{k+1 j}^{T}$，和都是已知量，而是零均值高斯噪声，因此的一阶近似也为零均值高斯噪声。 (2)$\delta {v}_{i j}$的分布形式由于$\delta {\phi}_{i j}^{T}$近似拥有了高斯噪声的形式，且$\mathbf{\eta}_{k}^{a d}$也是零均值高斯噪声，根据$\delta \mathbf{v}_{i j}$的表达式： \delta \mathbf{v}_{i j}=\sum_{k=i}^{j-1}\left[\Delta \tilde{\mathbf{R}}_{i c} \mathbf{\eta}_{k}^{a d} \Delta t-\Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \cdot \delta {\phi}_{i k} \cdot \Delta t\right]可知$\delta {v}_{i j}^{T}$也有零均值高斯分布的形式。 (3)$\delta {p}_{i j}$的分布形式类似$\delta {v}_{i j}$，$\delta {p}_{i j}$也拥有零均值高斯分布的形式，其表达式为： \delta \mathbf{p}_{i j}=\sum_{k=i}^{j-1}\left[\delta \mathbf{v}_{i k} \Delta t-\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \delta \vec{\phi}_{i k} \Delta t^{2}+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \mathbf{\eta}_{k}^{a d} \Delta t^{2}\right]可知$\delta {v}_{i j}$也有零均值高斯分布的形式。 4. 预积分白噪声递推形式下面推导预积分测量噪声的递推形式，即$\mathbf{\eta}_{i j-1}^{\Delta} \rightarrow \mathbf{\eta}_{i j}^{\Delta}$，及其协方差$\boldsymbol{\Sigma}_{i j}$的递推形式，即$\boldsymbol{\Sigma}_{i j-1} \rightarrow \boldsymbol{\Sigma}_{i j}$。先推导$\delta {\phi}_{i j-1} \rightarrow \delta {\phi}_{i j}$、$\delta \mathbf{v}_{i j-1} \rightarrow \delta \mathbf{v}_{i j}$和$\delta \mathbf{p}_{i j-1} \rightarrow \delta \mathbf{p}_{i j}$。 (1)$\delta {\phi}_{i j-1} \rightarrow \delta {\phi}_{i j}$ \begin{aligned} \delta {\phi}_{i j} &=\sum_{k=i}^{j-1} \Delta \tilde{\mathbf{R}}_{k+1 j}^{T} \mathbf{J}_{r}^{k} \mathbf{\eta}_{k}^{g d} \Delta t \\[2ex] &=\sum_{k=1}^{j-2} \Delta \tilde{\mathbf{R}}_{k+1 j}^{T} \mathbf{J}_{r}^{k} \mathbf{\eta}_{k}^{g d} \Delta t+\Delta \tilde{\mathbf{R}}_{j j}^{T} \mathbf{J}_{r}^{j-1} \mathbf{\eta}_{j-1}^{g d} \Delta t \\[2ex] &= \sum_{k=1}^{j-2}\left(\Delta \tilde{\mathbf{R}}_{k+j-1} \Delta \tilde{\mathbf{R}}_{j-1 j}\right)^{T} \mathbf{J}_{r}^{k} \mathbf{\eta}_{k}^{g d} \Delta t+\mathbf{J}_{r}^{j-1} \mathbf{\eta}_{j-1}^{g d} \Delta t \\[2ex] &=\Delta \tilde{\mathbf{R}}_{j j-1} \sum_{k=1}^{j-2} \Delta \tilde{\mathbf{R}}_{k+1 j-1}^{T} \mathbf{J}_{r}^{k} \mathbf{\eta}_{k}^{g d} \Delta t+\mathbf{J}_{r}^{j-1} \mathbf{\eta}_{j-1}^{g d} \Delta t \\[2ex] &=\Delta \tilde{\mathbf{R}}_{j j-1} \delta {\phi}_{i j-1}+\mathbf{J}_{r}^{j-1} \mathbf{\eta}_{j-1}^{g d} \Delta t \end{aligned} (2) $\delta \mathbf{v}_{i j-1} \rightarrow \delta \mathbf{v}_{i j}$直接进行拆分即可完成推导 \begin{aligned} \delta \mathbf{v}_{i j}&=\sum_{k=i}^{j-1}\left[\Delta \tilde{\mathbf{R}}_{i k} \mathbf{\eta}_{k}^{\alpha d} \Delta t-\Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \cdot \delta {\phi}_{i k} \cdot \Delta t\right] \\[2ex] &=\sum_{k=i}^{j-2}\left[\Delta \tilde{\mathbf{R}}_{i k} \mathbf{n}_{\mathbf{k}}^{a d} \Delta t-\Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \cdot \delta {\phi}_{i k} \cdot \Delta t\right] \\ &\quad +\Delta \tilde{\mathbf{R}}_{i j-1} \mathbf{\eta}_{j-1}^{a d} \Delta t-\Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \cdot \delta {\phi}_{i j-1} \cdot \Delta t\\[2ex] &=\delta \mathbf{v}_{i j-1}+\Delta \tilde{\mathbf{R}}_{i j-1} \mathbf{\eta}_{j-1}^{a d} \Delta t-\Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \cdot \delta {\phi}_{i j-1} \cdot \Delta t \end{aligned} (3) $\delta \mathbf{p}_{i j-1} \rightarrow \delta \mathbf{p}_{i j}$同样直接进行拆分即可完成推导 \begin{aligned} \delta \mathbf{p}_{i j}=& \sum_{k=1}^{j-1}\left[\delta \mathbf{v}_{i k} \Delta t-\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \cdot\left(\tilde{\mathbf{a}}_{k}-\mathbf{b}_{i}^{a}\right)^{\wedge} \delta {\phi}_{i k} \Delta t^{2}+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i k} \mathbf{n}_{k}^{a d} \Delta t^{2}\right] \\[2ex] =& \delta \mathbf{p}_{i j-1}+\delta \mathbf{v}_{i j-1} \Delta t \\[2ex] &-\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \delta {\phi}_{i j-1} \Delta t^{2}+\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i j-1} \mathbf{n}_{j-1}^{a d} \Delta t^{2} \end{aligned}综上可得$\mathbf{\eta}_{i j}^{\Delta}$的递推形式如下(令$\mathbf{\eta}_{k}^{d}=\left[\left(\mathbf{\eta}_{k}^{g d}\right)^{T} \quad\left(\mathbf{\eta}_{k}^{a d}\right)^{T}\right]^{T}$)： \mathbf{\eta}_{i j}^{\Delta}= \begin{bmatrix} \Delta \tilde{\mathbf{R}}_{j j-1} & \mathbf{0} & \mathbf{0} \\ -\Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \Delta t & \mathbf{I} & \mathbf{0}\\ -\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \Delta t^{2} & \Delta t\mathbf{I} & \mathbf{I} \end{bmatrix}\mathbf{\eta}_{i j-1}^{\Delta}+\left[\begin{array}{cc}{\mathbf{J}_{r}^{j-1} \Delta t} & {\mathbf{0}} \\ {\mathbf{0}} & {\Delta \tilde{\mathbf{R}}_{i j-1} \Delta t} \\ {\mathbf{0}} & {\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i j-1} \Delta t^{2}}\end{array}\right] \mathbf{\eta}_{j-1}^{d}令 \begin{aligned} A_{j-1} &= \begin{bmatrix} \Delta \tilde{\mathbf{R}}_{j j-1} & \mathbf{0} & \mathbf{0} \\ -\Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \Delta t & \mathbf{I} & \mathbf{0}\\ -\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i j-1} \cdot\left(\tilde{\mathbf{a}}_{j-1}-\mathbf{b}_{i}^{a}\right)^{\wedge} \Delta t^{2} & \Delta t\mathbf{I} & \mathbf{I} \end{bmatrix}\\[2ex] B_{j-1}&=\left[\begin{array}{cc}{\mathbf{J}_{r}^{j-1} \Delta t} & {\mathbf{0}} \\ {\mathbf{0}} & {\Delta \tilde{\mathbf{R}}_{i j-1} \Delta t} \\ {\mathbf{0}} & {\frac{1}{2} \Delta \tilde{\mathbf{R}}_{i j-1} \Delta t^{2}}\end{array}\right] \end{aligned}则有 \mathbf{\eta}_{i j}^{\Delta}=\mathbf{A}_{j-1} \mathbf{\eta}_{i j-1}^{\Delta}+\mathbf{B}_{j-1} \mathbf{\eta}_{j-1}^{d}现在$\Sigma_{i j-1}$（预积分测量噪声的协方差矩阵）有了如下递推计算形式： \Sigma_{i j}=\mathbf{A}_{j-1} \Sigma_{i j-1} \mathbf{A}_{j-1}^{T}+\mathbf{B}_{j-1} \mathbf{\Sigma}_{\mathbf{\eta}} \mathbf{B}_{j-1}^{T}]]></content>
      <categories>
        <category>IMU</category>
      </categories>
      <tags>
        <tag>Camera</tag>
        <tag>IMU</tag>
        <tag>Preintegration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旋转向量和李代数]]></title>
    <url>%2F2019%2F06%2F25%2F%E6%97%8B%E8%BD%AC%E5%90%91%E9%87%8F%E5%92%8CIMU%2F</url>
    <content type="text"><![CDATA[1. 向量和坐标系如果我们确定一个坐标系$\vec{w_1}=\begin{bmatrix} e_1 \ e_2 \ e_3\end{bmatrix}$，也就是一个线性空间的基$e_1,e_2,e_3$那就可以谈论向量$a$在这组基下的坐标了，假设向量$a$在这个坐标系的坐标为$x_1 =\begin{bmatrix} a_1 \ a_2 \ a_3\end{bmatrix} $: \vec{a} = \begin{bmatrix} e_1 & e_2 & e_3\end{bmatrix} \begin{bmatrix}a_1\\ a_2 \\ a_3\end{bmatrix} = a_1e_1+a_2e_2+a_3e_3对于另一个坐标系$\vec{w_2}=\begin{bmatrix} e_1’ \ e_2’ \ e_3’\end{bmatrix}$，坐标为$x_2 =\begin{bmatrix} a_1’ \ a_2’ \ a_3’\end{bmatrix} $也有 \vec{a} = \begin{bmatrix} e_1' & e_2' & e_3'\end{bmatrix} \begin{bmatrix}b_1\\ b_2 \\ b_3\end{bmatrix} = a_1'e_1'+b_2e_2'+b_3e_3'于是有原点相同的两个参考系$\vec{w_1}$和$\vec{w_2}$ \vec{a} = \vec{w_1}x_1 = \vec{w_2}x_2继续推导可以得到 x_2 = R_{21}x_1这就定义了$R_{21} = \vec{w_2}\vec{w_1}^T$我们称矩阵$R_{21}$为旋转矩阵，有时也称之为方向余弦矩阵，因为两个单位向量的点积结果就是他们之间夹角的余弦。于是两个坐标系中的单位向量可以关联起来 \vec{w_1} = \vec{w_2}R_{21}旋转矩阵的性质： x_1 = R_{21}^{-1}x_2 = R_{12}x_2于是有： R_{21} = R_{12}^{-1} = R_{12}^T2. 向量的内积和外积设向量$\vec {a} = \begin{bmatrix} a_1 \ a_2 \ a_3\end{bmatrix}$，向量$\vec {b} = \begin{bmatrix} b_1 \ b_2 \ b_3\end{bmatrix}$ 内积： \vec{a}\vec{b} = \vec{a}^T\vec{b} = \sum_{i=1}^3{a_ib_i}=|\vec{a}||\vec{b}|\cos\langle a,b\rangle 外积： \vec{a} \times \vec{b} = \begin{bmatrix} i & j & k \\ a_1 & a_2 & a_3 \\ b_1 & b_2 & b_3 \end{bmatrix}= \begin{bmatrix} a_2b_3 - a_3b_2 \\ a_3b_1 - a_1b_3 \\ a_1b_2 - a_2b_1 \end{bmatrix}= \begin{bmatrix} 0 & -a_3 &a_2 \\ a_3 & 0 & -a_1 \\ a_2& a_1 & 0 \end{bmatrix}\vec{b} =[\vec{a}]_x\vec{b} hat运算： [\vec{a}]\hat{}=\begin{bmatrix} a_1 \\ a_2 \\ a_3\end{bmatrix}\hat{} = \begin{bmatrix} 0 & -a_3 &a_2 \\ a_3 & 0 & -a_1 \\ a_2& a_1 & 0 \end{bmatrix} -a\hat{}b=-b\hat{}a3. 基本旋转矩阵与欧拉角 绕坐标系$z$轴旋转$\theta_3$角度的矩阵： R_3 = \begin{bmatrix} \cos\theta_3 & \sin\theta_3 & 0 \\ -\sin\theta_3 & \cos\theta_3 & 0 \\ 0 & 0 & 1 \end{bmatrix} 绕坐标系$y$轴旋转$\theta_2$角度的矩阵： R_2 = \begin{bmatrix} \cos\theta_2 & 0 & -\sin\theta_2 \\ 0 & 1 & 0 \\ \sin\theta_2 & 0 & \cos\theta_2 \\ \end{bmatrix} 绕坐标系$x$轴旋转$\theta_1$角度的矩阵： R_1 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & \cos\theta_1 & \sin\theta_1 \\ 0 & -\sin\theta_1 & \cos\theta_1 \end{bmatrix} RPY(翻滚角-俯仰角-偏航角)表示旋转沿着原始坐标系的主轴1（x轴）旋转$\theta_1$d度（翻滚角）；沿着原始坐标系的主轴2（y轴）旋转$\theta_2$d度（俯仰角）；沿着原始坐标系的主轴3（z轴）旋转$\theta_3$d度（偏航角）；这种情况下从参考系1到参考系2的旋转矩阵为： R_{21}(\theta_3,\theta_2,\theta_1) = R_3(\theta_3)R_2(\theta_2)R_1(\theta_1) = \begin{bmatrix} c_2c_3 & c_1s_3+s_1s_2c_3 & s_1s_3-c_1s_2c_3 \\ -c_2s_3 & c_1c_3 -s_1s_2s_3 & s_1c_3 + c_1s_2s_3 \\ s_2 & -s_1c_2 &c_1c_2 \end{bmatrix} 4. SO(n) 特殊正交群 与 SE(n) 特殊欧式群旋转矩阵是一个行列式为1的正交矩阵，反之，行列式为1的正交矩阵也是一个旋转矩阵。所以可以把旋转矩阵的集合定义如下： SO(3) = \{R \in \Bbb{R}^{n \times n}| RR^T=I,\det(R)=1\} R^{-1}=R^T在欧氏变换中,除了旋转之外还有一个平移。关于变换矩阵$T$，它具有比较特别的结构：左上角为旋转矩阵，右侧为平移向量，左下角为0向量，右下角为1。这种矩阵又称为特殊欧氏群： SE(3) = \{T=\begin{bmatrix}R &t \\ 0^T & 1\end{bmatrix} \in \Bbb {R}^{4 \times 4}| R \in SO(3),t \in \Bbb {R}^3\} T^{-1} = \begin{bmatrix}R^T & -R^Tt \\ 0^T & 1\end{bmatrix}5. 旋转向量对于坐标系的旋转，我们知道，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是，我们可以使用一个向量，其方向与旋转轴一致，而长度等于旋转角。这种向量，称为旋转向量(或轴角，Axis-Angle)。这种表示法只需一个三维向量即可描述旋转。同样，对于变换矩阵，我们使用一个旋转向量和一个平移向量即可表达一次变换。这时的维数正好是六维。假设有一个旋转轴为$\alpha$，角度为$\theta$的旋转，显然，它对应的旋转向量为$\theta \alpha$。由旋转向量到旋转矩阵的过程由罗德里格斯公式表明： R = \cos \theta I + (1-\cos\theta)\alpha\alpha^T + \sin \theta \alpha\hat{}.符号$\hat{}$是向量到反对称的转换符。反之，我们也可以计算从一个旋转矩阵到旋转向量的转换。对于转角$\theta$，有： tr(R) = \cos\theta tr(I) + (1-\cos \theta)tr(\alpha\alpha^T)+\sin\theta tr(\alpha\hat{})=3\cos\theta + (1-\cos\theta)= 1+2cos\theta因此，有 \theta = \arccos (\frac{tr(R)-1}{2})关于转轴$\alpha$，由于旋转轴上的向量在旋转后不发生改变，说明 R\alpha=\alpha.因此，转轴$\alpha$是矩阵$R$特征值1对应的特征向量。求解此方程，再归一化，就得到了旋转轴。 6. 李代数$SO(3)$对应的李代数$so(3)$是定义在$\Bbb {R}^3$的向量，我们记作$\phi$。根据前面的推导，每个$\phi$都可以生成一个反对称矩阵: \Phi = \phi\hat{}= \begin{bmatrix} 0 & -\phi_3 &\phi_2 \\ \phi_3 & 0 & -\phi_1 \\ -\phi_2 & -\phi_1 & 0 \end{bmatrix} \in \Bbb {R}^{3 \times 3}由于$\phi$与反对称矩阵关系很紧密,在不引起歧义的情况下,就说$so(3)$的元素是3维向量或者3维反对称矩阵,不加区别: so(3) = \{\phi \in \Bbb {R}^3,\Phi = \phi\hat{} \in \Bbb {R}^{3\times3}\}至此，我们已清楚了$so(3)$的内容。它们是一个由三维向量组成的集合，每个向量对应到一个反对称矩阵，可以表达旋转矩阵的导数。它与$SO(0)$的关系由指数映射给定: R = \exp(\phi\hat{})对于$SE(3)$，它也有对应的李代数$se(3)$，$se(3)$位于$\Bbb {R}^6$空间中： se(3)=\{ \xi = \begin{bmatrix} \rho \\ \phi \end{bmatrix} \in \Bbb {R}^3, \phi \in so(3), \xi\hat{} = \begin{bmatrix} \phi\hat{} & \rho \\ 0^T & 0 \end{bmatrix} \in \Bbb {R}^{4 \times4} \}我们把每个$se(3)$元素记作$\xi$，它是一个六维向量。前三维为平移，记作$\rho$；后三维为旋转，记作$\phi$，实质上是$so(3)$元素。同时，我们拓展了$\hat{}$符号的含义。在$se(3)$中，同样使用符号$\hat{}$将一个六维向量转换成四维矩阵，但这里不再表示反对称： \xi\hat{} = \begin{bmatrix} \phi\hat{} & \rho \\ 0^T & 0 \end{bmatrix} \in \Bbb {R}^{4\times4}7. 指数与对数映射任意矩阵的指数映射可以写成一个泰勒展开，但是只有在收敛的情况下才会有结果，其结果仍是一个矩阵。 \exp(A) = \sum_{n=0}^{\infty}{\frac{1}{n!}A^n}同样地,对$SO(3)$中任意一元素$\phi$，我们亦可按此方式定义它的指数映射: \exp(\phi\hat{}) = \sum_{n=0}^{\infty}{\frac{1}{n!}(\phi\hat{})^n}我们来仔细推导一下这个定义。由于$\phi$是三维向量，我们可以定义它的模长和它的方向，分别记作$\theta$和$\alpha$,于是有$\phi = \theta\alpha$。这里$\alpha$是一个长度为1的方向向量。首先，对于$a\hat{}$，有以下两条性质: a\hat{}a\hat{} = aa^T-I,a\hat{}a\hat{}a\hat{} = -a\hat{}于是，指数映射有：\begin{align}\exp(\phi\hat{}) &amp;= \exp(\theta\alpha\hat{})=\sum_{n=0}^{\infty}{\frac{1}{n!}(\theta\alpha\hat{})^n} \\&amp;=I + \theta\alpha\hat{} +\frac{1}{2!}\theta^2\alpha\hat{}\alpha\hat{}+\frac{1}{3!}\theta^3\alpha\hat{}\alpha\hat{}\alpha\hat{}+\frac{1}{4!}\theta^4(\alpha\hat{})^4 +\cdots\\&amp;=\alpha\alpha^T-\alpha\hat{}\alpha\hat{}+\theta\alpha\hat{}+\frac{1}{2!}\theta^2\alpha\hat{}\alpha\hat{}-\frac{1}{3!}\theta^3\alpha\hat{}-\frac{1}{4!}\theta^4(\alpha\hat{})^2+\cdots \\&amp;= \alpha\alpha^T + (\theta -\frac{1}{3!}\theta^3+\frac{1}{5!}\theta^5-\cdots)\alpha\hat{} - (1-\frac{1}{2!}\theta^2+\frac{1}{4!}\theta^4-\cdots)\alpha\hat{}\alpha\hat{} \\&amp;=\alpha\hat{}\alpha\hat{} + I +\sin\theta\alpha\hat{} -\cos\theta\alpha\hat{}\alpha\hat{} \\&amp;=(1-\cos\theta)\alpha\hat{}\alpha\hat{} + I + \sin\theta\alpha\hat{} \\&amp;=\cos\theta I +(1-\cos\theta)\alpha\alpha^T+\sin\theta\alpha\hat{}\end{align}最后，得到罗德里格斯公式： \exp(\phi\hat{}) =\cos\theta I +(1-\cos\theta)\alpha\alpha^T+\sin\theta\alpha\hat{}通过$\phi = \theta\alpha$转化为原旋转矩阵有： \exp(\phi\hat{}) = I + \frac{\sin(\Vert\phi\Vert)}{\Vert\phi\Vert}\phi\hat{}+\frac{1-\cos(\Vert\phi\Vert)}{\Vert\phi\Vert}(\phi\hat{})^2如果$\phi$比较小，有一阶近似如下： exp(\phi\hat{})\approx I + \phi\hat{}则有对数映射如下： \theta =\arccos (\frac{tr(R)-1}{2}) \phi = log(R) = \frac {\theta (R-R^T)}{2\sin(\theta)} R\alpha = \alphaSE(3)上的指数映射 \exp(\xi\hat{})= \begin{bmatrix} \sum_{n=0}^{\infty}{\frac{1}{n!}(\phi\hat{})^n} & \sum_{n=0}^{\infty}{\frac{1}{(n+1)!}(\phi\hat{})^n\rho} \\ 0^T & 1 \end{bmatrix} = \begin{bmatrix} R & J\rho \\ 0^T & 1 \end{bmatrix} = T J =J_l = \frac{\sin\theta}{\theta}I+(1-\frac{\sin\theta}{\theta})\alpha\alpha^T+\frac{1-\cos\theta}{\theta}\alpha\hat{}平移向量t，可以用下式推导： t = J\rho 8. Baker-Campbell-Hausdorff 近似公式 \log(\exp(\phi_1\hat{}\exp(\phi_2\hat{}) \approx \begin{cases} J_l(\phi_2)^{-1}\phi_1+\phi_2 & \text{if $\phi_1$ is small} \\[2ex] J_r(\phi_1)^{-1}\phi_2+\phi_1 & \text{if $\phi_2$ is small} \end{cases} J =J_l = \frac{\sin\theta}{\theta}I+(1-\frac{\sin\theta}{\theta})\alpha\alpha^T+\frac{1-\cos\theta}{\theta}\alpha\hat{}它的逆为： J_l^{-1} = \frac{\theta}{2} \cot(\frac{\theta}{2}) I + ( 1 -\frac{\theta}{2} \cot(\frac{\theta}{2}) ) \alpha\alpha^T - \frac{\theta}{2}\alpha\hat{}而右乘雅可比仅需要对自变量取负号即可： J_r^{\phi} = J_l(-\phi)加法近似： \exp((\phi+\delta\phi)\hat{}) = \exp((J_l\delta\phi)\hat{})\exp(\phi\hat{})=\exp(\phi\hat{})\exp((J_r\delta\phi)\hat{})对于原$\phi$来说，Jacobian 式如下： J_r(\phi) = I - \frac{1-\cos(\Vert\phi\Vert)}{\Vert \phi \Vert^2} \phi\hat{} + \frac{\Vert\phi\Vert-\sin(\Vert\phi\Vert)}{\Vert \phi ^3 \Vert}(\phi\hat{})^2 J_r(\phi)^{-1} = I + \frac{1}{2}\phi\hat{}+ \left(\frac{1}{\Vert \phi \Vert^2} + \frac{1 + \cos(\Vert\phi\Vert)}{2\Vert \phi \Vert \sin(\Vert\phi\Vert)}\right)(\phi\hat{})^29. adjoint property R\exp(\phi)R^T = \exp(R\phi\hat{}R^T) = \exp{R\phi} \exp(\phi)R = R\exp(R^T\phi)]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析十一]]></title>
    <url>%2F2019%2F06%2F19%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8D%81%E4%B8%80%2F</url>
    <content type="text"><![CDATA[LocalMapping 类说明1. LocalMapping 成员变量1.1 単目Monocular标记，标记是否为単目地图跟踪1bool mbMonocular; 1.2 reset重置地图请求标记1bool mbResetRequested; 1.3 地图完成请求标记，以及完成标记12bool mbFinishRequested;bool mbFinished; 1.4 优化的地图指针1Map* mpMap; 1.5 回环检测指针以及跟踪指针12LoopClosing* mpLoopCloser;Tracking* mpTracker; 1.6 Tracking线程向LocalMapping中插入关键帧是先插入到该队列中,等待处理的关键帧列表12// Tracking线程向LocalMapping中插入关键帧是先插入到该队列中 std::list&lt;KeyFrame*&gt; mlNewKeyFrames; ///&lt; 等待处理的关键帧列表 1.7 当前处理的关键帧指针1KeyFrame* mpCurrentKeyFrame; 1.8 最近新加进来的地图点1std::list&lt;MapPoint*&gt; mlpRecentAddedMapPoints; 1.9 是否要BA标记1bool mbAbortBA; 1.10 进程终止标记、请求进程终止标记、进程不可终止标记123bool mbStopped;bool mbStopRequested;bool mbNotStop; 1.11 是否插入关键帧标记1bool mbAcceptKeyFrames; 2. LocalMapping 成员函数说明2.1 构造函数，通过传入的地图指针以及是否为単目地图跟踪来初始化LocalMapping,此时可接受关键帧并且认为上一次LocalMapping已经结束12345LocalMapping::LocalMapping(Map *pMap, const float bMonocular): mbMonocular(bMonocular), mbResetRequested(false), mbFinishRequested(false), mbFinished(true), mpMap(pMap), mbAbortBA(false), mbStopped(false), mbStopRequested(false), mbNotStop(false), mbAcceptKeyFrames(true)&#123;&#125; 2.2 设置LoopCloser以及Tracker指针123456789void LocalMapping::SetLoopCloser(LoopClosing* pLoopCloser)&#123; mpLoopCloser = pLoopCloser;&#125;void LocalMapping::SetTracker(Tracking *pTracker)&#123; mpTracker=pTracker;&#125; 2.3 将关键帧插入到列表中进行等待1234567891011121314/** * @brief 插入关键帧 * * 将关键帧插入到地图中，以便将来进行局部地图优化 * 这里仅仅是将关键帧插入到列表中进行等待 * @param pKF KeyFrame */void LocalMapping::InsertKeyFrame(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lock(mMutexNewKFs); // 将关键帧插入到列表中 mlNewKeyFrames.push_back(pKF); mbAbortBA=true;&#125; 2.4 查看列表中是否有等待被插入的关键帧123456789/** * @brief 查看列表中是否有等待被插入的关键帧 * @return 如果存在，返回true */bool LocalMapping::CheckNewKeyFrames()&#123; unique_lock&lt;mutex&gt; lock(mMutexNewKFs); return(!mlNewKeyFrames.empty());&#125; 2.5 处理列表中的关键帧,函数用于计算关键帧特征点的BoW映射，将关键帧插入地图。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * @brief 处理列表中的关键帧 * * - 计算Bow，加速三角化新的MapPoints * - 关联当前关键帧至MapPoints，并更新MapPoints的平均观测方向和观测距离范围 * - 插入关键帧，更新Covisibility图和Essential图 * @see VI-A keyframe insertion */void LocalMapping::ProcessNewKeyFrame()&#123; // 步骤1：从缓冲队列中取出一帧关键帧 // Tracking线程向LocalMapping中插入关键帧存在该队列中 &#123; unique_lock&lt;mutex&gt; lock(mMutexNewKFs); // 从列表中获得一个等待被插入的关键帧 mpCurrentKeyFrame = mlNewKeyFrames.front(); mlNewKeyFrames.pop_front(); &#125; // Compute Bags of Words structures // 步骤2：计算该关键帧特征点的Bow映射关系 mpCurrentKeyFrame-&gt;ComputeBoW(); // Associate MapPoints to the new keyframe and update normal and descriptor // 步骤3：跟踪局部地图过程中新匹配上的MapPoints和当前关键帧绑定 // 在TrackLocalMap函数中将局部地图中的MapPoints与当前帧进行了匹配， // 但没有对这些匹配上的MapPoints与当前帧进行关联 const vector&lt;MapPoint*&gt; vpMapPointMatches = mpCurrentKeyFrame-&gt;GetMapPointMatches(); for(size_t i=0; i&lt;vpMapPointMatches.size(); i++) &#123; MapPoint* pMP = vpMapPointMatches[i]; if(pMP) &#123; if(!pMP-&gt;isBad()) &#123; // 非当前帧生成的MapPoints // 为当前帧在tracking过程跟踪到的MapPoints更新属性 if(!pMP-&gt;IsInKeyFrame(mpCurrentKeyFrame)) &#123; // 添加观测 pMP-&gt;AddObservation(mpCurrentKeyFrame, i); // 获得该点的平均观测方向和观测距离范围 pMP-&gt;UpdateNormalAndDepth(); // 加入关键帧后，更新3d点的最佳描述子 pMP-&gt;ComputeDistinctiveDescriptors(); &#125; else // this can only happen for new stereo points inserted by the Tracking &#123; // 当前帧生成的MapPoints // 将双目或RGBD跟踪过程中新插入的MapPoints放入mlpRecentAddedMapPoints，等待检查 // CreateNewMapPoints函数中通过三角化也会生成MapPoints // 这些MapPoints都会经过MapPointCulling函数的检验 mlpRecentAddedMapPoints.push_back(pMP); &#125; &#125; &#125; &#125; // Update links in the Covisibility Graph // 步骤4：更新关键帧间的连接关系，Covisibility图和Essential图(tree)，UpdateConnections()是根据observations进行更新关键帧之间的联系 mpCurrentKeyFrame-&gt;UpdateConnections(); // Insert Keyframe in Map // 步骤5：将该关键帧插入到地图中 mpMap-&gt;AddKeyFrame(mpCurrentKeyFrame);&#125; 2.6 剔除ProcessNewKeyFrame函数中引入的质量不好的MapPoints设立观测阈值，単目为2，双目为3遍历所有待检测的点进行剔除，剔除点的规则： 1.该点已经是坏点的MapPoints直接从检查链表中删除（该点已经被删除） 2.跟踪到该MapPoint的Frame数（即3D点可以找到对应的特征点）相比预计可观测到该MapPoint的Frame数（Observations可以观测到的）的比例需大于25% // IncreaseFound / IncreaseVisible &lt; 25%，注意不一定是关键帧，设定badflag，并从列表中删除该点 3.从该点建立开始，到现在已经过了不小于2个关键帧，但是观测到该点的关键帧数却不超过cnThObs（単目=2）帧，那么该点检验不合格，设定badflag，并从列表中删除该点 从建立该点开始，已经过了3个关键帧而没有被剔除，则认为是质量高的点，因此没有SetBadFlag()，仅从队列中删除，放弃继续对该MapPoint的检测123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @brief 剔除ProcessNewKeyFrame和CreateNewMapPoints函数中引入的质量不好的MapPoints * @see VI-B recent map points culling */void LocalMapping::MapPointCulling()&#123; // Check Recent Added MapPoints list&lt;MapPoint*&gt;::iterator lit = mlpRecentAddedMapPoints.begin(); const unsigned long int nCurrentKFid = mpCurrentKeyFrame-&gt;mnId; int nThObs; if(mbMonocular) nThObs = 2; else nThObs = 3; const int cnThObs = nThObs; // 遍历等待检查的MapPoints while(lit!=mlpRecentAddedMapPoints.end()) &#123; MapPoint* pMP = *lit; if(pMP-&gt;isBad()) &#123; // 步骤1：已经是坏点的MapPoints直接从检查链表中删除 lit = mlpRecentAddedMapPoints.erase(lit); &#125; else if(pMP-&gt;GetFoundRatio()&lt;0.25f) &#123; // 步骤2：将不满足VI-B条件的MapPoint剔除 // VI-B 条件1： // 跟踪到该MapPoint的Frame数相比预计可观测到该MapPoint的Frame数的比例需大于25% // IncreaseFound / IncreaseVisible &lt; 25%，注意不一定是关键帧。 pMP-&gt;SetBadFlag(); lit = mlpRecentAddedMapPoints.erase(lit); &#125; else if(((int)nCurrentKFid-(int)pMP-&gt;mnFirstKFid)&gt;=2 &amp;&amp; pMP-&gt;Observations()&lt;=cnThObs) &#123; // 步骤3：将不满足VI-B条件的MapPoint剔除 // VI-B 条件2：从该点建立开始，到现在已经过了不小于2个关键帧 // 但是观测到该点的关键帧数却不超过cnThObs帧，那么该点检验不合格 pMP-&gt;SetBadFlag(); lit = mlpRecentAddedMapPoints.erase(lit); &#125; else if(((int)nCurrentKFid-(int)pMP-&gt;mnFirstKFid)&gt;=3) // 步骤4：从建立该点开始，已经过了3个关键帧而没有被剔除，则认为是质量高的点 // 因此没有SetBadFlag()，仅从队列中删除，放弃继续对该MapPoint的检测 lit = mlpRecentAddedMapPoints.erase(lit); else lit++; &#125;&#125; 2.7 CreateNewMapPoints() 生成新的地图点 步骤一：在当前关键帧的共视关键帧中找到共视程度最高的nn帧相邻帧vpNeighKFs 123456// Retrieve neighbor keyframes in covisibility graphint nn = 10;if(mbMonocular) nn=20;// 步骤1：在当前关键帧的共视关键帧中找到共视程度最高的nn帧相邻帧vpNeighKFsconst vector&lt;KeyFrame*&gt; vpNeighKFs = mpCurrentKeyFrame-&gt;GetBestCovisibilityKeyFrames(nn); 步骤二：得到当前帧的位姿等相机信息，得到光心坐标，焦距等相机参数。 123456789101112131415161718cv::Mat Rcw1 = mpCurrentKeyFrame-&gt;GetRotation();cv::Mat Rwc1 = Rcw1.t();cv::Mat tcw1 = mpCurrentKeyFrame-&gt;GetTranslation();cv::Mat Tcw1(3,4,CV_32F);Rcw1.copyTo(Tcw1.colRange(0,3));tcw1.copyTo(Tcw1.col(3));// 得到当前关键帧在世界坐标系中的坐标cv::Mat Ow1 = mpCurrentKeyFrame-&gt;GetCameraCenter();const float &amp;fx1 = mpCurrentKeyFrame-&gt;fx;const float &amp;fy1 = mpCurrentKeyFrame-&gt;fy;const float &amp;cx1 = mpCurrentKeyFrame-&gt;cx;const float &amp;cy1 = mpCurrentKeyFrame-&gt;cy;const float &amp;invfx1 = mpCurrentKeyFrame-&gt;invfx;const float &amp;invfy1 = mpCurrentKeyFrame-&gt;invfy;const float ratioFactor = 1.5f*mpCurrentKeyFrame-&gt;mfScaleFactor; 步骤三：得到临近关键帧相机光心坐标，和当前帧的基线长度，然后和景深作比较，如果景深过深或者基线太短就放弃这一帧 123456789101112131415161718192021222324252627KeyFrame* pKF2 = vpNeighKFs[i];// Check first that baseline is not too short// 邻接的关键帧在世界坐标系中的坐标cv::Mat Ow2 = pKF2-&gt;GetCameraCenter();// 基线向量，两个关键帧间的相机位移cv::Mat vBaseline = Ow2-Ow1;// 基线长度const float baseline = cv::norm(vBaseline);// 步骤3：判断相机运动的基线是不是足够长if(!mbMonocular)&#123; // 如果是立体相机，关键帧间距太小时不生成3D点 if(baseline&lt;pKF2-&gt;mb) continue;&#125;else&#123; // 邻接关键帧的场景深度中值 const float medianDepthKF2 = pKF2-&gt;ComputeSceneMedianDepth(2); // baseline与景深的比例 const float ratioBaselineDepth = baseline/medianDepthKF2; // 如果特别远(比例特别小)，那么不考虑当前邻接的关键帧，不生成3D点 if(ratioBaselineDepth&lt;0.01) continue;&#125; 步骤四：根据两个关键帧的位姿计算它们之间的基本矩阵 123/ Compute Fundamental Matrix // 步骤4：根据两个关键帧的位姿计算它们之间的基本矩阵 cv::Mat F12 = ComputeF12(mpCurrentKeyFrame,pKF2); 步骤五：根据这两帧计算F矩阵，根据矩阵计算匹配点索引，存在vMatchedIndices里，通过极线约束限制匹配时的搜索范围，进行特征点匹配，vector]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析十]]></title>
    <url>%2F2019%2F06%2F14%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8D%81%2F</url>
    <content type="text"><![CDATA[KeyFrame 类说明1234/* KeyFrame * 关键帧，和普通的Frame不一样，但是可以由Frame来构造 * 许多数据会被三个线程同时访问，所以用锁的地方很普遍 */ 1. KeyFrame 类成员变量说明1.1 关键帧id和下一个关键帧id,nNextId用于计数1234// nNextID名字改为nLastID更合适，表示上一个KeyFrame的ID号static long unsigned int nNextId;// 在nNextID的基础上加1就得到了mnID，为当前KeyFrame的ID号long unsigned int mnId; 1.2 mnFrameId记录了该KeyFrame是由哪个Frame初始化的123// 每个KeyFrame基本属性是它是一个Frame，KeyFrame初始化的时候需要Frame，// mnFrameId记录了该KeyFrame是由哪个Frame初始化的const long unsigned int mnFrameId; 1.3 该关键帧的时间戳1const double mTimeStamp; 1.4 网格信息，和Frame中定义的一样，用于加速特征匹配123456// Grid (to speed up feature matching)// 和Frame类中的定义相同const int mnGridCols;const int mnGridRows;const float mfGridElementWidthInv;const float mfGridElementHeightInv; 1.5 用于Tracking的变量123 // Variables used by the trackinglong unsigned int mnTrackReferenceForFrame;long unsigned int mnFuseTargetForKF; 1.6 用于local mapping的变量123// Variables used by the local mappinglong unsigned int mnBALocalForKF;long unsigned int mnBAFixedForKF; 1.7 用于关键帧数据库的变量1234567// Variables used by the keyframe databaselong unsigned int mnLoopQuery;int mnLoopWords;float mLoopScore;long unsigned int mnRelocQuery;int mnRelocWords;float mRelocScore; 1.8 用于回环检测的变量1234// Variables used by loop closing cv::Mat mTcwGBA; cv::Mat mTcwBefGBA; long unsigned int mnBAGlobalForKF; 1.9 相机参数12// Calibration parametersconst float fx, fy, cx, cy, invfx, invfy, mbf, mb, mThDepth; 1.10 特征点数目12// Number of KeyPointsconst int N; 1.11 Bow信息123//BoWDBoW2::BowVector mBowVec; ///&lt; Vector of words to represent imagesDBoW2::FeatureVector mFeatVec; ///&lt; Vector of nodes with indexes of local features 1.12 相对于父关键帧的位姿12// Pose relative to parent (this is computed when bad flag is activated) cv::Mat mTcp; 1.13 尺度信息1234567// Scaleconst int mnScaleLevels;const float mfScaleFactor;const float mfLogScaleFactor;const std::vector&lt;float&gt; mvScaleFactors;// 尺度因子，scale^n，scale=1.2，n为层数const std::vector&lt;float&gt; mvLevelSigma2;// 尺度因子的平方const std::vector&lt;float&gt; mvInvLevelSigma2; 1.14 图像边界1234const int mnMinX;const int mnMinY;const int mnMaxX;const int mnMaxY; 1.15 相机内参1const cv::Mat mK; 1.16 相机位姿12345// SE3 Pose and camera centercv::Mat Tcw;cv::Mat Twc;cv::Mat Ow;cv::Mat Cw; // Stereo middel point. Only for visualization 1.17 关键帧地图点12// MapPoints associated to keypoints std::vector&lt;MapPoint*&gt; mvpMapPoints; 1.18 Bow123// BoWKeyFrameDatabase* mpKeyFrameDB;ORBVocabulary* mpORBvocabulary; 1.19 网格划分12// Grid over the image to speed up feature matching std::vector&lt; std::vector &lt;std::vector&lt;size_t&gt; &gt; &gt; mGrid; 1.20 共视图信息1234// Covisibility Graphstd::map&lt;KeyFrame*,int&gt; mConnectedKeyFrameWeights; ///&lt; 与该关键帧连接的关键帧与权重std::vector&lt;KeyFrame*&gt; mvpOrderedConnectedKeyFrames; ///&lt; 排序后的关键帧std::vector&lt;int&gt; mvOrderedWeights; ///&lt; 排序后的权重(从大到小) 1.21 生成树信息123456// Spanning Tree and Loop Edges // std::set是集合，相比vector，进行插入数据这样的操作时会自动排序 bool mbFirstConnection; KeyFrame* mpParent; std::set&lt;KeyFrame*&gt; mspChildrens; std::set&lt;KeyFrame*&gt; mspLoopEdges; 1.22 Bad flags1234// Bad flagsbool mbNotErase;bool mbToBeErased;bool mbBad; 1.23 mHalfBaseline1float mHalfBaseline; // Only for visualization 1.24 map指针1Map* mpMap; 2. KeyFrame 成员函数说明2.1 构造函数传入图像帧，地图指针，以及关键帧数据库指针来建立关键帧，用传入的图像帧来赋值关键帧1KeyFrame(Frame &amp;F, Map *pMap, KeyFrameDatabase *pKFDB); 2.2 计算Bow12345678910111213141516/** * @brief Bag of Words Representation * * 计算mBowVec，并且将描述子分散在第4层上，即mFeatVec记录了属于第i个node的ni个描述子 * @see ProcessNewKeyFrame() */void KeyFrame::ComputeBoW()&#123; if(mBowVec.empty() || mFeatVec.empty()) &#123; vector&lt;cv::Mat&gt; vCurrentDesc = Converter::toDescriptorVector(mDescriptors); // Feature vector associate features with nodes in the 4th level (from leaves up) // We assume the vocabulary tree has 6 levels, change the 4 otherwise mpORBvocabulary-&gt;transform(vCurrentDesc,mBowVec,mFeatVec,4); &#125;&#125; 2.3 设置相机参数，计算$T_{cw},R_{cw},t_{cw},T_{wc},R_{wc},t_{wc}$12345678910111213141516171819void KeyFrame::SetPose(const cv::Mat &amp;Tcw_)&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); Tcw_.copyTo(Tcw); cv::Mat Rcw = Tcw.rowRange(0,3).colRange(0,3); cv::Mat tcw = Tcw.rowRange(0,3).col(3); cv::Mat Rwc = Rcw.t(); Ow = -Rwc*tcw; Twc = cv::Mat::eye(4,4,Tcw.type()); Rwc.copyTo(Twc.rowRange(0,3).colRange(0,3)); Ow.copyTo(Twc.rowRange(0,3).col(3)); // center为相机坐标系（左目）下，立体相机中心的坐标 // 立体相机中心点坐标与左目相机坐标之间只是在x轴上相差mHalfBaseline, // 因此可以看出，立体相机中两个摄像头的连线为x轴，正方向为左目相机指向右目相机 cv::Mat center = (cv::Mat_&lt;float&gt;(4,1) &lt;&lt; mHalfBaseline, 0 , 0, 1); // 世界坐标系下，左目相机中心到立体相机中心的向量，方向由左目相机指向立体相机中心 Cw = Twc*center;&#125; 2.4 GetPose12345cv::Mat KeyFrame::GetPose()&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); return Tcw.clone();&#125; 2.5 GetPoseInverse12345cv::Mat KeyFrame::GetPoseInverse()&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); return Twc.clone();&#125; 2.6 GetCameraCenter12345cv::Mat KeyFrame::GetCameraCenter()&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); return Ow.clone();&#125; 2.7 GetStereoCenter12345cv::Mat KeyFrame::GetStereoCenter()&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); return Cw.clone();&#125; 2.8 GetRotation12345cv::Mat KeyFrame::GetRotation()&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); return Tcw.rowRange(0,3).colRange(0,3).clone();&#125; 2.9 GetTranslation12345cv::Mat KeyFrame::GetTranslation()&#123; unique_lock&lt;mutex&gt; lock(mMutexPose); return Tcw.rowRange(0,3).col(3).clone();&#125; 2.10 为关键帧之间添加连接12345678910111213141516171819202122/** * @brief 为关键帧之间添加连接 * * 更新了mConnectedKeyFrameWeights * @param pKF 关键帧 * @param weight 权重，该关键帧与pKF共同观测到的3d点数量 */void KeyFrame::AddConnection(KeyFrame *pKF, const int &amp;weight)&#123; &#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); // std::map::count函数只可能返回0或1两种情况 if(!mConnectedKeyFrameWeights.count(pKF)) // count函数返回0，mConnectedKeyFrameWeights中没有pKF，之前没有连接 mConnectedKeyFrameWeights[pKF]=weight; else if(mConnectedKeyFrameWeights[pKF]!=weight) // 之前连接的权重不一样 mConnectedKeyFrameWeights[pKF]=weight; else return; &#125; UpdateBestCovisibles();&#125; 2.11 按权重对关键帧进行排序,从大到小关键帧放在mvpOrderedConnectedKeyFrames中，权重值存放在mvOrderedWeights中1234567891011121314151617181920212223242526272829/** * @brief 按照权重对连接的关键帧进行排序 * * 更新后的变量存储在mvpOrderedConnectedKeyFrames和mvOrderedWeights中 */void KeyFrame::UpdateBestCovisibles()&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); // http://stackoverflow.com/questions/3389648/difference-between-stdliststdpair-and-stdmap-in-c-stl vector&lt;pair&lt;int,KeyFrame*&gt; &gt; vPairs; vPairs.reserve(mConnectedKeyFrameWeights.size()); // 取出所有连接的关键帧，mConnectedKeyFrameWeights的类型为std::map&lt;KeyFrame*,int&gt;，而vPairs变量将共视的3D点数放在前面，利于排序 for(map&lt;KeyFrame*,int&gt;::iterator mit=mConnectedKeyFrameWeights.begin(), mend=mConnectedKeyFrameWeights.end(); mit!=mend; mit++) vPairs.push_back(make_pair(mit-&gt;second,mit-&gt;first)); // 按照权重进行排序 sort(vPairs.begin(),vPairs.end()); list&lt;KeyFrame*&gt; lKFs; // keyframe list&lt;int&gt; lWs; // weight for(size_t i=0, iend=vPairs.size(); i&lt;iend;i++) &#123; lKFs.push_front(vPairs[i].second); lWs.push_front(vPairs[i].first); &#125; // 权重从大到小 mvpOrderedConnectedKeyFrames = vector&lt;KeyFrame*&gt;(lKFs.begin(),lKFs.end()); mvOrderedWeights = vector&lt;int&gt;(lWs.begin(), lWs.end());&#125; 2.12 得到与该关键帧连接的关键帧，返回的是是关键帧set123456789101112/** * @brief 得到与该关键帧连接的关键帧 * @return 连接的关键帧 */set&lt;KeyFrame*&gt; KeyFrame::GetConnectedKeyFrames()&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); set&lt;KeyFrame*&gt; s; for(map&lt;KeyFrame*,int&gt;::iterator mit=mConnectedKeyFrameWeights.begin();mit!=mConnectedKeyFrameWeights.end();mit++) s.insert(mit-&gt;first); return s;&#125; 2.13 得到与该关键帧连接的关键帧(已按权值排序),返回mvpOrderedConnectedKeyFrames，是一个vector123456789/** * @brief 得到与该关键帧连接的关键帧(已按权值排序) * @return 连接的关键帧 */vector&lt;KeyFrame*&gt; KeyFrame::GetVectorCovisibleKeyFrames()&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); return mvpOrderedConnectedKeyFrames;&#125; 2.14 得到与该关键帧连接的前N个关键帧(已按权值排序)123456789101112131415/** * @brief 得到与该关键帧连接的前N个关键帧(已按权值排序) * * 如果连接的关键帧少于N，则返回所有连接的关键帧 * @param N 前N个 * @return 连接的关键帧 */vector&lt;KeyFrame*&gt; KeyFrame::GetBestCovisibilityKeyFrames(const int &amp;N)&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); if((int)mvpOrderedConnectedKeyFrames.size()&lt;N) return mvpOrderedConnectedKeyFrames; else return vector&lt;KeyFrame*&gt;(mvpOrderedConnectedKeyFrames.begin(),mvpOrderedConnectedKeyFrames.begin()+N);&#125; 2.15 得到与该关键帧连接的权重大于等于w的关键帧，返回的是一个vector，已排序12345678910111213141516171819202122232425/** * @brief 得到与该关键帧连接的权重大于等于w的关键帧 * @param w 权重 * @return 连接的关键帧 */vector&lt;KeyFrame*&gt; KeyFrame::GetCovisiblesByWeight(const int &amp;w)&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); if(mvpOrderedConnectedKeyFrames.empty()) return vector&lt;KeyFrame*&gt;(); // http://www.cplusplus.com/reference/algorithm/upper_bound/ // 从mvOrderedWeights找出第一个大于w的那个迭代器 // 这里应该使用lower_bound，因为lower_bound是返回小于等于，而upper_bound只能返回第一个大于的 // 自注释：这里没问题，因为自定义的比较函数weightComp是按大于排序的 vector&lt;int&gt;::iterator it = upper_bound(mvOrderedWeights.begin(),mvOrderedWeights.end(),w,KeyFrame::weightComp); if(it==mvOrderedWeights.end() &amp;&amp; *mvOrderedWeights.rbegin()&lt;w) return vector&lt;KeyFrame*&gt;(); else &#123; int n = it-mvOrderedWeights.begin(); return vector&lt;KeyFrame*&gt;(mvpOrderedConnectedKeyFrames.begin(), mvpOrderedConnectedKeyFrames.begin()+n); &#125;&#125; 2.16 得到该关键帧与pKF的权重12345678910111213/** * @brief 得到该关键帧与pKF的权重 * @param pKF 关键帧 * @return 权重 */int KeyFrame::GetWeight(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); if(mConnectedKeyFrameWeights.count(pKF)) return mConnectedKeyFrameWeights[pKF]; else return 0;&#125; 2.17 在关键帧中添加地图点，需要指定地图点的序号，也就是对应的特征点序号12345678910/** * @brief Add MapPoint to KeyFrame * @param pMP MapPoint * @param idx MapPoint在KeyFrame中的索引 */void KeyFrame::AddMapPoint(MapPoint *pMP, const size_t &amp;idx)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); mvpMapPoints[idx]=pMP;&#125; 2.18 传入地图点序号，清除地图点12345void KeyFrame::EraseMapPointMatch(const size_t &amp;idx)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); mvpMapPoints[idx]=static_cast&lt;MapPoint*&gt;(NULL);&#125; 2.19 传入地图点指针，清除地图点123456void KeyFrame::EraseMapPointMatch(MapPoint* pMP)&#123; int idx = pMP-&gt;GetIndexInKeyFrame(this); if(idx&gt;=0) mvpMapPoints[idx]=static_cast&lt;MapPoint*&gt;(NULL);&#125; 2.20 传入地图点序号和新的地图点指针，替换原来的地图点1234void KeyFrame::ReplaceMapPointMatch(const size_t &amp;idx, MapPoint* pMP)&#123; mvpMapPoints[idx]=pMP;&#125; 2.21 返回地图点set集合，判断每一个地图点是否为空，该地图点是否是坏点1234567891011121314set&lt;MapPoint*&gt; KeyFrame::GetMapPoints()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); set&lt;MapPoint*&gt; s; for(size_t i=0, iend=mvpMapPoints.size(); i&lt;iend; i++) &#123; if(!mvpMapPoints[i]) continue; MapPoint* pMP = mvpMapPoints[i]; if(!pMP-&gt;isBad()) s.insert(pMP); &#125; return s;&#125; 2.22 关键帧中，大于等于minObs的MapPoints的数量，判断每一个地图点是否为空，该地图点是否是坏点，该地图点的观测关键帧是否大于阈值123456789101112131415161718192021222324252627282930313233/** * @brief 关键帧中，大于等于minObs的MapPoints的数量 * minObs就是一个阈值，大于minObs就表示该MapPoint是一个高质量的MapPoint * 一个高质量的MapPoint会被多个KeyFrame观测到， * @param minObs 最小观测 */int KeyFrame::TrackedMapPoints(const int &amp;minObs)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); int nPoints=0; const bool bCheckObs = minObs&gt;0; for(int i=0; i&lt;N; i++) &#123; MapPoint* pMP = mvpMapPoints[i]; if(pMP) &#123; if(!pMP-&gt;isBad()) &#123; if(bCheckObs) &#123; // 该MapPoint是一个高质量的MapPoint if(mvpMapPoints[i]-&gt;Observations()&gt;=minObs) nPoints++; &#125; else nPoints++; &#125; &#125; &#125; return nPoints;&#125; 2.23 获得该关键帧所有的MapPoints12345678910/** * @brief Get MapPoint Matches * * 获取该关键帧的MapPoints */vector&lt;MapPoint*&gt; KeyFrame::GetMapPointMatches()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return mvpMapPoints;&#125; 2.24 通过地图点的序号来获得关键帧地图点12345MapPoint* KeyFrame::GetMapPoint(const size_t &amp;idx)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return mvpMapPoints[idx];&#125; 2.25 新建一个关键帧后，更新共视图的连接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * @brief 更新图的连接 * * 1. 首先获得该关键帧的所有MapPoint点，统计观测到这些3d点的每个关键帧与该帧图像的共视程度， * 对每一个找到的关键帧，建立一条边，边的权重是该关键帧与当前关键帧公共3d点的个数。 * 2. 并且该权重必须大于一个阈值，如果没有超过该阈值的权重，那么就只保留权重最大的边（与其它关键帧的共视程度比较高） * 3. 对这些连接按照权重从大到小进行排序，以方便将来的处理 * 更新完covisibility图之后，如果没有初始化过，则初始化为连接权重最大的边（与其它关键帧共视程度最高的那个关键帧），类似于最大生成树 */void KeyFrame::UpdateConnections()&#123; // 在没有执行这个函数前，关键帧只和MapPoints之间有连接关系，这个函数可以更新关键帧之间的连接关系 //===============1================================== map&lt;KeyFrame*,int&gt; KFcounter; // 关键帧-权重，权重为其它关键帧与当前关键帧共视3d点的个数 vector&lt;MapPoint*&gt; vpMP; &#123; // 获得该关键帧的所有3D点 unique_lock&lt;mutex&gt; lockMPs(mMutexFeatures); vpMP = mvpMapPoints; &#125; //For all map points in keyframe check in which other keyframes are they seen //Increase counter for those keyframes // 通过3D点间接统计可以观测到这些3D点的所有关键帧之间的共视程度 // 即统计每一个关键帧都有多少关键帧与它存在共视关系，统计结果放在KFcounter for(vector&lt;MapPoint*&gt;::iterator vit=vpMP.begin(), vend=vpMP.end(); vit!=vend; vit++) &#123; MapPoint* pMP = *vit; if(!pMP) continue; if(pMP-&gt;isBad()) continue; // 对于每一个MapPoint点，observations记录了可以观测到该MapPoint的所有关键帧 map&lt;KeyFrame*,size_t&gt; observations = pMP-&gt;GetObservations(); for(map&lt;KeyFrame*,size_t&gt;::iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++) &#123; // 除去自身，自己与自己不算共视 if(mit-&gt;first-&gt;mnId==mnId) continue; KFcounter[mit-&gt;first]++; &#125; &#125; // This should not happen if(KFcounter.empty()) return; //===============2================================== // If the counter is greater than threshold add connection // In case no keyframe counter is over threshold add the one with maximum counter int nmax=0; KeyFrame* pKFmax=NULL; int th = 15; // vPairs记录与其它关键帧共视帧数大于th的关键帧 // pair&lt;int,KeyFrame*&gt;将关键帧的权重写在前面，关键帧写在后面方便后面排序 vector&lt;pair&lt;int,KeyFrame*&gt; &gt; vPairs; vPairs.reserve(KFcounter.size()); for(map&lt;KeyFrame*,int&gt;::iterator mit=KFcounter.begin(), mend=KFcounter.end(); mit!=mend; mit++) &#123; if(mit-&gt;second&gt;nmax) &#123; nmax=mit-&gt;second; // 找到对应权重最大的关键帧（共视程度最高的关键帧） pKFmax=mit-&gt;first; &#125; if(mit-&gt;second&gt;=th) &#123; // 对应权重需要大于阈值，对这些关键帧建立连接 vPairs.push_back(make_pair(mit-&gt;second,mit-&gt;first)); // 更新KFcounter中该关键帧的mConnectedKeyFrameWeights // 更新其它KeyFrame的mConnectedKeyFrameWeights，更新其它关键帧与当前帧的连接权重 (mit-&gt;first)-&gt;AddConnection(this,mit-&gt;second); &#125; &#125; // 如果没有超过阈值的权重，则对权重最大的关键帧建立连接 if(vPairs.empty()) &#123; // 如果每个关键帧与它共视的关键帧的个数都少于th， // 那就只更新与其它关键帧共视程度最高的关键帧的mConnectedKeyFrameWeights // 这是对之前th这个阈值可能过高的一个补丁 vPairs.push_back(make_pair(nmax,pKFmax)); pKFmax-&gt;AddConnection(this,nmax); &#125; // vPairs里存的都是相互共视程度比较高的关键帧和共视权重，由小到大 sort(vPairs.begin(),vPairs.end()); // lKFs 和 lWs 排序都是从大到小 list&lt;KeyFrame*&gt; lKFs; list&lt;int&gt; lWs; for(size_t i=0; i&lt;vPairs.size();i++) &#123; lKFs.push_front(vPairs[i].second); lWs.push_front(vPairs[i].first); &#125; //===============3================================== &#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); // mspConnectedKeyFrames = spConnectedKeyFrames; // 更新图的连接(权重) mConnectedKeyFrameWeights = KFcounter;//更新该KeyFrame的mConnectedKeyFrameWeights，更新当前帧与其它关键帧的连接权重 mvpOrderedConnectedKeyFrames = vector&lt;KeyFrame*&gt;(lKFs.begin(),lKFs.end()); mvOrderedWeights = vector&lt;int&gt;(lWs.begin(), lWs.end()); // 更新生成树的连接 if(mbFirstConnection &amp;&amp; mnId!=0) &#123; // 初始化该关键帧的父关键帧为共视程度最高的那个关键帧 mpParent = mvpOrderedConnectedKeyFrames.front(); // 建立双向连接关系 mpParent-&gt;AddChild(this); mbFirstConnection = false; &#125; &#125;&#125; 2.26 增加子树节点12345void KeyFrame::AddChild(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); mspChildrens.insert(pKF);&#125; 2.27 删除子树节点12345void KeyFrame::EraseChild(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); mspChildrens.erase(pKF);&#125; 2.28 改变父节点123456void KeyFrame::ChangeParent(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); mpParent = pKF; pKF-&gt;AddChild(this);&#125; 2.29 获得所有子树节点set12345set&lt;KeyFrame*&gt; KeyFrame::GetChilds()&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); return mspChildrens;&#125; 2.30 获得该帧的父节点12345KeyFrame* KeyFrame::GetParent()&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); return mpParent;&#125; 2.31 判断某一帧是否含有某一个关键帧子节点12345bool KeyFrame::hasChild(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); return mspChildrens.count(pKF);&#125; 2.32 将某一关键帧加入回环边集合123456void KeyFrame::AddLoopEdge(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); mbNotErase = true; mspLoopEdges.insert(pKF);&#125; 2.33 获得回环关键帧集合12345set&lt;KeyFrame*&gt; KeyFrame::GetLoopEdges()&#123; unique_lock&lt;mutex&gt; lockCon(mMutexConnections); return mspLoopEdges;&#125; 2.34 设置某一关键帧不可擦除12345void KeyFrame::SetNotErase()&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); mbNotErase = true;&#125; 2.35 删除关键帧，修改父子连接关系123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111void KeyFrame::SetBadFlag()&#123; &#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); if(mnId==0) return; else if(mbNotErase)// mbNotErase表示不应该擦除该KeyFrame，于是把mbToBeErased置为true，表示已经擦除了，其实没有擦除 &#123; mbToBeErased = true; return; &#125; &#125; for(map&lt;KeyFrame*,int&gt;::iterator mit = mConnectedKeyFrameWeights.begin(), mend=mConnectedKeyFrameWeights.end(); mit!=mend; mit++) mit-&gt;first-&gt;EraseConnection(this);// 让其它的KeyFrame删除与自己的联系 for(size_t i=0; i&lt;mvpMapPoints.size(); i++) if(mvpMapPoints[i]) mvpMapPoints[i]-&gt;EraseObservation(this);// 让与自己有联系的MapPoint删除与自己的联系 &#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); unique_lock&lt;mutex&gt; lock1(mMutexFeatures); //清空自己与其它关键帧之间的联系 mConnectedKeyFrameWeights.clear(); mvpOrderedConnectedKeyFrames.clear(); // Update Spanning Tree set&lt;KeyFrame*&gt; sParentCandidates; sParentCandidates.insert(mpParent); // Assign at each iteration one children with a parent (the pair with highest covisibility weight) // Include that children as new parent candidate for the rest // 如果这个关键帧有自己的孩子关键帧，告诉这些子关键帧，它们的父关键帧不行了，赶紧找新的父关键帧 while(!mspChildrens.empty()) &#123; bool bContinue = false; int max = -1; KeyFrame* pC; KeyFrame* pP; // 遍历每一个子关键帧，让它们更新它们指向的父关键帧 for(set&lt;KeyFrame*&gt;::iterator sit=mspChildrens.begin(), send=mspChildrens.end(); sit!=send; sit++) &#123; KeyFrame* pKF = *sit; if(pKF-&gt;isBad()) continue; // Check if a parent candidate is connected to the keyframe // 子关键帧遍历每一个与它相连的关键帧（共视关键帧） vector&lt;KeyFrame*&gt; vpConnected = pKF-&gt;GetVectorCovisibleKeyFrames(); for(size_t i=0, iend=vpConnected.size(); i&lt;iend; i++) &#123; for(set&lt;KeyFrame*&gt;::iterator spcit=sParentCandidates.begin(), spcend=sParentCandidates.end(); spcit!=spcend; spcit++) &#123; // 如果该帧的子节点和父节点（祖孙节点）之间存在连接关系（共视） // 举例：B--&gt;A（B的父节点是A） C--&gt;B（C的父节点是B） D--C（D与C相连） E--C（E与C相连） F--C（F与C相连） D--&gt;A（D的父节点是A） E--&gt;A（E的父节点是A） // 现在B挂了，于是C在与自己相连的D、E、F节点中找到父节点指向A的D // 此过程就是为了找到可以替换B的那个节点。 // 上面例子中，B为当前要设置为SetBadFlag的关键帧 // A为spcit，也即sParentCandidates // C为pKF,pC，也即mspChildrens中的一个 // D、E、F为vpConnected中的变量，由于C与D间的权重 比 C与E间的权重大，因此D为pP if(vpConnected[i]-&gt;mnId == (*spcit)-&gt;mnId) &#123; int w = pKF-&gt;GetWeight(vpConnected[i]); if(w&gt;max) &#123; pC = pKF; pP = vpConnected[i]; max = w; bContinue = true; &#125; &#125; &#125; &#125; &#125; if(bContinue) &#123; // 因为父节点死了，并且子节点找到了新的父节点，子节点更新自己的父节点 pC-&gt;ChangeParent(pP); // 因为子节点找到了新的父节点并更新了父节点，那么该子节点升级，作为其它子节点的备选父节点 sParentCandidates.insert(pC); // 该子节点处理完毕 mspChildrens.erase(pC); &#125; else break; &#125; // If a children has no covisibility links with any parent candidate, assign to the original parent of this KF // 如果还有子节点没有找到新的父节点 if(!mspChildrens.empty()) for(set&lt;KeyFrame*&gt;::iterator sit=mspChildrens.begin(); sit!=mspChildrens.end(); sit++) &#123; // 直接把父节点的父节点作为自己的父节点 (*sit)-&gt;ChangeParent(mpParent); &#125; mpParent-&gt;EraseChild(this); mTcp = Tcw*mpParent-&gt;GetPoseInverse(); mbBad = true; &#125; mpMap-&gt;EraseKeyFrame(this); mpKeyFrameDB-&gt;erase(this);&#125; 2.36 判断一帧图像是否是坏帧，即是否已经被删除12345bool KeyFrame::isBad()&#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); return mbBad;&#125; 2.37 删除与某一帧的联系，并没有删除该关键帧123456789101112131415void KeyFrame::EraseConnection(KeyFrame* pKF)&#123; bool bUpdate = false; &#123; unique_lock&lt;mutex&gt; lock(mMutexConnections); if(mConnectedKeyFrameWeights.count(pKF)) &#123; mConnectedKeyFrameWeights.erase(pKF); bUpdate=true; &#125; &#125; if(bUpdate) UpdateBestCovisibles();&#125; 2.38 找到在以x,y为中心，边长为2r的方形内特征点，先遍历该圆域区间所属的边长为2r的格子区间内的所有特征点，再判断该点的尺度信息是否满足要求，再判断该特征点离中心点的距离是否满足半径要求，返回该区间的所有的特征点，参考普通帧的GetFeaturesInArea函数12345678910111213141516171819202122232425262728293031323334353637383940414243// r为边长（半径）vector&lt;size_t&gt; KeyFrame::GetFeaturesInArea(const float &amp;x, const float &amp;y, const float &amp;r) const&#123; vector&lt;size_t&gt; vIndices; vIndices.reserve(N); // floor向下取整，mfGridElementWidthInv为每个像素占多少个格子 const int nMinCellX = max(0,(int)floor((x-mnMinX-r)*mfGridElementWidthInv)); if(nMinCellX&gt;=mnGridCols) return vIndices; // ceil向上取整 const int nMaxCellX = min((int)mnGridCols-1,(int)ceil((x-mnMinX+r)*mfGridElementWidthInv)); if(nMaxCellX&lt;0) return vIndices; const int nMinCellY = max(0,(int)floor((y-mnMinY-r)*mfGridElementHeightInv)); if(nMinCellY&gt;=mnGridRows) return vIndices; const int nMaxCellY = min((int)mnGridRows-1,(int)ceil((y-mnMinY+r)*mfGridElementHeightInv)); if(nMaxCellY&lt;0) return vIndices; for(int ix = nMinCellX; ix&lt;=nMaxCellX; ix++) &#123; for(int iy = nMinCellY; iy&lt;=nMaxCellY; iy++) &#123; const vector&lt;size_t&gt; vCell = mGrid[ix][iy]; for(size_t j=0, jend=vCell.size(); j&lt;jend; j++) &#123; const cv::KeyPoint &amp;kpUn = mvKeysUn[vCell[j]]; const float distx = kpUn.pt.x-x; const float disty = kpUn.pt.y-y; if(fabs(distx)&lt;r &amp;&amp; fabs(disty)&lt;r) vIndices.push_back(vCell[j]); &#125; &#125; &#125; return vIndices;&#125; 2.39 判断某个坐标点是否在图像内1234bool KeyFrame::IsInImage(const float &amp;x, const float &amp;y) const&#123; return (x&gt;=mnMinX &amp;&amp; x&lt;mnMaxX &amp;&amp; y&gt;=mnMinY &amp;&amp; y&lt;mnMaxY);&#125; 2.40 双目立体投影123456789101112131415161718192021222324252627282930/** * @brief Backprojects a keypoint (if stereo/depth info available) into 3D world coordinates. * @param i 第i个keypoint * @return 3D点（相对于世界坐标系） */cv::Mat KeyFrame::UnprojectStereo(int i)&#123; const float z = mvDepth[i]; if(z&gt;0) &#123; // 由2维图像反投影到相机坐标系 // mvDepth是在ComputeStereoMatches函数中求取的 // mvDepth对应的校正前的特征点，因此这里对校正前特征点反投影 // 可在Frame::UnprojectStereo中却是对校正后的特征点mvKeysUn反投影 // 在ComputeStereoMatches函数中应该对校正后的特征点求深度？？ (wubo???) const float u = mvKeys[i].pt.x; const float v = mvKeys[i].pt.y; const float x = (u-cx)*z*invfx; const float y = (v-cy)*z*invfy; cv::Mat x3Dc = (cv::Mat_&lt;float&gt;(3,1) &lt;&lt; x, y, z); unique_lock&lt;mutex&gt; lock(mMutexPose); // 由相机坐标系转换到世界坐标系 // Twc为相机坐标系到世界坐标系的变换矩阵 // Twc.rosRange(0,3).colRange(0,3)取Twc矩阵的前3行与前3列 return Twc.rowRange(0,3).colRange(0,3)*x3Dc+Twc.rowRange(0,3).col(3); &#125; else return cv::Mat();&#125; 2.41 计算并返回所有地图点的深度中值123456789101112131415161718192021222324252627282930313233343536/** * @brief 评估当前关键帧场景深度，q=2表示中值 * @param q q=2 * @return Median Depth */float KeyFrame::ComputeSceneMedianDepth(const int q)&#123; vector&lt;MapPoint*&gt; vpMapPoints; cv::Mat Tcw_; &#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); unique_lock&lt;mutex&gt; lock2(mMutexPose); vpMapPoints = mvpMapPoints; Tcw_ = Tcw.clone(); &#125; vector&lt;float&gt; vDepths; vDepths.reserve(N); cv::Mat Rcw2 = Tcw_.row(2).colRange(0,3); Rcw2 = Rcw2.t(); float zcw = Tcw_.at&lt;float&gt;(2,3); for(int i=0; i&lt;N; i++) &#123; if(mvpMapPoints[i]) &#123; MapPoint* pMP = mvpMapPoints[i]; cv::Mat x3Dw = pMP-&gt;GetWorldPos(); float z = Rcw2.dot(x3Dw)+zcw; // (R*x3Dw+t)的第三行，即z vDepths.push_back(z); &#125; &#125; sort(vDepths.begin(),vDepths.end()); return vDepths[(vDepths.size()-1)/q];&#125;]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析九]]></title>
    <url>%2F2019%2F06%2F14%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%9D%2F</url>
    <content type="text"><![CDATA[Frame 类说明1. Frame 类成员变量说明1.1 用于重定位的词典12// Vocabulary used for relocalization.ORBVocabulary* mpORBvocabulary; 1.2 当前帧的特征提取器12// Feature extractor. The right is used only in the stereo case. ORBextractor* mpORBextractorLeft, *mpORBextractorRight; 1.3 当前帧的时间戳12// Frame timestamp. double mTimeStamp; 1.3 当前帧的时间戳12// Frame timestamp. double mTimeStamp; 1.3 当前帧的时间戳12// Frame timestamp. double mTimeStamp; 1.4 相机参数123456789101112131415// Calibration matrix and OpenCV distortion parameters. cv::Mat mK; static float fx; static float fy; static float cx; static float cy; static float invfx; static float invfy; cv::Mat mDistCoef; // Stereo baseline multiplied by fx. float mbf; // Stereo baseline in meters. float mb; 1.4 截断深度123// Threshold close/far points. Close points are inserted from 1 view. // Far points are inserted as in the monocular case from 2 views. float mThDepth; 1.5 特征点的数目12// Number of KeyPoints. int N; ///&lt; KeyPoints数量 1.6 特征点Vector12345678// Vector of keypoints (original for visualization) and undistorted (actually used by the system).// In the stereo case, mvKeysUn is redundant as images must be rectified.// In the RGB-D case, RGB images can be distorted.// mvKeys:原始左图像提取出的特征点（未校正）// mvKeysRight:原始右图像提取出的特征点（未校正）// mvKeysUn:校正mvKeys后的特征点，对于双目摄像头，一般得到的图像都是校正好的，再校正一次有点多余std::vector&lt;cv::KeyPoint&gt; mvKeys, mvKeysRight;std::vector&lt;cv::KeyPoint&gt; mvKeysUn; 1.7 特征点的双目信息1234567// Corresponding stereo coordinate and depth for each keypoint. // "Monocular" keypoints have a negative value. // 对于双目，mvuRight存储了左目像素点在右目中的对应点的横坐标 // mvDepth对应的深度 // 单目摄像头，这两个容器中存的都是-1 std::vector&lt;float&gt; mvuRight; std::vector&lt;float&gt; mvDepth; 1.8 当前帧的Bow以及特征点的Bow123// Bag of Words Vector structures. DBoW2::BowVector mBowVec; DBoW2::FeatureVector mFeatVec; 1.9 当前帧的描述子123// ORB descriptor, each row associated to a keypoint. // 左目摄像头和右目摄像头特征点对应的描述子 cv::Mat mDescriptors, mDescriptorsRight; 1.10 每个特征点对应的MapPoints123// MapPoints associated to keypoints, NULL pointer if no association. // 每个特征点对应的MapPoint std::vector&lt;MapPoint*&gt; mvpMapPoints; 1.11 特征点是否是Outlier的flag123// Flag to identify outlier associations. // 观测不到Map中的3D点 std::vector&lt;bool&gt; mvbOutlier; 1.12 Frame 网格信息划分 mGrid[FRAME_GRID_COLS][FRAME_GRID_ROWS]记录每一个网格包含的特征点的序号vector12345678// Keypoints are assigned to cells in a grid to reduce matching complexity when projecting MapPoints. // 坐标乘以mfGridElementWidthInv和mfGridElementHeightInv就可以确定在哪个格子 static float mfGridElementWidthInv; static float mfGridElementHeightInv; // 每个格子分配的特征点数，将图像分成格子，保证提取的特征点比较均匀 // FRAME_GRID_ROWS 48 // FRAME_GRID_COLS 64 std::vector&lt;std::size_t&gt; mGrid[FRAME_GRID_COLS][FRAME_GRID_ROWS]; 1.13 相机位姿12// Camera pose. cv::Mat mTcw; ///&lt; 相机姿态 世界坐标系到相机坐标坐标系的变换矩阵 1.14 当前帧和下一帧的id123// Current and Next Frame id.static long unsigned int nNextId; ///&lt; Next Frame id.long unsigned int mnId; ///&lt; Current Frame id. 1.15 当前帧的参考关键帧12// Reference Keyframe. KeyFrame* mpReferenceKF;//指针，指向参考关键帧 1.16 图像金字塔信息12345678// Scale pyramid info. int mnScaleLevels;//图像提金字塔的层数 float mfScaleFactor;//图像提金字塔的尺度因子 float mfLogScaleFactor;// vector&lt;float&gt; mvScaleFactors; vector&lt;float&gt; mvInvScaleFactors; vector&lt;float&gt; mvLevelSigma2; vector&lt;float&gt; mvInvLevelSigma2; 1.17 用于确定画格子时的边界123456// Undistorted Image Bounds (computed once).// 用于确定画格子时的边界static float mnMinX;static float mnMaxX;static float mnMinY;static float mnMaxY; 1.18 mbInitialComputations初始计算Flag1static bool mbInitialComputations; 构造第一帧的时候，确定相机内参等，避免重复初始化计算 1.19 相机位姿的几个变换1234cv::Mat mRcw; ///&lt; Rotation from world to cameracv::Mat mtcw; ///&lt; Translation from world to cameracv::Mat mRwc; ///&lt; Rotation from camera to worldcv::Mat mOw; ///&lt; mtwc,Translation from camera to world 1.20 图像帧划分格子数目12#define FRAME_GRID_ROWS 48#define FRAME_GRID_COLS 64 2. Frame 类成员函数说明2.1 构造函数 默认构造函数，建立一个空的Frame 12Frame::Frame()&#123;&#125; 复制构造函数，mLastFrame = Frame(mCurrentFrame)，完全复制当前帧的成员变量 1234567891011121314151617181920Frame::Frame(const Frame &amp;frame) :mpORBvocabulary(frame.mpORBvocabulary), mpORBextractorLeft(frame.mpORBextractorLeft), mpORBextractorRight(frame.mpORBextractorRight), mTimeStamp(frame.mTimeStamp), mK(frame.mK.clone()), mDistCoef(frame.mDistCoef.clone()), mbf(frame.mbf), mb(frame.mb), mThDepth(frame.mThDepth), N(frame.N), mvKeys(frame.mvKeys), mvKeysRight(frame.mvKeysRight), mvKeysUn(frame.mvKeysUn), mvuRight(frame.mvuRight), mvDepth(frame.mvDepth), mBowVec(frame.mBowVec), mFeatVec(frame.mFeatVec), mDescriptors(frame.mDescriptors.clone()), mDescriptorsRight(frame.mDescriptorsRight.clone()), mvpMapPoints(frame.mvpMapPoints), mvbOutlier(frame.mvbOutlier), mnId(frame.mnId), mpReferenceKF(frame.mpReferenceKF), mnScaleLevels(frame.mnScaleLevels), mfScaleFactor(frame.mfScaleFactor), mfLogScaleFactor(frame.mfLogScaleFactor), mvScaleFactors(frame.mvScaleFactors), mvInvScaleFactors(frame.mvInvScaleFactors), mvLevelSigma2(frame.mvLevelSigma2), mvInvLevelSigma2(frame.mvInvLevelSigma2)&#123; for(int i=0;i&lt;FRAME_GRID_COLS;i++) for(int j=0; j&lt;FRAME_GRID_ROWS; j++) mGrid[i][j]=frame.mGrid[i][j]; if(!frame.mTcw.empty()) SetPose(frame.mTcw);&#125; RGB-D 构造函数 Stereo 构造函数 Monocular 构造函数，利用灰度图，时间戳，特征提取器，词典，相机内参，相机矫正参数，基线，深度截断值来构造一帧图像123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 单目初始化Frame::Frame(const cv::Mat &amp;imGray, const double &amp;timeStamp, ORBextractor* extractor,ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth) :mpORBvocabulary(voc),mpORBextractorLeft(extractor),mpORBextractorRight(static_cast&lt;ORBextractor*&gt;(NULL)), mTimeStamp(timeStamp), mK(K.clone()),mDistCoef(distCoef.clone()), mbf(bf), mThDepth(thDepth)&#123; // Frame ID mnId=nNextId++; // Scale Level Info ，设置金字塔信息 mnScaleLevels = mpORBextractorLeft-&gt;GetLevels(); mfScaleFactor = mpORBextractorLeft-&gt;GetScaleFactor(); mfLogScaleFactor = log(mfScaleFactor); mvScaleFactors = mpORBextractorLeft-&gt;GetScaleFactors(); mvInvScaleFactors = mpORBextractorLeft-&gt;GetInverseScaleFactors(); mvLevelSigma2 = mpORBextractorLeft-&gt;GetScaleSigmaSquares(); mvInvLevelSigma2 = mpORBextractorLeft-&gt;GetInverseScaleSigmaSquares(); // ORB extraction ExtractORB(0,imGray); // 0表示単目，进行特征点的提取，提取的特征存在mvKeys里面 N = mvKeys.size(); if(mvKeys.empty()) return; // 调用OpenCV的矫正函数矫正orb提取的特征点 UndistortKeyPoints(); // Set no stereo information mvuRight = vector&lt;float&gt;(N,-1); mvDepth = vector&lt;float&gt;(N,-1); mvpMapPoints = vector&lt;MapPoint*&gt;(N,static_cast&lt;MapPoint*&gt;(NULL)); // 对特征点列表构造空的地图点列表 mvbOutlier = vector&lt;bool&gt;(N,false); // This is done only for the first Frame (or after a change in the calibration) if(mbInitialComputations) &#123; ComputeImageBounds(imGray); mfGridElementWidthInv=static_cast&lt;float&gt;(FRAME_GRID_COLS)/static_cast&lt;float&gt;(mnMaxX-mnMinX); mfGridElementHeightInv=static_cast&lt;float&gt;(FRAME_GRID_ROWS)/static_cast&lt;float&gt;(mnMaxY-mnMinY); fx = K.at&lt;float&gt;(0,0); fy = K.at&lt;float&gt;(1,1); cx = K.at&lt;float&gt;(0,2); cy = K.at&lt;float&gt;(1,2); invfx = 1.0f/fx; invfy = 1.0f/fy; mbInitialComputations=false; &#125; mb = mbf/fx; AssignFeaturesToGrid();&#125; 2.2 获取特征点对应的格子坐标，并判断该特征点是否在原图像中1234567891011bool Frame::PosInGrid(const cv::KeyPoint &amp;kp, int &amp;posX, int &amp;posY)&#123; posX = round((kp.pt.x-mnMinX)*mfGridElementWidthInv); // 将实际坐标分散到各个网格中 posY = round((kp.pt.y-mnMinY)*mfGridElementHeightInv); //Keypoint's coordinates are undistorted, which could cause to go out of the image if(posX&lt;0 || posX&gt;=FRAME_GRID_COLS || posY&lt;0 || posY&gt;=FRAME_GRID_ROWS) return false; return true;&#125; 2.3 将矫正过的特征点分配到各个网格中，判断矫正过的特征点在哪个网格中，并将其加入到对应的表格vector中1234567891011121314151617void Frame::AssignFeaturesToGrid()&#123; int nReserve = 0.5f*N/(FRAME_GRID_COLS*FRAME_GRID_ROWS); for(unsigned int i=0; i&lt;FRAME_GRID_COLS;i++) for (unsigned int j=0; j&lt;FRAME_GRID_ROWS;j++) mGrid[i][j].reserve(nReserve); // 在mGrid中记录了各特征点 for(int i=0;i&lt;N;i++) &#123; const cv::KeyPoint &amp;kp = mvKeysUn[i]; int nGridPosX, nGridPosY; if(PosInGrid(kp,nGridPosX,nGridPosY)) mGrid[nGridPosX][nGridPosY].push_back(i); &#125;&#125; 2.4 特征提取函数ExtractORB，调用初始化的特征提取器进行特征提取，flag = 0単目提取，flag = 1，双目提取1234567void Frame::ExtractORB(int flag, const cv::Mat &amp;im)&#123; if(flag==0) (*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors); else (*mpORBextractorRight)(im,cv::Mat(),mvKeysRight,mDescriptorsRight);&#125; 2.5 设置相机姿态，随后会调用 UpdatePoseMatrices() 来改变mRcw,mRwc等变量的值1234567891011/** * @brief Set the camera pose. * * 设置相机姿态，随后会调用 UpdatePoseMatrices() 来改变mRcw,mRwc等变量的值 * @param Tcw Transformation from world to camera */void Frame::SetPose(cv::Mat Tcw)&#123; mTcw = Tcw.clone(); UpdatePoseMatrices();&#125; 2.6 根据Tcw计算mRcw、mtcw和mRwc、mOw（Twc）1234567891011121314151617/** * @brief Computes rotation, translation and camera center matrices from the camera pose. * * 根据Tcw计算mRcw、mtcw和mRwc、mOw */void Frame::UpdatePoseMatrices()&#123; // [x_camera 1] = [R|t]*[x_world 1]，坐标为齐次形式 // x_camera = R*x_world + t mRcw = mTcw.rowRange(0,3).colRange(0,3); mRwc = mRcw.t(); mtcw = mTcw.rowRange(0,3).col(3); // mtcw, 即相机坐标系下相机坐标系到世界坐标系间的向量, 向量方向由相机坐标系指向世界坐标系 // mOw, 即世界坐标系下世界坐标系到相机坐标系间的向量, 向量方向由世界坐标系指向相机坐标系 mOw = -mRcw.t()*mtcw;&#125; 2.7 判断一个点是否在当前帧的视野内，将该地图点投影到图像中然后计算观测方向夹角，预测在当前帧的尺度12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * @brief 判断一个点是否在视野内 * * 计算了重投影坐标，观测方向夹角，预测在当前帧的尺度 * @param pMP MapPoint * @param viewingCosLimit 视角和平均视角的方向阈值,0.5 ,cos 60 * @return true if is in view * @see SearchLocalPoints() */bool Frame::isInFrustum(MapPoint *pMP, float viewingCosLimit)&#123; pMP-&gt;mbTrackInView = false; // 3D in absolute coordinates cv::Mat P = pMP-&gt;GetWorldPos(); // 3D in camera coordinates // 3D点P在相机坐标系下的坐标 const cv::Mat Pc = mRcw*P+mtcw; // 这里的Rt是经过初步的优化后的 const float &amp;PcX = Pc.at&lt;float&gt;(0); const float &amp;PcY = Pc.at&lt;float&gt;(1); const float &amp;PcZ = Pc.at&lt;float&gt;(2); // Check positive depth if(PcZ&lt;0.0f) return false; // Project in image and check it is not outside // V-D 1) 将MapPoint投影到当前帧, 并判断是否在图像内 const float invz = 1.0f/PcZ; const float u=fx*PcX*invz+cx; const float v=fy*PcY*invz+cy; if(u&lt;mnMinX || u&gt;mnMaxX) return false; if(v&lt;mnMinY || v&gt;mnMaxY) return false; // Check distance is in the scale invariance region of the MapPoint // V-D 3) 计算MapPoint到相机中心的距离, 并判断是否在尺度变化的距离内 const float maxDistance = pMP-&gt;GetMaxDistanceInvariance(); const float minDistance = pMP-&gt;GetMinDistanceInvariance(); // 世界坐标系下，相机到3D点P的向量, 向量方向由相机指向3D点P const cv::Mat PO = P-mOw; const float dist = cv::norm(PO); if(dist&lt;minDistance || dist&gt;maxDistance) return false; // Check viewing angle // V-D 2) 计算当前视角和平均视角夹角的余弦值, 若小于cos(60), 即夹角大于60度则返回 cv::Mat Pn = pMP-&gt;GetNormal(); const float viewCos = PO.dot(Pn)/dist; if(viewCos&lt;viewingCosLimit) // viewingCosLimit = 0.5 return false; // Predict scale in the image // V-D 4) 根据深度预测尺度（对应特征点在一层） const int nPredictedLevel = pMP-&gt;PredictScale(dist,this); // Data used by the tracking // 标记该点将来要被投影 pMP-&gt;mbTrackInView = true; pMP-&gt;mTrackProjX = u; pMP-&gt;mTrackProjXR = u - mbf*invz; //该3D点投影到双目右侧相机上的横坐标 pMP-&gt;mTrackProjY = v; pMP-&gt;mnTrackScaleLevel = nPredictedLevel; pMP-&gt;mTrackViewCos = viewCos; return true;&#125; 2.8 找到在以x,y为中心，边长为2r的方形内且在[minLevel, maxLevel]的特征点，先遍历该圆域区间所属的边长为2r的格子区间内的所有特征点，再判断该点的尺度信息是否满足要求，再判断该特征点离中心点的距离是否满足半径要求，返回该区间的所有的特征点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * @brief 找到在 以x,y为中心,边长为2r的方形内且在[minLevel, maxLevel]的特征点 * @param x 图像坐标u * @param y 图像坐标v * @param r 边长 * @param minLevel 最小尺度 * @param maxLevel 最大尺度 * @return 满足条件的特征点的序号 */ vector&lt;size_t&gt; Frame::GetFeaturesInArea(const float &amp;x, const float &amp;y, const float &amp;r, const int minLevel, const int maxLevel) const&#123; vector&lt;size_t&gt; vIndices; vIndices.reserve(N); // 预留所有的特征点 // 判断最小最大距离是否越界，并计算坐标点所在的格子坐标，先计算出圆所在的格子区域区间 const int nMinCellX = max(0,(int)floor((x-mnMinX-r)*mfGridElementWidthInv)); if(nMinCellX&gt;=FRAME_GRID_COLS) return vIndices; const int nMaxCellX = min((int)FRAME_GRID_COLS-1,(int)ceil((x-mnMinX+r)*mfGridElementWidthInv)); if(nMaxCellX&lt;0) return vIndices; const int nMinCellY = max(0,(int)floor((y-mnMinY-r)*mfGridElementHeightInv)); if(nMinCellY&gt;=FRAME_GRID_ROWS) return vIndices; const int nMaxCellY = min((int)FRAME_GRID_ROWS-1,(int)ceil((y-mnMinY+r)*mfGridElementHeightInv)); if(nMaxCellY&lt;0) return vIndices; const bool bCheckLevels = (minLevel&gt;0) || (maxLevel&gt;=0); for(int ix = nMinCellX; ix&lt;=nMaxCellX; ix++) &#123; for(int iy = nMinCellY; iy&lt;=nMaxCellY; iy++) &#123; const vector&lt;size_t&gt; vCell = mGrid[ix][iy]; // vCell 存的是该格子区域的所有特征点对应的MvKeysUn序号 if(vCell.empty()) continue; for(size_t j=0, jend=vCell.size(); j&lt;jend; j++) &#123; const cv::KeyPoint &amp;kpUn = mvKeysUn[vCell[j]]; if(bCheckLevels) &#123; if(kpUn.octave&lt;minLevel) // 判断该特征点的金字塔level是否满足要求 continue; if(maxLevel&gt;=0) if(kpUn.octave&gt;maxLevel) continue; &#125; const float distx = kpUn.pt.x-x; const float disty = kpUn.pt.y-y; if(fabs(distx)&lt;r &amp;&amp; fabs(disty)&lt;r) vIndices.push_back(vCell[j]); &#125; &#125; &#125; return vIndices;&#125; 2.9 计算当前帧的词包词典12345678void Frame::ComputeBoW()&#123; if(mBowVec.empty()) &#123; vector&lt;cv::Mat&gt; vCurrentDesc = Converter::toDescriptorVector(mDescriptors); mpORBvocabulary-&gt;transform(vCurrentDesc,mBowVec,mFeatVec,4); &#125;&#125; 2.10 调用OpenCV的矫正函数矫正orb提取的特征点1234567891011121314151617181920212223242526272829303132333435void Frame::UndistortKeyPoints()&#123; // 如果没有图像是矫正过的，没有失真 if(mDistCoef.at&lt;float&gt;(0)==0.0) &#123; mvKeysUn=mvKeys; return; &#125; // Fill matrix with points // N为提取的特征点数量，将N个特征点保存在N*2的mat中 cv::Mat mat(N,2,CV_32F); for(int i=0; i&lt;N; i++) &#123; mat.at&lt;float&gt;(i,0)=mvKeys[i].pt.x; mat.at&lt;float&gt;(i,1)=mvKeys[i].pt.y; &#125; // Undistort points // 调整mat的通道为2，矩阵的行列形状不变 mat=mat.reshape(2); cv::undistortPoints(mat,mat,mK,mDistCoef,cv::Mat(),mK); // 用cv的函数进行失真校正 mat=mat.reshape(1); // Fill undistorted keypoint vector // 存储校正后的特征点 mvKeysUn.resize(N); for(int i=0; i&lt;N; i++) &#123; cv::KeyPoint kp = mvKeys[i]; kp.pt.x=mat.at&lt;float&gt;(i,0); kp.pt.y=mat.at&lt;float&gt;(i,1); mvKeysUn[i]=kp; &#125;&#125; 2.11 计算图像边界123456789101112131415161718192021222324252627282930313233void Frame::ComputeImageBounds(const cv::Mat &amp;imLeft)&#123; if(mDistCoef.at&lt;float&gt;(0)!=0.0) &#123; // 矫正前四个边界点：(0,0) (cols,0) (0,rows) (cols,rows) cv::Mat mat(4,2,CV_32F); mat.at&lt;float&gt;(0,0)=0.0; //左上 mat.at&lt;float&gt;(0,1)=0.0; mat.at&lt;float&gt;(1,0)=imLeft.cols; //右上 mat.at&lt;float&gt;(1,1)=0.0; mat.at&lt;float&gt;(2,0)=0.0; //左下 mat.at&lt;float&gt;(2,1)=imLeft.rows; mat.at&lt;float&gt;(3,0)=imLeft.cols; //右下 mat.at&lt;float&gt;(3,1)=imLeft.rows; // Undistort corners mat=mat.reshape(2); cv::undistortPoints(mat,mat,mK,mDistCoef,cv::Mat(),mK); mat=mat.reshape(1); mnMinX = min(mat.at&lt;float&gt;(0,0),mat.at&lt;float&gt;(2,0));//左上和左下横坐标最小的 mnMaxX = max(mat.at&lt;float&gt;(1,0),mat.at&lt;float&gt;(3,0));//右上和右下横坐标最大的 mnMinY = min(mat.at&lt;float&gt;(0,1),mat.at&lt;float&gt;(1,1));//左上和右上纵坐标最小的 mnMaxY = max(mat.at&lt;float&gt;(2,1),mat.at&lt;float&gt;(3,1));//左下和右下纵坐标最小的 &#125; else &#123; mnMinX = 0.0f; mnMaxX = imLeft.cols; mnMinY = 0.0f; mnMaxY = imLeft.rows; &#125;&#125;]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析八]]></title>
    <url>%2F2019%2F06%2F14%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%85%AB%2F</url>
    <content type="text"><![CDATA[MapPoint地图点1. MapPoint 成员变量1.1 MapPointId 地图点的ID，全局唯一，nNextId 静态计数12long unsigned int mnId; ///&lt; Global ID for MapPointstatic long unsigned int nNextId; 1.2 记录第一次创建该地图点的关键帧ID，以及帧ID12const long int mnFirstKFid; ///&lt; 创建该MapPoint的关键帧IDconst long int mnFirstFrame; ///&lt; 创建该MapPoint的帧ID（即每一关键帧有一个帧ID） 1.3 表示该地图点被观测的次数 nObs1int nObs; 1.4 该地图点被重投影到某一阵帧时的X坐标，Y坐标，以及在右视图中的坐标XR(双目匹配)，以及该地图点所对应的特征点被预测的尺度，以及该地图点在该帧下的观测向量与平均向量mNormalVector的夹角信息。123456// Variables used by the tracking float mTrackProjX; float mTrackProjY; float mTrackProjXR; int mnTrackScaleLevel; float mTrackViewCos; 1.5 该地图点是否需要进行重投影的标记变量，mbTrackInView = true表示需要进行重投影123456// TrackLocalMap - SearchByProjection中决定是否对该点进行投影的变量// mbTrackInView==false的点有几种：// a 已经和当前帧经过匹配（TrackReferenceKeyFrame，TrackWithMotionModel）但在优化过程中认为是外点// b 已经和当前帧经过匹配且为内点，这类点也不需要再进行投影// c 不在当前相机视野中的点（即未通过isInFrustum判断）bool mbTrackInView; 1.6 TrackLocalMap - UpdateLocalPoints中防止将MapPoints重复添加至mvpLocalMapPoints的参考帧标记避免重复添加局部地图点到更新的局部地图12// TrackLocalMap - UpdateLocalPoints中防止将MapPoints重复添加至mvpLocalMapPoints的标记 long unsigned int mnTrackReferenceForFrame; 1.7 TrackLocalMap - SearchLocalPoints中决定是否进行isInFrustum判断的变量，判断该点是否需要进行视野判断的变量12345// TrackLocalMap - SearchLocalPoints中决定是否进行isInFrustum判断的变量// mnLastFrameSeen==mCurrentFrame.mnId的点有几种：// a 已经和当前帧经过匹配（TrackReferenceKeyFrame，TrackWithMotionModel）但在优化过程中认为是外点// b 已经和当前帧经过匹配且为内点，这类点也不需要再进行投影long unsigned int mnLastFrameSeen; 1.8123// Variables used by local mapping long unsigned int mnBALocalForKF; long unsigned int mnFuseCandidateForKF; 1.9123456// Variables used by loop closinglong unsigned int mnLoopPointForKF;long unsigned int mnCorrectedByKF;long unsigned int mnCorrectedReference;cv::Mat mPosGBA;long unsigned int mnBAGlobalForKF; 1.10 MapPoint在世界坐标系下的坐标,地图点的坐标都是相对于世界坐标系，和当前帧无关，并没有存储局部坐标信息12// Position in absolute coordinatescv::Mat mWorldPos; ///&lt; MapPoint在世界坐标系下的坐标 1.11 观测到该MapPoint的KF和该MapPoint在KF中的索引12// Keyframes observing the point and associated index in keyframe std::map&lt;KeyFrame*,size_t&gt; mObservations; ///&lt; 观测到该MapPoint的KF和该MapPoint在KF中的索引 1.12 该MapPoint平均观测方向123// Mean viewing direction// 该MapPoint平均观测方向cv::Mat mNormalVector; 1.13 3D点的特征描述子12345// Best descriptor to fast matching// 每个3D点也有一个descriptor// 如果MapPoint与很多帧图像特征点对应（由keyframe来构造时），那么距离其它描述子的平均距离最小的描述子是最佳描述子// MapPoint只与一帧的图像特征点对应（由frame来构造时），那么这个特征点的描述子就是该3D点的描述子cv::Mat mDescriptor; ///&lt; 通过 ComputeDistinctiveDescriptors() 得到的最优描述子 1.14 参考关键帧12// Reference KeyFrame KeyFrame* mpRefKF; 1.15 跟踪计数，将局部地图关键帧和地图点重新跟踪投影时的计数信息123// Tracking counters int mnVisible; int mnFound; 1.16 坏的地图点标记，并没有显式的从内存中删除地图点123// Bad flag (we do not currently erase MapPoint from memory) bool mbBad; MapPoint* mpReplaced; 1.17 追踪时的地图点尺度信息123// Scale invariance distances float mfMinDistance; float mfMaxDistance; 1.18 该地图点所属于的地图1Map* mpMap; 2. 成员函数2.1 构造函数 MapPoint::MapPoint(const cv::Mat &amp;Pos, KeyFrame pRefKF, Map pMap)123//单目：CreateInitialMapMonocular()，LocalMapping::CreateNewMapPoints()// 通过世界坐标，关键帧，以及地图指针来构建新的地图点，初始化所有的变量，赋默认值，并令计算器自增，这种情况下是不知道地图点所对应的关键帧特征点，需要下一步重投影来计算MapPoint::MapPoint(const cv::Mat &amp;Pos, KeyFrame *pRefKF, Map* pMap); 2.2 构造函数 MapPoint::MapPoint(const cv::Mat &amp;Pos, Map pMap, Frame pFrame, const int &amp;idxF)12// 通过世界坐标，地图指针，图像帧，以及该地图点所对应的图像中的特征点idx来构建新的地图点，已经有了匹配信息，可以计算出相关变量的值MapPoint::MapPoint(const cv::Mat &amp;Pos, Map* pMap, Frame* pFrame, const int &amp;idxF) 123456// 计算这个点在当前帧的最大最小尺度距离mfMaxDistance = dist*levelScaleFactor;mfMinDistance = mfMaxDistance/pFrame-&gt;mvScaleFactors[nLevels-1];// 见mDescriptor在MapPoint.h中的注释，计算这个地图点在当前帧的描述符pFrame-&gt;mDescriptors.row(idxF).copyTo(mDescriptor); 2.3 构造函数 MapPoint::MapPoint(const cv::Mat &amp;Pos, Map pMap, Frame pFrame, const int &amp;idxF)12// 通过世界坐标，地图指针，图像帧，以及该地图点所对应的图像中的特征点idx来构建新的地图点，已经有了匹配信息，可以计算出相关变量的值MapPoint::MapPoint(const cv::Mat &amp;Pos, Map* pMap, Frame* pFrame, const int &amp;idxF) 2.4 set和get世界坐标12void SetWorldPos(const cv::Mat &amp;Pos);cv::Mat GetWorldPos(); 2.5 get平均观测向量12345cv::Mat MapPoint::GetNormal()&#123; unique_lock&lt;mutex&gt; lock(mMutexPos); return mNormalVector.clone();&#125; 2.6 get参考关键帧12345KeyFrame* MapPoint::GetReferenceKeyFrame()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return mpRefKF;&#125; 2.7 添加观测信息到 mObservations 这个 map12345678910111213void MapPoint::AddObservation(KeyFrame* pKF, size_t idx)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); if(mObservations.count(pKF)) // 如果键值已存在，直接返回 return; // 记录下能观测到该MapPoint的KF和该MapPoint在KF中的索引 mObservations[pKF]=idx; if(pKF-&gt;mvuRight[idx]&gt;=0) nObs+=2; // 双目或者grbd else nObs++; // 单目，让该点的观测计数加1&#125; 2.8 从mObservations 这个 map 删除观测信息 当删除观测信息时，会检测该点是否变为坏点，会重新设置badFlag1234567891011121314151617181920212223242526272829void MapPoint::EraseObservation(KeyFrame* pKF)&#123; bool bBad=false; // 默认该点不是坏点 &#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); if(mObservations.count(pKF)) &#123; int idx = mObservations[pKF]; if(pKF-&gt;mvuRight[idx]&gt;=0) nObs-=2; else nObs--; // 让观测计数建减1 mObservations.erase(pKF); // 从mObservations 这个 map删除该关键帧 // 如果该keyFrame是参考帧，该Frame被删除后重新指定RefFrame if(mpRefKF==pKF) mpRefKF=mObservations.begin()-&gt;first; // If only 2 observations or less, discard point // 当观测到该点的相机数目少于2时，丢弃该点 if(nObs&lt;=2) bBad=true; &#125; &#125; if(bBad) SetBadFlag();&#125; 2.9 GetObservations 返回观测信息 map12345map&lt;KeyFrame*, size_t&gt; MapPoint::GetObservations()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return mObservations;&#125; 2.10 返回观测计数 obs1int MapPoint::Observations() 2.11 SetBadFlag 告知可以观测到该MapPoint的Frame，该MapPoint已被删除12345678910111213141516171819// 告知可以观测到该MapPoint的Frame，该MapPoint已被删除void MapPoint::SetBadFlag()&#123; map&lt;KeyFrame*,size_t&gt; obs; &#123; unique_lock&lt;mutex&gt; lock1(mMutexFeatures); unique_lock&lt;mutex&gt; lock2(mMutexPos); mbBad=true; obs = mObservations;// 把mObservations转存到obs，obs和mObservations里存的是指针，赋值过程为浅拷贝 mObservations.clear();// 把mObservations指向的内存释放，obs作为局部变量之后自动删除 &#125; for(map&lt;KeyFrame*,size_t&gt;::iterator mit=obs.begin(), mend=obs.end(); mit!=mend; mit++) &#123; KeyFrame* pKF = mit-&gt;first; pKF-&gt;EraseMapPointMatch(mit-&gt;second);// 告诉可以观测到该MapPoint的KeyFrame，该MapPoint被删了 &#125; mpMap-&gt;EraseMapPoint(this);// 擦除该MapPoint申请的内存&#125; 2.12 返回被替换的地图点123456MapPoint* MapPoint::GetReplaced()&#123; unique_lock&lt;mutex&gt; lock1(mMutexFeatures); unique_lock&lt;mutex&gt; lock2(mMutexPos); return mpReplaced;&#125; 2.13 闭环更新12345678910111213141516171819202122232425262728293031323334353637383940414243// 在形成闭环的时候，会更新KeyFrame与MapPoint之间的关系void MapPoint::Replace(MapPoint* pMP)&#123; if(pMP-&gt;mnId==this-&gt;mnId) return; int nvisible, nfound; map&lt;KeyFrame*,size_t&gt; obs;// 这一段和SetBadFlag函数相同 &#123; unique_lock&lt;mutex&gt; lock1(mMutexFeatures); unique_lock&lt;mutex&gt; lock2(mMutexPos); obs=mObservations; mObservations.clear(); mbBad=true; nvisible = mnVisible; nfound = mnFound; mpReplaced = pMP; &#125; // 所有能观测到该MapPoint的keyframe都要替换 for(map&lt;KeyFrame*,size_t&gt;::iterator mit=obs.begin(), mend=obs.end(); mit!=mend; mit++) &#123; // Replace measurement in keyframe KeyFrame* pKF = mit-&gt;first; if(!pMP-&gt;IsInKeyFrame(pKF)) &#123; pKF-&gt;ReplaceMapPointMatch(mit-&gt;second, pMP);// 让KeyFrame用pMP替换掉原来的MapPoint pMP-&gt;AddObservation(pKF,mit-&gt;second);// 让MapPoint替换掉对应的KeyFrame &#125; else &#123; // 产生冲突，即pKF中有两个特征点a,b（这两个特征点的描述子是近似相同的），这两个特征点对应两个MapPoint为this,pMP // 然而在fuse的过程中pMP的观测更多，需要替换this，因此保留b与pMP的联系，去掉a与this的联系 pKF-&gt;EraseMapPointMatch(mit-&gt;second); &#125; &#125; pMP-&gt;IncreaseFound(nfound); pMP-&gt;IncreaseVisible(nvisible); pMP-&gt;ComputeDistinctiveDescriptors(); mpMap-&gt;EraseMapPoint(this);&#125; 2.14 检测该点是否是一个坏点123456bool MapPoint::isBad()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); unique_lock&lt;mutex&gt; lock2(mMutexPos); return mbBad;&#125; 2.15 增加该地图点的可视性，可以观察到，但不一定能够匹配到特征点1234567891011121314/** * @brief Increase Visible * * Visible表示： * 1. 该MapPoint在某些帧的视野范围内，通过Frame::isInFrustum()函数判断 * 2. 该MapPoint被这些帧观测到，但并不一定能和这些帧的特征点匹配上 * 例如：有一个MapPoint（记为M），在某一帧F的视野范围内， * 但并不表明该点M可以和F这一帧的某个特征点能匹配上 */void MapPoint::IncreaseVisible(int n)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); mnVisible+=n;&#125; 2.16 能找到该地图点的帧数加1，可以观察到该地图点，同时可以匹配到某一帧的特征点1234567891011/** * @brief Increase Found * * 能找到该点的帧数+n，n默认为1 * @see Tracking::TrackLocalMap() */void MapPoint::IncreaseFound(int n)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); mnFound+=n;&#125; 2.17 增加该地图点的可视性1234567891011121314/** * @brief Increase Visible * * Visible表示： * 1. 该MapPoint在某些帧的视野范围内，通过Frame::isInFrustum()函数判断 * 2. 该MapPoint被这些帧观测到，但并不一定能和这些帧的特征点匹配上 * 例如：有一个MapPoint（记为M），在某一帧F的视野范围内， * 但并不表明该点M可以和F这一帧的某个特征点能匹配上 */void MapPoint::IncreaseVisible(int n)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); mnVisible+=n;&#125; 2.18 返回匹配性与观测性的比例12345float MapPoint::GetFoundRatio()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return static_cast&lt;float&gt;(mnFound)/mnVisible;&#125; 2.19 计算具有代表的描述子，然后计算描述子之间的两两距离，最好的描述子与其他描述子应该具有最小的距离中值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * @brief 计算具有代表的描述子 * * 由于一个MapPoint会被许多相机观测到，因此在插入关键帧后，需要判断是否更新当前点的最适合的描述子 \n * 先获得当前点的所有描述子，然后计算描述子之间的两两距离，最好的描述子与其他描述子应该具有最小的距离中值 * @see III - C3.3 */void MapPoint::ComputeDistinctiveDescriptors()&#123; // Retrieve all observed descriptors vector&lt;cv::Mat&gt; vDescriptors; map&lt;KeyFrame*,size_t&gt; observations; &#123; unique_lock&lt;mutex&gt; lock1(mMutexFeatures); if(mbBad) return; observations=mObservations; &#125; if(observations.empty()) return; vDescriptors.reserve(observations.size()); // 遍历观测到3d点的所有关键帧，获得orb描述子，并插入到vDescriptors中 for(map&lt;KeyFrame*,size_t&gt;::iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++) &#123; KeyFrame* pKF = mit-&gt;first; if(!pKF-&gt;isBad()) vDescriptors.push_back(pKF-&gt;mDescriptors.row(mit-&gt;second)); &#125; if(vDescriptors.empty()) return; // Compute distances between them // 获得这些描述子两两之间的距离 const size_t N = vDescriptors.size(); //float Distances[N][N]; std::vector&lt;std::vector&lt;float&gt; &gt; Distances; Distances.resize(N, vector&lt;float&gt;(N, 0)); for (size_t i = 0; i&lt;N; i++) &#123; Distances[i][i]=0; for(size_t j=i+1;j&lt;N;j++) &#123; int distij = ORBmatcher::DescriptorDistance(vDescriptors[i],vDescriptors[j]); Distances[i][j]=distij; Distances[j][i]=distij; &#125; &#125; // Take the descriptor with least median distance to the rest int BestMedian = INT_MAX; int BestIdx = 0; for(size_t i=0;i&lt;N;i++) &#123; // 第i个描述子到其它所有所有描述子之间的距离 //vector&lt;int&gt; vDists(Distances[i],Distances[i]+N); vector&lt;int&gt; vDists(Distances[i].begin(), Distances[i].end()); sort(vDists.begin(), vDists.end()); // 获得中值 int median = vDists[0.5*(N-1)]; // 寻找最小的中值 if(median&lt;BestMedian) &#123; BestMedian = median; BestIdx = i; &#125; &#125; &#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); // 最好的描述子，该描述子相对于其他描述子有最小的距离中值 // 简化来讲，中值代表了这个描述子到其它描述子的平均距离 // 最好的描述子就是和其它描述子的平均距离最小 mDescriptor = vDescriptors[BestIdx].clone(); &#125;&#125; 2.20 GetDescriptor()获得mapPoint的描述符12345cv::Mat MapPoint::GetDescriptor()&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return mDescriptor.clone();&#125; 2.21 返回该mapPoint所对应的特征点在指定关键帧的idx12345678int MapPoint::GetIndexInKeyFrame(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); if(mObservations.count(pKF)) return mObservations[pKF]; else return -1;&#125; 2.22 检查该地图点是否是某一帧图像的地图点12345bool MapPoint::IsInKeyFrame(KeyFrame *pKF)&#123; unique_lock&lt;mutex&gt; lock(mMutexFeatures); return (mObservations.count(pKF));&#125; 2.23 更新平均观测方向以及观测距离范围1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @brief 更新平均观测方向以及观测距离范围 * * 由于一个MapPoint会被许多相机观测到，因此在插入关键帧后，需要更新相应变量 * @see III - C2.2 c2.4 */void MapPoint::UpdateNormalAndDepth()&#123; map&lt;KeyFrame*,size_t&gt; observations; KeyFrame* pRefKF; cv::Mat Pos; &#123; unique_lock&lt;mutex&gt; lock1(mMutexFeatures); unique_lock&lt;mutex&gt; lock2(mMutexPos); if(mbBad) return; observations=mObservations; // 获得观测到该3d点的所有关键帧 pRefKF=mpRefKF; // 观测到该点的参考关键帧 Pos = mWorldPos.clone(); // 3d点在世界坐标系中的位置 &#125; if(observations.empty()) return; cv::Mat normal = cv::Mat::zeros(3,1,CV_32F); int n=0; for(map&lt;KeyFrame*,size_t&gt;::iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++) &#123; KeyFrame* pKF = mit-&gt;first; cv::Mat Owi = pKF-&gt;GetCameraCenter(); cv::Mat normali = mWorldPos - Owi; normal = normal + normali/cv::norm(normali); // 对所有关键帧对该点的观测方向归一化为单位向量进行求和 n++; &#125; cv::Mat PC = Pos - pRefKF-&gt;GetCameraCenter(); // 参考关键帧相机指向3D点的向量（在世界坐标系下的表示） const float dist = cv::norm(PC); // 该点到参考关键帧相机的距离 const int level = pRefKF-&gt;mvKeysUn[observations[pRefKF]].octave; const float levelScaleFactor = pRefKF-&gt;mvScaleFactors[level]; const int nLevels = pRefKF-&gt;mnScaleLevels; // 金字塔层数 &#123; unique_lock&lt;mutex&gt; lock3(mMutexPos); // 另见PredictScale函数前的注释 mfMaxDistance = dist*levelScaleFactor; // 观测到该点的距离下限 mfMinDistance = mfMaxDistance/pRefKF-&gt;mvScaleFactors[nLevels-1]; // 观测到该点的距离上限 mNormalVector = normal/n; // 获得新的平均的观测方向 &#125;&#125; 2.24 获得最小最大距离的方差1234567891011float MapPoint::GetMinDistanceInvariance()&#123; unique_lock&lt;mutex&gt; lock(mMutexPos); return 0.8f*mfMinDistance;&#125;float MapPoint::GetMaxDistanceInvariance()&#123; unique_lock&lt;mutex&gt; lock(mMutexPos); return 1.2f*mfMaxDistance;&#125; 2.25 预测当前地图点相对于参考帧的金字塔尺度12345678910111213141516171819202122232425262728293031323334353637383940414243444546// ____// Nearer /____\ level:n-1 --&gt; dmin// /______\ d/dmin = 1.2^(n-1-m)// /________\ level:m --&gt; d// /__________\ dmax/d = 1.2^m// Farther /____________\ level:0 --&gt; dmax//// log(dmax/d)// m = ceil(------------)// log(1.2)int MapPoint::PredictScale(const float &amp;currentDist, KeyFrame* pKF)&#123; float ratio; &#123; unique_lock&lt;mutex&gt; lock(mMutexPos); // mfMaxDistance = ref_dist*levelScaleFactor为参考帧考虑上尺度后的距离 // ratio = mfMaxDistance/currentDist = ref_dist/cur_dist ratio = mfMaxDistance/currentDist; &#125; // 同时取log线性化 int nScale = ceil(log(ratio)/pKF-&gt;mfLogScaleFactor); if(nScale&lt;0) nScale = 0; else if(nScale&gt;=pKF-&gt;mnScaleLevels) nScale = pKF-&gt;mnScaleLevels-1; return nScale;&#125;int MapPoint::PredictScale(const float &amp;currentDist, Frame* pF)&#123; float ratio; &#123; unique_lock&lt;mutex&gt; lock(mMutexPos); ratio = mfMaxDistance/currentDist; &#125; int nScale = ceil(log(ratio)/pF-&gt;mfLogScaleFactor); if(nScale&lt;0) nScale = 0; else if(nScale&gt;=pF-&gt;mnScaleLevels) nScale = pF-&gt;mnScaleLevels-1; return nScale;&#125;]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相机矩阵的Tips]]></title>
    <url>%2F2019%2F06%2F13%2F%E7%9B%B8%E6%9C%BA%E7%9F%A9%E9%98%B5%E7%9A%84tips%2F</url>
    <content type="text"><![CDATA[关于相机矩阵以及坐标系变换的Tips绕原点逆时针旋转$\theta$角度的旋转方程为 x' = \begin{bmatrix} cos\theta & -sin\theta \\ sin\theta & cos\theta \end{bmatrix} x设$T_{cw}$表示从世界坐标系到摄像机坐标系的变换矩阵，也就是说，对于齐次坐标： \begin{array}{c} \begin{bmatrix} P_c & 1 \end{bmatrix} = T_{cw} * { \begin{bmatrix} P_w & 1 \end{bmatrix} } \\ \begin{bmatrix} P_w & 1 \end{bmatrix} = T_{wc} * { \begin{bmatrix} P_c & 1 \end{bmatrix} } \end{array}对标准坐标来说，分解成旋转矩阵和平移向量也就是 \begin{array}{c} P_c = R_{cw} * P_w + t_{cw} \\ P_w = R_{wc} * P_c + t_{wc} \end{array}$R_{cw}$表示$T_{cw}$的左上角$3 \times 3$的矩阵，即1Rcw = Tcw.rowRange(0,3).colRange(0,3); $t_{cw}$表示$T_{cw}$的右上角$3 \times 1$的矩阵，即1tcw = Tcw.rowRange(0,3).col(3); 平移向量$T_{cw}$表示在相机坐标系中，相机坐标系到世界坐标系间的向量，向量方向由相机坐标系指向世界坐标系，即相机坐标系中，世界坐标系的原点坐标。旋转矩阵R中的角度表示平移完成后，从相机坐标系逆时针旋转至世界坐标系的角度。以二维坐标旋转为例，如下图所示 反过来，$R_{wc}$表示坐标从相机坐标系转换世界坐标系的旋转矩阵，$R_{wc}=R_{cw}^T=R_{cw}^{-1}$1Rwc = Rcw.t(); $t_{wc}$也记作$Ow$，表示世界坐标系下世界坐标系到相机坐标系间的向量, 向量方向由世界坐标系指向相机坐标系，即世界坐标系下，相机中心点的坐标。$t_{wc} = - R_{cw}^T \ast t_{cw}$ 1Ow = -Rcw.t()*tcw;]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>Camera</tag>
        <tag>Matrix</tag>
        <tag>System Transform</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析七]]></title>
    <url>%2F2019%2F06%2F11%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%83%2F</url>
    <content type="text"><![CDATA[track()线程主函数详解此时track()函数已经完成了初始化，mstate = OK，mpInitializer已经初始化，track()函数进入else分支 1. 正常初始化 mState==OK1.1 检查并更新上一帧被替换的MapPoints，Local Mapping线程可能会修改最后一帧图像的地图点1234// Local Mapping might have changed some MapPoints tracked in last frame // 检查并更新上一帧被替换的MapPoints // 更新Fuse函数和SearchAndFuse函数替换的MapPoints CheckReplacedInLastFrame(); 1.2 根据参考关键帧进行跟踪 TrackReferenceKeyFrame()123456789101112// 运动模型是空的或刚完成重定位// mCurrentFrame.mnId&lt;mnLastRelocFrameId+2这个判断不应该有???// 源代码注释说不应该有后面这个判断，我认为有必要，如果刚进行重定位，此时mVelocity不为空// 应该只要mVelocity不为空，就优先选择TrackWithMotionModel// mnLastRelocFrameId上一次重定位的那一帧if(mVelocity.empty() || mCurrentFrame.mnId&lt;mnLastRelocFrameId+2)&#123; // 将上一帧的位姿作为当前帧的初始位姿 // 通过BoW的方式在参考帧中找当前帧特征点的匹配点 // 优化每个特征点都对应3D点重投影误差即可得到位姿 bOK = TrackReferenceKeyFrame();&#125; 1.3 根据恒速模型和最后一帧图像进行跟踪 TrackWithMotionModel()，如果恒速模型不成功，再根据参考关键帧进行跟踪1234567891011else &#123; // 根据恒速模型设定当前帧的初始位姿 // 通过投影的方式在参考帧中找当前帧特征点的匹配点 // 优化每个特征点所对应3D点的投影误差即可得到位姿 bOK = TrackWithMotionModel(); if(!bOK) // TrackReferenceKeyFrame是跟踪参考帧，不能根据固定运动速度模型预测当前帧的位姿态，通过bow加速匹配（SearchByBow） // 最后通过优化得到优化后的位姿 bOK = TrackReferenceKeyFrame(); &#125; 2. 初始化完成后，特征点跟踪丢失，mState！=OK,此时进行重定位12345else &#123; // BOW搜索，PnP求解位姿 bOK = Relocalization(); &#125; 3. 跟踪完当前帧后，需要进行更新信息3.1 更新当前帧的参考关键帧为当前参考关键帧12// 将最新的关键帧作为reference frame mCurrentFrame.mpReferenceKF = mpReferenceKF; 3.2 跟踪局部地图 详细分解参照源码分析二1234567891011// If we have an initial estimation of the camera pose and matching. Track the local map.// 步骤2.2：在帧间匹配得到初始的姿态后，现在对local map进行跟踪得到更多的匹配，并优化当前位姿// local map:当前帧、当前帧的MapPoints、当前关键帧与其它关键帧共视关系// 在步骤2.1中主要是两两跟踪（恒速模型跟踪上一帧、跟踪参考帧），这里搜索局部关键帧后搜集所有局部MapPoints，// 然后将局部MapPoints和当前帧进行投影匹配，得到更多匹配的MapPoints后进行Pose优化if(!mbOnlyTracking)&#123; if(bOK) bOK = TrackLocalMap();&#125; 3.3 跟踪局部地图完成，mstate = OK1234if(bOK) mState = OK;else mState=LOST; 3.4 更新Motion模型计算mVelocity，计算当前帧相对于最后一帧的相对位姿 \begin{array}{l} X_l = R_{lw}X_w+t_{lw}=T_{lw}X_w \\ X_c = R_{cw}X_w+t_{cw}=T_{cw}X_w = T_{cw}T_{lw}^{-1}X_l \end{array}1234567891011// Update motion model if(!mLastFrame.mTcw.empty()) &#123; // 步骤2.3：更新恒速运动模型TrackWithMotionModel中的mVelocity cv::Mat LastTwc = cv::Mat::eye(4,4,CV_32F); mLastFrame.GetRotationInverse().copyTo(LastTwc.rowRange(0,3).colRange(0,3)); mLastFrame.GetCameraCenter().copyTo(LastTwc.rowRange(0,3).col(3)); mVelocity = mCurrentFrame.mTcw*LastTwc; // Tcl &#125; else mVelocity = cv::Mat(); 3.5 清楚VO matches 清除UpdateLastFrame中为当前帧临时添加的MapPoints12345678910111213// Clean VO matches // 步骤2.4：清除UpdateLastFrame中为当前帧临时添加的MapPoints for(int i=0; i&lt;mCurrentFrame.N; i++) &#123; MapPoint* pMP = mCurrentFrame.mvpMapPoints[i]; if(pMP) // 排除UpdateLastFrame函数中为了跟踪增加的MapPoints if(pMP-&gt;Observations()&lt;1) &#123; mCurrentFrame.mvbOutlier[i] = false; mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL); &#125; &#125; 3.6 从地图中清除地图点1234567891011// Delete temporal MapPoints // 步骤2.5：清除临时的MapPoints，这些MapPoints在TrackWithMotionModel的UpdateLastFrame函数里生成（仅双目和rgbd） // 步骤2.4中只是在当前帧中将这些MapPoints剔除，这里从MapPoints数据库中删除 // 这里生成的仅仅是为了提高双目或rgbd摄像头的帧间跟踪效果，用完以后就扔了，没有添加到地图中 for(list&lt;MapPoint*&gt;::iterator lit = mlpTemporalPoints.begin(), lend = mlpTemporalPoints.end(); lit!=lend; lit++) &#123; MapPoint* pMP = *lit; delete pMP; &#125; // 这里不仅仅是清除mlpTemporalPoints，通过delete pMP还删除了指针指向的MapPoint mlpTemporalPoints.clear(); 3.7 检测是否需要插入关键帧1234// Check if we need to insert a new keyframe // 步骤2.6：检测并插入关键帧，对于双目会产生新的MapPoints if(NeedNewKeyFrame()) CreateNewKeyFrame(); 3.8 删除那些在bundle adjustment中检测为outlier的3D map点12345678910// We allow points with high innovation (considererd outliers by the Huber Function) // pass to the new keyframe, so that bundle adjustment will finally decide // if they are outliers or not. We don't want next frame to estimate its position // with those points so we discard them in the frame. // 删除那些在bundle adjustment中检测为outlier的3D map点 for(int i=0; i&lt;mCurrentFrame.N;i++) &#123; if(mCurrentFrame.mvpMapPoints[i] &amp;&amp; mCurrentFrame.mvbOutlier[i]) mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL); &#125; 3.9 判断跟踪状态，如果跟踪丢失，则reset1234567891011// Reset if the camera get lost soon after initialization // 跟踪失败，并且relocation也没有搞定，只能重新Reset if(mState==LOST) &#123; if(mpMap-&gt;KeyFramesInMap()&lt;=5) &#123; cout &lt;&lt; "Track lost soon after initialisation, reseting..." &lt;&lt; endl; mpSystem-&gt;Reset(); return; &#125; &#125; 3.10 保存上一帧图像的数据，往下传递跟踪12345if(!mCurrentFrame.mpReferenceKF) mCurrentFrame.mpReferenceKF = mpReferenceKF; // 保存上一帧的数据 mLastFrame = Frame(mCurrentFrame); 3.11 记录位姿信息，用于轨迹复现1234567891011121314151617181920// Store frame pose information to retrieve the complete camera trajectory afterwards.// 步骤3：记录位姿信息，用于轨迹复现if(!mCurrentFrame.mTcw.empty())&#123; // 计算相对姿态T_currentFrame_referenceKeyFrame cv::Mat Tcr = mCurrentFrame.mTcw*mCurrentFrame.mpReferenceKF-&gt;GetPoseInverse(); mlRelativeFramePoses.push_back(Tcr); mlpReferences.push_back(mpReferenceKF); mlFrameTimes.push_back(mCurrentFrame.mTimeStamp); mlbLost.push_back(mState==LOST);&#125;else&#123; // This can happen if tracking is lost // 如果跟踪失败，则相对位姿使用上一次值 mlRelativeFramePoses.push_back(mlRelativeFramePoses.back()); mlpReferences.push_back(mlpReferences.back()); mlFrameTimes.push_back(mlFrameTimes.back()); mlbLost.push_back(mState==LOST);&#125;]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析六]]></title>
    <url>%2F2019%2F06%2F11%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%85%AD%2F</url>
    <content type="text"><![CDATA[track()线程初始化过程详解Tracking.cpp里面的Track()函数可以说是 Tracking 线程最主体部分了，来看看调用Track()函数的过程： 1. 初始化初始器 mpInitializer1.1 第一次进Track()函数，处理系统的第一帧图像,此时state = NO_IMAGE_YET，赋值为state = NOT_INITIALIZED12345678910111213// track包含两部分：估计运动、跟踪局部地图// mState为tracking的状态机// SYSTME_NOT_READY, NO_IMAGE_YET, NOT_INITIALIZED, OK, LOST// 如果图像复位过、或者第一次运行，则为NO_IMAGE_YET状态if(mState==NO_IMAGES_YET)&#123; mState = NOT_INITIALIZED;&#125;// mLastProcessedState存储了Tracking最新的状态，用于FrameDrawer中的绘制mLastProcessedState=mState; 1.2 接下来 mState==NOT_INITIALIZED 执行単目初始化过程，进入MonocularInitialization();123456789101112if(mState==NOT_INITIALIZED)&#123; if(mSensor==System::STEREO || mSensor==System::RGBD) StereoInitialization(); else MonocularInitialization(); mpFrameDrawer-&gt;Update(this); if(mState!=OK) return;&#125; 1.3 此时単目初始器还没有建立，mpInitializer=nullptr,进入MonocularInitialization()函数if分支，需要保证单目初始帧的特征点数必须大于100123456789// 步骤1：得到用于初始化的第一帧，初始化需要两帧，处理第一帧时，mInitialFrame和mLastFrame都等于第一帧，也就是当前帧 mInitialFrame = Frame(mCurrentFrame); // 记录最近的一帧 mLastFrame = Frame(mCurrentFrame); // mvbPrevMatched最大的情况就是所有特征点都被跟踪上 mvbPrevMatched.resize(mCurrentFrame.mvKeysUn.size()); for(size_t i=0; i&lt;mCurrentFrame.mvKeysUn.size(); i++) mvbPrevMatched[i]=mCurrentFrame.mvKeysUn[i].pt; 1.4 构造初始器 mpInitializer12// 由当前帧构造初始器 sigma:1.0 iterations:200 mpInitializer = new Initializer(mCurrentFrame,1.0,200); 填充匹配信息为未匹配，值为-11fill(mvIniMatches.begin(),mvIniMatches.end(),-1); 此时函数返回，mState仍然为NOT_INITIALIZED 1.5 mstate = NOT_INITIALIZED,mpInitializer已经初始化，开始处理第二帧图像接下来处理第二帧图像，同样进入MonocularInitialization();此时単目初始器已经初始化，走MonocularInitialization()函数else过程。同样需要保证第二帧图像的特征点数大于1001234567891011// Try to initialize // 步骤2：如果当前帧特征点数大于100，则得到用于单目初始化的第二帧 // 如果当前帧特征点太少，重新构造初始器 // 因此只有连续两帧的特征点个数都大于100时，才能继续进行初始化过程 if((int)mCurrentFrame.mvKeys.size()&lt;=100) &#123; delete mpInitializer; mpInitializer = static_cast&lt;Initializer*&gt;(NULL); fill(mvIniMatches.begin(),mvIniMatches.end(),-1); return; &#125; 1.6 建立匹配器，在mInitialFrame帧和mCurrentFrame帧之间进行特征点匹配，返回匹配的特征点个数123456789// Find correspondences // 步骤3：在mInitialFrame与mCurrentFrame中找匹配的特征点对 // mvbPrevMatched为前一帧的特征点，存储了mInitialFrame中哪些点将进行接下来的匹配 // mvIniMatches存储mInitialFrame,mCurrentFrame之间匹配的特征点 // mvbPrevMatched为前一帧的特征点，存储了mInitialFrame中哪些点将进行接下来的匹配 // mvIniMatches存储mInitialFrame,mCurrentFrame之间匹配的特征点,键值对是两帧匹配特征点的索引 // mvbPrevMatched，mvIniMatches获得更新 ORBmatcher matcher(0.9,true); int nmatches = matcher.SearchForInitialization(mInitialFrame,mCurrentFrame,mvbPrevMatched,mvIniMatches,100); 检测匹配点的个数是否满足要求，如果初始两帧图像之间的匹配点太少，则重新初始化12345678// Check if there are enough correspondences // 步骤4：如果初始化的两帧之间的匹配点太少，重新初始化 if(nmatches&lt;100) &#123; delete mpInitializer; mpInitializer = static_cast&lt;Initializer*&gt;(NULL); return; &#125; 1.7 建立匹配器，在mInitialFrame帧和mCurrentFrame帧之间进行特征点匹配，返回匹配的特征点个数mCurrentFrame, mvIniMatches是传入的初始化参数如果初始化成功，intializer得到Rcw, tcw，mvIniP3D, vbTriangulated。12// 步骤5：通过H模型或F模型进行单目初始化，得到两帧间相对运动、初始MapPointsif(mpInitializer-&gt;Initialize(mCurrentFrame, mvIniMatches, Rcw, tcw, mvIniP3D, vbTriangulated)) 1.8 删除那些无法三角化的匹配点123456789// 步骤6：删除那些无法进行三角化的匹配点 for(size_t i=0, iend=mvIniMatches.size(); i&lt;iend;i++) &#123; if(mvIniMatches[i]&gt;=0 &amp;&amp; !vbTriangulated[i]) &#123; mvIniMatches[i]=-1; nmatches--; &#125; &#125; 1.9 设置第一帧为世界坐标系，并建立第二帧的位姿12345678// Set Frame Poses // 将初始化的第一帧作为世界坐标系，因此第一帧变换矩阵为单位矩阵 mInitialFrame.SetPose(cv::Mat::eye(4,4,CV_32F)); // 由Rcw和tcw构造Tcw,并赋值给mTcw，mTcw为世界坐标系到该帧的变换矩阵 cv::Mat Tcw = cv::Mat::eye(4,4,CV_32F); Rcw.copyTo(Tcw.rowRange(0,3).colRange(0,3)); tcw.copyTo(Tcw.rowRange(0,3).col(3)); mCurrentFrame.SetPose(Tcw); 说明:Frame.SetPose函数，将相对于参考帧的Tcw复制到当前帧的Tcw,并更新世界坐标系矩阵中的一些变量12345void Frame::SetPose(cv::Mat Tcw)&#123; mTcw = Tcw.clone(); UpdatePoseMatrices();&#125; 1234567891011void Frame::UpdatePoseMatrices()&#123; // [x_camera 1] = [R|t]*[x_world 1]，坐标为齐次形式 // x_camera = R*x_world + t mRcw = mTcw.rowRange(0,3).colRange(0,3); mRwc = mRcw.t(); mtcw = mTcw.rowRange(0,3).col(3); // mtcw, 即相机坐标系下相机坐标系到世界坐标系间的向量, 向量方向由相机坐标系指向世界坐标系 // mOw, 即世界坐标系下世界坐标系到相机坐标系间的向量, 向量方向由世界坐标系指向相机坐标系 mOw = -mRcw.t()*mtcw;&#125; 2. 建立初始局部地图 CreateInitialMapMonocular()12345// 步骤6：将三角化得到的3D点包装成MapPoints // Initialize函数会得到mvIniP3D， // mvIniP3D是cv::Point3f类型的一个容器，是个存放3D点的临时变量， // CreateInitialMapMonocular将3D点包装成MapPoint类型存入KeyFrame和Map中 CreateInitialMapMonocular(); 2.1 将第一帧图像和第二帧图像都设为关键帧12KeyFrame* pKFini = new KeyFrame(mInitialFrame,mpMap,mpKeyFrameDB);KeyFrame* pKFcur = new KeyFrame(mCurrentFrame,mpMap,mpKeyFrameDB); 2.2 将第一帧和第二帧图像的描述子都转换为Bow1234// 步骤1：将初始关键帧的描述子转为BoWpKFini-&gt;ComputeBoW();// 步骤2：将当前关键帧的描述子转为BoWpKFcur-&gt;ComputeBoW(); 2.3 将关键帧插入全局地图12345// Insert KFs in the map// 步骤3：将关键帧插入到地图// 凡是关键帧，都要插入地图mpMap-&gt;AddKeyFrame(pKFini);mpMap-&gt;AddKeyFrame(pKFcur); 2.4 生成地图点并和关键帧相关联123456789101112131415161718192021222324252627282930313233343536373839// Create MapPoints and asscoiate to keyframes// 步骤4：将3D点包装成MapPointsfor(size_t i=0; i&lt;mvIniMatches.size();i++)&#123; if(mvIniMatches[i]&lt;0) continue; //Create MapPoint. cv::Mat worldPos(mvIniP3D[i]); // 步骤4.1：用3D点构造MapPoint MapPoint* pMP = new MapPoint(worldPos,pKFcur,mpMap); // 步骤4.2：为该MapPoint添加属性： // a.观测到该MapPoint的关键帧 // b.该MapPoint的描述子 // c.该MapPoint的平均观测方向和深度范围 // 步骤4.3：表示该KeyFrame的哪个特征点可以观测到哪个3D点 pKFini-&gt;AddMapPoint(pMP,i); pKFcur-&gt;AddMapPoint(pMP,mvIniMatches[i]); // a.表示该MapPoint可以被哪个KeyFrame的哪个特征点观测到 pMP-&gt;AddObservation(pKFini,i); pMP-&gt;AddObservation(pKFcur,mvIniMatches[i]); // b.从众多观测到该MapPoint的特征点中挑选区分度最高的描述子 pMP-&gt;ComputeDistinctiveDescriptors(); // c.更新该MapPoint平均观测方向以及观测距离的范围 pMP-&gt;UpdateNormalAndDepth(); //Fill Current Frame structure mCurrentFrame.mvpMapPoints[mvIniMatches[i]] = pMP; mCurrentFrame.mvbOutlier[mvIniMatches[i]] = false; //Add to Map // 步骤4.4：在地图中添加该MapPoint mpMap-&gt;AddMapPoint(pMP);&#125; Create MapPoint()说明:12345//Create MapPoint. cv::Mat worldPos(mvIniP3D[i]); // 步骤4.1：用3D点构造MapPoint MapPoint* pMP = new MapPoint(worldPos,pKFcur,mpMap); 创建地图点的过程Pos存储地图点的世界坐标系坐标，mNormalVector存储世界坐标系下相机到3D点的单位向量，dist表示相机中心到世界坐标系原点的距离// mtcw, 即相机坐标系下相机坐标系到世界坐标系间的向量, 向量方向由相机坐标系指向世界坐标系，可以理解为在相机坐标系下，世界坐标系原点的坐标// mOw, 即世界坐标系下世界坐标系到相机坐标系间的向量, 向量方向由世界坐标系指向相机坐标系，可以理解为在世界坐标系下，相机中心的坐标 12345678910// ____// Nearer /____\ level:n-1 --&gt; dmin// /______\ d/dmin = 1.2^(n-1-m)// /________\ level:m --&gt; d// /__________\ dmax/d = 1.2^m// Farther /____________\ level:0 --&gt; dmax//// log(dmax/d)// m = ceil(------------)// log(1.2) 123456789101112131415161718192021Pos.copyTo(mWorldPos);cv::Mat Ow = pFrame-&gt;GetCameraCenter();mNormalVector = mWorldPos - Ow;// 世界坐标系下相机到3D点的向量mNormalVector = mNormalVector/cv::norm(mNormalVector);// 世界坐标系下相机到3D点的单位向量cv::Mat PC = Pos - Ow;const float dist = cv::norm(PC);const int level = pFrame-&gt;mvKeysUn[idxF].octave;const float levelScaleFactor = pFrame-&gt;mvScaleFactors[level];const int nLevels = pFrame-&gt;mnScaleLevels;// 另见PredictScale函数前的注释mfMaxDistance = dist*levelScaleFactor;mfMinDistance = mfMaxDistance/pFrame-&gt;mvScaleFactors[nLevels-1];// 见mDescriptor在MapPoint.h中的注释pFrame-&gt;mDescriptors.row(idxF).copyTo(mDescriptor);// MapPoints can be created from Tracking and Local Mapping. This mutex avoid conflicts with id.unique_lock&lt;mutex&gt; lock(mpMap-&gt;mMutexPointCreation);mnId=nNextId++; 2.5 更新关键帧间的连接关系,在关键帧之间建立边，每个边有一个权重，边的权重是该关键帧与当前帧公共3D点的个数，同时更新每一个3D点能够被哪些帧观测到12pKFini-&gt;UpdateConnections();pKFcur-&gt;UpdateConnections(); 2.6 BA优化// 步骤5：BA优化 Optimizer::GlobalBundleAdjustemnt(mpMap,20); 2.7 归一化3D点坐标和摄像机矩阵123456789101112131415161718192021222324252627282930// Set median depth to 1 // 步骤6：!!!将MapPoints的中值深度归一化到1，并归一化两帧之间变换 // 评估关键帧场景深度，q=2表示中值 float medianDepth = pKFini-&gt;ComputeSceneMedianDepth(2); float invMedianDepth = 1.0f/medianDepth; if(medianDepth&lt;0 || pKFcur-&gt;TrackedMapPoints(1)&lt;100) &#123; cout &lt;&lt; "Wrong initialization, reseting..." &lt;&lt; endl; Reset(); return; &#125; // Scale initial baseline cv::Mat Tc2w = pKFcur-&gt;GetPose(); // x/z y/z 将z归一化到1 Tc2w.col(3).rowRange(0,3) = Tc2w.col(3).rowRange(0,3)*invMedianDepth; pKFcur-&gt;SetPose(Tc2w); // Scale points // 把3D点的尺度也归一化到1 vector&lt;MapPoint*&gt; vpAllMapPoints = pKFini-&gt;GetMapPointMatches(); for(size_t iMP=0; iMP&lt;vpAllMapPoints.size(); iMP++) &#123; if(vpAllMapPoints[iMP]) &#123; MapPoint* pMP = vpAllMapPoints[iMP]; pMP-&gt;SetWorldPos(pMP-&gt;GetWorldPos()*invMedianDepth); &#125; &#125; 2.8 建立此时mpTracker的成员变量mpLocalMapper,mpLastKeyFrame，mnLastKeyFrameId，mvpLocalKeyFrames，mvpLocalMapPoints，mpReferenceKF，mLastFrame，mpMap的相关信息,以及当前帧的信息将初始关键帧和当前关键帧键入局部地图关键帧集合，重新设置当前帧的位姿为归一化后的位姿，设置局部地图为此时的初始地图，设置参考关键帧为当前关键帧，设置当前帧的参考关键帧为当前关键帧，设置最后一帧为当前帧，全局地图的参考地图为此时的局部地图，全局地图的初始关键帧为初始关键帧1234567891011121314151617181920mpLocalMapper-&gt;InsertKeyFrame(pKFini);mpLocalMapper-&gt;InsertKeyFrame(pKFcur);mCurrentFrame.SetPose(pKFcur-&gt;GetPose());mnLastKeyFrameId=mCurrentFrame.mnId;mpLastKeyFrame = pKFcur;mvpLocalKeyFrames.push_back(pKFcur);mvpLocalKeyFrames.push_back(pKFini);mvpLocalMapPoints=mpMap-&gt;GetAllMapPoints();mpReferenceKF = pKFcur;mCurrentFrame.mpReferenceKF = pKFcur;mLastFrame = Frame(mCurrentFrame);mpMap-&gt;SetReferenceMapPoints(mvpLocalMapPoints);mpMapDrawer-&gt;SetCurrentCameraPose(pKFcur-&gt;GetPose());mpMap-&gt;mvpKeyFrameOrigins.push_back(pKFini); 2.9 初始化完成，mState=OK1mState=OK;// 初始化成功，至此，初始化过程完成 3. 初始化结束后，对每一帧图像进行track()此时mState==OK，track()函数走else分支 op1=>operation: SLAM.TrackMonocular() op2=>operation: GrabImageMonocular() op3=>operation: Track() op1(right)->op2(right)->op3{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析五]]></title>
    <url>%2F2019%2F06%2F11%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%94%2F</url>
    <content type="text"><![CDATA[ORBmatcher类说明单目SLAM初始化相关，双目和RGBD不会使用这个类 1. ORBmatcher 成员变量说明1.1 ORBmatcher 成员变量说明123static const int TH_LOW;static const int TH_HIGH;static const int HISTO_LENGTH; 1.2 ORBmatcher 匹配分数设置1float mfNNratio; 1.3 ORBmatcher 是否检查方向1bool mbCheckOrientation;]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析四]]></title>
    <url>%2F2019%2F06%2F11%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[初始器 Initializer类说明1. Initializer 成员变量说明1typedef pair&lt;int,int&gt; Match; 定义Match类型 1.1 特征点匹配数据类型声明 Match1typedef pair&lt;int,int&gt; Match; 定义Match类型 1.2 mvKeys1，mvKeys2参考帧和当前帧中的特征点12345// Keypoints from Reference Frame (Frame 1)vector&lt;cv::KeyPoint&gt; mvKeys1; ///&lt; 存储Reference Frame中的特征点// Keypoints from Current Frame (Frame 2)vector&lt;cv::KeyPoint&gt; mvKeys2; ///&lt; 存储Current Frame中的特征点 1.3 特征匹配结构说明1234// Current Matches from Reference to Current // Reference Frame: 1, Current Frame: 2 vector&lt;Match&gt; mvMatches12; ///&lt; Match的数据结构是pair,mvMatches12只记录Reference到Current匹配上的特征点对 vector&lt;bool&gt; mvbMatched1; ///&lt; 记录Reference Frame的每个特征点在Current Frame是否有匹配的特征点 1.4 相机内参1cv::Mat mK; ///&lt; 相机内参 1.5 测量误差12// Standard Deviation and Variance float mSigma, mSigma2; ///&lt; 测量误差 1.6 RANSAC迭代次数12// Ransac max iterations int mMaxIterations; ///&lt; 算Fundamental和Homography矩阵时RANSAC迭代次数 1.7 特征匹配结构说明12// Ransac sets vector&lt;vector&lt;size_t&gt; &gt; mvSets; ///&lt; 二维容器，外层容器的大小为迭代次数，内层容器大小为每次迭代算H或F矩阵需要的点 2. Initializer 成员函数说明2.1 Initializer构造函数说明123456789101112131415161718 // Fix the reference frame // 用reference frame来初始化，这个reference frame就是SLAM正式开始的第一帧 Initializer(const Frame &amp;ReferenceFrame, float sigma = 1.0, int iterations = 200);/** * @brief 给定参考帧构造Initializer * * 用reference frame来初始化，这个reference frame就是SLAM正式开始的第一帧 * @param ReferenceFrame 参考帧 * @param sigma 测量误差 * @param iterations RANSAC迭代次数 */ mK = ReferenceFrame.mK.clone(); mvKeys1 = ReferenceFrame.mvKeysUn; mSigma = sigma; mSigma2 = sigma*sigma; mMaxIterations = iterations; 2.1 Initialize()函数说明12345// Computes in parallel a fundamental matrix and a homography // Selects a model and tries to recover the motion and the structure from motion // 用current frame,也就是用SLAM逻辑上的第二帧来初始化整个SLAM，得到最开始两帧之间的R t,以及点云 bool Initialize(const Frame &amp;CurrentFrame, const vector&lt;int&gt; &amp;vMatches12, cv::Mat &amp;R21, cv::Mat &amp;t21, vector&lt;cv::Point3f&gt; &amp;vP3D, vector&lt;bool&gt; &amp;vbTriangulated); 针对第一二帧图像进行初始化，初始化时需要确定第二帧相对于第一帧的旋转矩阵和平移向量，以及生成的三维地图点和是否能三角测量化，并行地计算基础矩阵和单应性矩阵，选取其中一个模型，恢复出最开始两帧之间的相对姿态以及点云。 初始化匹配特征点点1234567891011// Fill structures with current keypoints and matches with reference frame// Reference Frame: 1, Current Frame: 2// Frame2 特征点mvKeys2 = CurrentFrame.mvKeysUn;// mvMatches12记录匹配上的特征点对mvMatches12.clear();mvMatches12.reserve(mvKeys2.size());// mvbMatched1记录每个特征点是否有匹配的特征点，// 这个变量后面没有用到，后面只关心匹配上的特征点mvbMatched1.resize(mvKeys1.size()); 2.2 FindHomography()函数说明12// 假设场景为平面情况下通过前两帧求取Homography矩阵(current frame 2 到 reference frame 1),并得到该模型的评分 void FindHomography(vector&lt;bool&gt; &amp;vbMatchesInliers, float &amp;score, cv::Mat &amp;H21); 平面情况下评估Homograph矩阵并计算得分 2.3 FindFundamental()函数说明12// 假设场景为非平面情况下通过前两帧求取Fundamental矩阵(current frame 2 到 reference frame 1),并得到该模型的评分 void FindFundamental(vector&lt;bool&gt; &amp;vbInliers, float &amp;score, cv::Mat &amp;F21); 非平面情况下评估Fundamental矩并计算得分 2.4 ComputeH21()函数说明12// 被FindHomography函数调用具体来算Homography矩阵 cv::Mat ComputeH21(const vector&lt;cv::Point2f&gt; &amp;vP1, const vector&lt;cv::Point2f&gt; &amp;vP2); 2.5 FindHomography()函数说明12// 被FindFundamental函数调用具体来算Fundamental矩阵 cv::Mat ComputeF21(const vector&lt;cv::Point2f&gt; &amp;vP1, const vector&lt;cv::Point2f&gt; &amp;vP2); 2.6 CheckHomography()函数说明12// 被FindHomography函数调用，具体来算假设使用Homography模型的得分 float CheckHomography(const cv::Mat &amp;H21, const cv::Mat &amp;H12, vector&lt;bool&gt; &amp;vbMatchesInliers, float sigma); 2.7 FindHomography()函数说明12// 被FindFundamental函数调用，具体来算假设使用Fundamental模型的得分 float CheckFundamental(const cv::Mat &amp;F21, vector&lt;bool&gt; &amp;vbMatchesInliers, float sigma); 2.8 ReconstructF()函数说明123// 分解F矩阵，并从分解后的多个解中找出合适的R，t bool ReconstructF(vector&lt;bool&gt; &amp;vbMatchesInliers, cv::Mat &amp;F21, cv::Mat &amp;K, cv::Mat &amp;R21, cv::Mat &amp;t21, vector&lt;cv::Point3f&gt; &amp;vP3D, vector&lt;bool&gt; &amp;vbTriangulated, float minParallax, int minTriangulated); 2.9 ReconstructH()函数说明123// 分解H矩阵，并从分解后的多个解中找出合适的R，t bool ReconstructH(vector&lt;bool&gt; &amp;vbMatchesInliers, cv::Mat &amp;H21, cv::Mat &amp;K, cv::Mat &amp;R21, cv::Mat &amp;t21, vector&lt;cv::Point3f&gt; &amp;vP3D, vector&lt;bool&gt; &amp;vbTriangulated, float minParallax, int minTriangulated); 2.10 Triangulate()函数说明12// 通过三角化方法，利用反投影矩阵将特征点恢复为3D点 void Triangulate(const cv::KeyPoint &amp;kp1, const cv::KeyPoint &amp;kp2, const cv::Mat &amp;P1, const cv::Mat &amp;P2, cv::Mat &amp;x3D); 2.11 Normalize()函数说明12// 归一化三维空间点和帧间位移t void Normalize(const vector&lt;cv::KeyPoint&gt; &amp;vKeys, vector&lt;cv::Point2f&gt; &amp;vNormalizedPoints, cv::Mat &amp;T); 2.12 CheckRT()函数说明1234// ReconstructF调用该函数进行cheirality check，从而进一步找出F分解后最合适的解 int CheckRT(const cv::Mat &amp;R, const cv::Mat &amp;t, const vector&lt;cv::KeyPoint&gt; &amp;vKeys1, const vector&lt;cv::KeyPoint&gt; &amp;vKeys2, const vector&lt;Match&gt; &amp;vMatches12, vector&lt;bool&gt; &amp;vbInliers, const cv::Mat &amp;K, vector&lt;cv::Point3f&gt; &amp;vP3D, float th2, vector&lt;bool&gt; &amp;vbGood, float &amp;parallax); 2.13 DecomposeE()函数说明12// F矩阵通过结合内参可以得到Essential矩阵，该函数用于分解E矩阵，将得到4组解 void DecomposeE(const cv::Mat &amp;E, cv::Mat &amp;R1, cv::Mat &amp;R2, cv::Mat &amp;t);]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Schmidt 正交化]]></title>
    <url>%2F2019%2F05%2F31%2FSchmidt-%E6%AD%A3%E4%BA%A4%E5%8C%96%2F</url>
    <content type="text"><![CDATA[施密特正交化(Schmidt orthogonalization)是求欧氏空间正交基的一种方法。从欧氏空间任意线性无关的向量组$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_m}$出发，求得正交向量组$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\cdots,\boldsymbol{\beta_m}$，$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_m}$与向量组$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\cdots,\boldsymbol{\beta_m}$等价，再将正交向量组中每个向量经过单位化，就得到一个标准正交向量组，这种方法称为施密特正交化。 线性无关向量组未必是正交向量组，但正交向量组又是重要的，因此现在就有一个问题：能否从一个线性无关向量组$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_m}$出发，构造出一个标准正交向量组$\boldsymbol{e_1},\boldsymbol{e_2},\cdots,\boldsymbol{e_m}$，并且使向量组$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_m}$与向量组$\boldsymbol{e_1},\boldsymbol{e_2},\cdots,\boldsymbol{e_m}$等价呢?回答是肯定的，通过施密特正交化方法就可以实现。下面就来介绍这个方法，由于把一个正交向量组中每个向量经过单位化，就得到一个标准正交向量组，所以，上述问题的关键是如何由一个线性无关向量组来构造出一个正交向量组，我们以3个向量组成的线性无关组为例来说明这个方法。设向量组$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\boldsymbol{\alpha_3}$线性无关，我们先来构造正交向量组$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\boldsymbol{\beta_3}$，并且使$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_r}$与向量组$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\cdots,\boldsymbol{\beta_r}$等价$(r=1,2,3)$。按所要求的条件，$\boldsymbol{\beta_1}$是$\boldsymbol{\alpha_1}$的线性组合，$\boldsymbol{\beta_2}$是$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2}$的线性组合，为方便起见，不妨设 \boldsymbol{\beta_1}=\boldsymbol{\alpha_1},\boldsymbol{\beta_2}=\boldsymbol{\alpha_2}-k\boldsymbol{\beta_1}其中，数值$k$的选取应满足$\boldsymbol{\beta_1}$与$\boldsymbol{\beta_2}$垂直，即 \langle\boldsymbol{\beta_2},\boldsymbol{\beta_1}\rangle=\langle\boldsymbol{\alpha_2},\boldsymbol{\beta_1}\rangle - k\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle=0注意到$\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle &gt; 0$，于是得$k={\langle\boldsymbol{\alpha_2},\boldsymbol{\beta_1}\rangle} / {\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle}$，从而得 \boldsymbol{\beta_1} =\boldsymbol{\alpha_1},\boldsymbol{\beta_2}=\boldsymbol{\alpha_2}-\frac{\langle\boldsymbol{\alpha_2},\boldsymbol{\beta_1}\rangle}{\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle}\boldsymbol{\beta_1}对于上面已经构造的向量$\boldsymbol{\beta_1}$和$\boldsymbol{\beta_2}$，再来构造$\boldsymbol{\beta_3}$，为满足要求，可以令 \boldsymbol{\beta_3} = \boldsymbol{\alpha_3}-k_1\boldsymbol{\beta_1}-k_2\boldsymbol{\beta_2}其中，$k_1,k_2$的选取应满足$\boldsymbol{\beta_3}$分别与向量$\boldsymbol{\beta_1}$和$\boldsymbol{\beta_2}$垂直，即 \langle\boldsymbol{\beta_3},\boldsymbol{\beta_1}\rangle=\langle\boldsymbol{\alpha_3},\boldsymbol{\beta_1}\rangle - k_1\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle=0，\langle\boldsymbol{\beta_3},\boldsymbol{\beta_2}\rangle=\langle\boldsymbol{\alpha_3},\boldsymbol{\beta_2}\rangle - k_2\langle\boldsymbol{\beta_2},\boldsymbol{\beta_2}\rangle=0由此解得 k_1=\frac{\langle \boldsymbol{\alpha_3},\boldsymbol{\beta_1}\rangle}{\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle}, k_2=\frac{\langle\boldsymbol{\alpha_3},\boldsymbol{\beta_2}\rangle}{\langle\boldsymbol{\beta_2},\boldsymbol{\beta_2}\rangle}于是得 \boldsymbol{\beta_3} = \boldsymbol{\alpha_3}-\frac{\langle\boldsymbol{\alpha_3},\boldsymbol{\beta_1}\rangle}{\langle\boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle}\boldsymbol{\beta_1}-\frac{\langle\boldsymbol{\alpha_3},\boldsymbol{\beta_2}\rangle}{\langle\boldsymbol{\beta_2},\boldsymbol{\beta_2}\rangle}\boldsymbol{\beta_2}容易验证，向量组$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\cdots,\boldsymbol{\beta_r}$是与$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_r}$等价的正交向量，若再将$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\cdots,\boldsymbol{\beta_r}$单位化，即令 \boldsymbol{e_i} = \frac{\boldsymbol{\beta_i}}{\Vert \boldsymbol{\beta_i} \Vert}(i=1,2,3)则$\boldsymbol{e}_1,\boldsymbol{e_2},\boldsymbol{e_3}$就是满足要求的标准正交向量。 数学归纳法一般性定理设$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_m}(m\leq n)$是$\mathbb{R}^n$中的一个线性无关向量组，若令 \begin{array}{l} \boldsymbol{\beta_1} = \boldsymbol{\alpha_1} \\[2ex] \boldsymbol{\beta_2} = \boldsymbol{\alpha_2}-\frac{\langle \boldsymbol{\alpha_2} , \boldsymbol{\beta_1} \rangle } {\langle \boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle}\boldsymbol{\beta_1} \\[2ex] \boldsymbol{\beta_m} = \boldsymbol{\alpha_m} - \frac{\langle \boldsymbol{\alpha_m} , \boldsymbol{\beta_1} \rangle } {\langle \boldsymbol{\beta_1},\boldsymbol{\beta_1}\rangle }\boldsymbol{\beta_1}-\frac{\langle \boldsymbol{\alpha_m} , \boldsymbol{\beta_2} \rangle } {\langle \boldsymbol{\beta_2},\boldsymbol{\beta_2}\rangle }\boldsymbol{\beta_2}-\cdots- \frac{\langle \boldsymbol{\alpha_m} , \boldsymbol{\beta_{m-1}} \rangle } {\langle \boldsymbol{\beta_{m-1}},\boldsymbol{\beta_{m-1}}\rangle }\beta_{m-1} \end{array} 则$\boldsymbol{\beta_1},\boldsymbol{\beta_2},\cdots,\boldsymbol{\beta_m}$就是一个正交向量组，若再令 \boldsymbol{e_i}=\frac {\boldsymbol{\beta_i}}{\Vert \boldsymbol{\beta_i} \Vert}(i=1,2,\cdots,m)就得到了一个标准正交向量组$\boldsymbol{e_1},\boldsymbol{e_2},\cdots,\boldsymbol{e_m}$， 且该向量和$\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},\cdots,\boldsymbol{\alpha_m}$上述所说明的利用线性无关向量组，构造出一个标准正交向量组的方法，就是施密特正交化方法。]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>矩阵分解</tag>
        <tag>Math</tag>
        <tag>正交化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵分解]]></title>
    <url>%2F2019%2F05%2F31%2F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. QR分解定理 1 对任意非奇异实矩阵$A$总可以分解为正交矩阵$Q$与上三角矩阵$R$的积,如果要求上三角阵$R$的对角元素均为正数,则分解是唯一的。]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>矩阵分解</tag>
        <tag>Math</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最小二乘问题]]></title>
    <url>%2F2019%2F05%2F30%2F%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 非齐次线性最小二乘问题考虑线性系统： \begin{array}{c} Ax = b & \text(A \in R^{ m \times n }(m > n),b \in R^m,x \in R^n) \end{array}的最小二乘解。即求 $ x \in R^n $使得 \begin{Vmatrix} Ax-b \end{Vmatrix} _2 = \min \{ \begin{Vmatrix} Av-b \end{Vmatrix} _2:v \in R^n\}记 X_{LS}=\{ x\in R^n:x是 (1) 的解\}则称$X_{LS}$是最小二乘问题的解集；$X_{LS}$中范数最小者称为最小范数解，并记作$x_{LS}$，即 \begin{Vmatrix} x_{LS} \end{Vmatrix} _2 = \min \{ \begin{Vmatrix} x \end{Vmatrix} _2 : x \in X_{LS}\}命题 1 $x\in X_{LS} \iff A^T(Ax-b)=0$证明 $\forall x,y \in R^n,$有 \begin{Vmatrix} b-A(x+y) \end{Vmatrix} _2^2 = \begin{Vmatrix} b-Ax \end{Vmatrix} _2^2 - 2y^TA^T(b-Ax)+ \begin{Vmatrix} Ay \end{Vmatrix} _2^2因此， x \in X_{LS} \iff \forall y \in R^n,\begin{Vmatrix} Ay \end{Vmatrix} _2^2 - 2y^TA^T(b-Ax)\geq 0 \iff A^T(b-Ax)=0方程$A^T(b-Ax)=0$称为$Ax-b=0$的正规方程。推论 1 $X_{LS}$是凸集； $x_{LS}$是唯一的； $X_{LS} = \{ x_{LS}的充分必要条件是rank(A)=n \}$。 Moore-Pseudo 广义逆为了给出最小二乘的一般表示，需要矩阵的广义逆的概念。 定义 1 $Ａ\in R_{m \times n} $，若$X\in R_{n\times m}$满足 \begin{array}{c} AXA = A ,& XAX=X ,& (AX)^T=AX ,& (XA)^T=XA \end{array}则称$X$是$A$的广义逆，并记作$A^+$。矩阵$A$的广义逆是唯一的，并且可以利用$A$的 SVD 分解进行计算。令$A$的 SVD 分解为 A=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T不难验证： A^+=V\begin{pmatrix}\Sigma_r^{-1} & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}U^T命题 2 最小二乘问题的一般解为 x=A^+b+(I-A^+A)z,z\in R^n最小范数解是 x_{LS}=A^+b证明 由命题1，最小二乘问题(1)的解可以由它的正规方程: A^TAx=A^Tb给出。利用广义逆，可以验证x=A^+b是上式的一个解。另外，由 SVD 分解可证明$N(A^TA)=N(A)$，且 N(A) = \{(I-A^+A)z:z\in R^n\}此外，注意到 [(I-A^+A)z]^TA^+b=z^T(I-A^+A)A^+b=0所以， \begin{Vmatrix} x \end{Vmatrix} _2^2 = \begin{Vmatrix} A^+b \end{Vmatrix} _2^2 + \begin{Vmatrix} (I-A^+A)z \end{Vmatrix} _2^2 \geq \begin{Vmatrix} A^+b \end{Vmatrix} _2^2即：$x_{LS}=A^+b$ 满秩最小二乘问题如果(1)中的矩阵$A$是列满秩的，即$rank(A)=n$，则称它为满秩最小二乘问题。可以通过正规分解法，QR 分解法来求解该最小二乘问题，但最好的方法还是 SVD 分解法。 SVD分解方法由于$rank(A)=n$，所以$A$必有下述形式的 SVD 分解$A=U\begin{pmatrix}\Sigma_n \ 0\end{pmatrix}V^T$，于是，$A^+=V\begin{pmatrix}\Sigma_n^{-1},0 \end{pmatrix}U^T$。所以，问题的解为 x=A^+b=V\begin{pmatrix}\Sigma_n^{-1},0 \end{pmatrix}U^Tb=\frac{u_1^Tb}{\sigma_1}v_1+\frac{u_2^Tb}{\sigma_2}v_2+\cdots+\frac{u_n^Tb}{\sigma_n}v_n = \sum_{j=1}^{n}\frac{u_j^Tb}{\sigma_j}v_j亏秩最小二乘问题此时不可以利用其他方法来求解最小二乘问题，SVD 方法是首选。具体来说，若$rank(A)=r$，则$A$有 SVD 分解: A=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T因此， x=A^+b=V\begin{pmatrix}\Sigma_r^{-1} & \boldsymbol 0 \\ \boldsymbol 0 & 0\end{pmatrix}U^Tb = \sum_{j=1}^{r}\frac{u_j^Tb}{\sigma_j}v_j数值秩的定义和确定方法略 以后再补 2. 齐次最小二乘问题考虑齐次线性方程： \begin{array}{c} Ax = 0 & \text(A \in R^{ m \times n }(m > n),b \in R^m,x \in R^n) \end{array}对应的最小二乘问题是 \begin{Vmatrix} Ax \end{Vmatrix} _2 = \min \{ \begin{Vmatrix} Av \end{Vmatrix} _2:v \in R^n\}显然，$x=0$总是上述最小二乘问题的最小范数解。在实际中，人们通常关心的是它的非零解，而不是零解。因此，总是考虑相应的约束最小二乘问题: \begin{Vmatrix} Ax \end{Vmatrix}_2 = \min \{ \begin{Vmatrix} Av \end{Vmatrix}_2:v\in R^n,\begin{Vmatrix} v \end{Vmatrix}_2 = 1\}或者等价的写成 \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix}_2\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1 \end{array} \right.命题 3 若$rank(A)=r$，则该齐次线性方程的解为 x=\sum_{j=1}^{n-r}s_jv_{r+j},(\sum_{j=1}^{n-r}s_j^2=1)其中，$v_{r+1},v_{r+2},\cdots,v_n$是$A^TA$的零特征值的$n-r$个线性无关的单位特征向量。 证明 问题等价于: \left\{ \begin{array}{l} \min x^TA^TAx\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1 \end{array} \right.因$rank(A^TA)=rank(A)=r$，所以$A^TA$有特征值分解 A^TA=Vdiag(\lambda_1,\lambda_2,\cdots,\lambda_r,0,\cdots,0)V^T其中，$V$是正交矩阵，所以$v_{r+1},v_{r+2},\cdots,v_n$是$A^TAx=0$的$n-r$个相互正交的单位解，因此，上述问题的解为 x=\sum_{j=1}^{n-r}s_jv_{r+j},(\sum_{j=1}^{n-r}s_j^2=1)命题 4 若$rank(A)=r$，则该齐次线性方程的解为 x=\sum_{j=1}^{n-r}s_jv_{r+j},(\sum_{j=1}^{n-r}s_j^2=1)其中，$v_{r+1},v_{r+2},\cdots,v_n$是$A$的$n-r$个零奇异值的右奇异向量。 3. 约束齐次最小二乘问题零约束考虑约束最小二乘问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix} _2^2\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1,Cx=0 \end{array} \right.不妨假设$rank(C)=r &lt; n$，对$C$作 SVD 分解 C=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T令$V_{n-r}=(v_{r+1},v_{r+2},\cdots,v_{n})$为$V$的最后$n-r$个列向量所构成的矩阵，因为$Cx=0$的所有解可以表示为: x=V_{n-r}y,y \in R^{n-r}并且$\begin{Vmatrix} Ax\end{Vmatrix} _2^2=1 \iff \begin{Vmatrix} y\end{Vmatrix} _2^2=1$，这是因为$V_{n-r}$是列正交的。于是，上述问题可以转化为下述最小化问题 \left\{ \begin{array}{l} \min \begin{Vmatrix} AV_{n-r}y \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} y \end{Vmatrix}_2=1 \end{array} \right.这个问题在上一节已经解决。 值约束考虑约束最小二乘问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix} _2^2\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1,x=Cy \end{array} \right.不妨假设$rank(C)=r &lt; n$，对$C$作 SVD 分解 C=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T由 SVD 分解特性可知，矩阵$C$的值空间可以表示为 x = R(C)=\{U_rx'|x'\in R^r\}其中，$U_r$为$U$的前$r$列所构成的矩阵。于是$x=Cy$可以表示为$x=U_rx’$且有$\begin{Vmatrix}x\end{Vmatrix} _2^2=1 \iff \begin{Vmatrix} x’\end{Vmatrix} _2^2=1$，这是因为$U_r$是列正交的。于是，上述问题可以转化为下述最小化问题 \left\{ \begin{array}{l} \min \begin{Vmatrix} AU_rx' \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} x' \end{Vmatrix}_2=1 \end{array} \right.这个问题在上一节已经解决。 模约束考虑约束最小二乘问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix} _2^2\\[2ex] subject to\begin{Vmatrix} Cx \end{Vmatrix}_2=1 \end{array} \right.不妨假设$rank(C)=r &lt; n$，对$C$作 SVD 分解 C=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T令$x’=V^Tx$，则有 Cx = U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}x'且$\begin{Vmatrix} Ax \end{Vmatrix} _2=1 \iff \begin{Vmatrix}\Sigma_r &amp; \boldsymbol 0 \ \boldsymbol 0 &amp; 0\end{Vmatrix}x’=1 \iff \begin{Vmatrix} \Sigma_rx’\end{Vmatrix} _2=1 $，其中， x'= \begin{pmatrix} x'_r \\ x'_{n-r}\end{pmatrix}所以， Ax=AVx'=A'x'= \begin{pmatrix} A'_r & A'_{n-r}\end{pmatrix}\begin{pmatrix} x'_r \\ x'_{n-r}\end{pmatrix}=A'_rx'_r+A'_{n-r}x'_{n-r}取$y=\Sigma_rx’_r$，则$x’_r=\Sigma_r^{-1}y$，于是，上述问题可以转化为下述最小化问题 \left\{ \begin{array}{l} \min \begin{Vmatrix} A'_r\Sigma_r^{-1}y+A'_{n-r}x'_{n-r} \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} y \end{Vmatrix}_2=1 \end{array} \right.由于$\min_{x’_{n-r}} \begin{Vmatrix} A’_r\Sigma_r^{-1}y+A’_{n-r}x’_{n-r} \end{Vmatrix}_2^2$的最小化问题的解为$x’_{n-r} = -{A’}_{n-r}^+A’_r\Sigma_r^{-1}y$于是该求解问题转化为如下最小化问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} (A'_r-A'_{n-r}{A'}_{n-r}^+A'_r)\Sigma_r^{-1}y \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} y \end{Vmatrix}_2=1 \end{array} \right.这个问题在上一节已经解决。注意，$A^+A$不等于$I$，除非A满秩。]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>最小二乘问题</tag>
        <tag>SVD分解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PnP算法]]></title>
    <url>%2F2019%2F05%2F30%2FPnP%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[PnP算法求解相机位姿PnP(Perspective-n-Point) 是求解3D到2D点对运动的方法。它描述了当我们知道n个3D空间点以及它们的投影位置时,如何估计相机所在的位姿。 1. 直接线性变换(DLT)考虑某个空间点$P$,它的齐次坐标为$P=(X, Y, Z, 1)^T$。在图像$I_1$中,投影到特征点$x_1=(u_1,v_1,1)^T$(以归一化平面齐次坐标表示)。此时相机的位姿$R,t$是未知的。与单应矩阵的求解类似,我们定义增广矩阵$[R|t]$为一个$3\times4$的矩阵,包含了旋转与平移信息。我们把它的展开形式列写如下: s\begin{pmatrix} u_1 \\ v_1 \\ 1 \\ \end{pmatrix} = \begin{pmatrix} t_1 & t_2 & t_3 & t_4 \\ t_5 & t_6 & t_7 & t_8 \\ t_9 & t_{10} & t_{11} & t_{12} \\ \end{pmatrix} \begin{pmatrix} X \\ Y \\ Z \\ \end{pmatrix}用最后一行把$s$消去,得到两个约束:\begin{align*}u_1 &amp;= \frac{t_1X+t_2Y+t_3Z+t_4}{t_9X+t_{10}Y+t_{11}Z+t_{12}}\\v_1 &amp;= \frac{t_5X+t_6Y+t_7Z+t_8}{t_9X+t_{10}Y+t_{11}Z+t_{12}}\end{align*} 为了简化表示,定义$T$的行向量: \begin{array}{c} t_1 = (t_1, t_2, t_3, t_4)^T,& t_2 = (t_5, t_6, t_7, t_8)^T,& t_3 = (t_9, t_{10}, t_{11}, t_{12})^T \end{array}于是有: \left\{ \begin{array}{c} t_1^TP-t_3^TPu_1=0 \\ t_2^TP-t_3^TPv_1=0 \end{array} \right.请注意$t$是待求的变量,可以看到每个特征点提供了两个关于$t$的线性约束。假设一共有$N$个特征点,可以列出线性方程组: \begin{pmatrix} P_1^T & 0 & -u_1P_1^T \\ 0 & P_1^T & -v_1P_1^T \\ \vdots & \vdots & \vdots \\ P_N^T & 0 & -u_NP_N^T \\ 0 & P_N^T & -v_NP_N^T \end{pmatrix}由于 $t$ 一共有12维，考虑到齐次性，共有11个自由度，而每一对特征点对都提供了两个约束方程。因此最少通过6对匹配点，即可实现矩阵$T$的线性求解，这种方法(也)称为直接线性变换(Direct Linear Transform，DLT)。当匹配点大于6对时，(又)可以使用 SVD 等方法对超定方程求最小二乘解。在 DLT 求解中，我们直接将$T$矩阵看成了12个未知数，忽略了它们之间的联系。因为旋转矩阵$R∈SO(3)$，用 DLT 求出的解不一定满足该约束，它是一个一般矩阵。平移向量比较好办，它属于向量空间。对于旋转矩阵$R$，我们必须针对 DLT 估计的$T$的左边$3\times3$的矩阵块，寻找一个最好的旋转矩阵对它进行近似。这可以由QR分解完成，相当于把结果从矩阵空间重新投影到$SE(3)$流形上，转换成旋转和平移两部分。需要解释的是,我们这里的$x_1$使用了归一化平面坐标，去掉了内参矩阵$K$的影响——这是因为内参$K$在SLAM中通常假设为已知。如果内参未知,那么我们也能用 PnP 去估计$K,R,t$三个量。然而由于未知量的增多，效果会差一些。]]></content>
      <categories>
        <category>SFM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>SFM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析三]]></title>
    <url>%2F2019%2F05%2F29%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%89%2F</url>
    <content type="text"><![CDATA[ORBextractor特征提取器1. ORBextractor 成员变量1.1 SCORE 得分常量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 描述子的筛选模式1std::vector&lt;cv::Point&gt; pattern; 用来快速建立256维的描述子 1.3 ORBextractor 特征提取器的控制变量12345int nfeatures; // 需要提取的特征点数目double scaleFactor; // ORB 金字塔相邻两层之间的尺度因子int nlevels; // 金字塔的层数int iniThFAST; // FAST角点提取的初始阈值int minThFAST; // FAST角点用初始阈值提取失败后放松阈值再次提取 1.4 每层金字塔对应的特征点数目Vector mnFeaturesPerLevel1std::vector&lt;int&gt; mnFeaturesPerLevel; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.5 每层金字塔对应的尺度因子Vector mvScaleFactor1std::vector&lt;float&gt; mvScaleFactor; 1.6 每层金字塔对应的尺度因子的倒数Vector mvInvScaleFactor1std::vector&lt;float&gt; mvInvScaleFactor; 1.7 每层金字塔对应的Sigma的平方Vector mvLevelSigma21std::vector&lt;float&gt; mvLevelSigma2; 1.8 每层金字塔对应的Sigma的平方的倒数Vector mvLevelSigma21std::vector&lt;float&gt; mvInvLevelSigma2; 1.9 每层金字塔对应图像Mat mvImagePyramid1std::vector&lt;cv::Mat&gt; mvImagePyramid; 1.10 半径为31时所对应的截半径vector1std::vector&lt;int&gt; umax; 2. ORBextractor 成员函数2.1 ORBextractor 构造函数12ORBextractor(int nfeatures, float scaleFactor, int nlevels, int iniThFAST, int minThFAST); 第一步：算金字塔每层的尺度，然后根据尺度计算每层应该提取多少特征点，这里面涉及了一个等比数列，唤起高中的记忆，还挺有意思的。最后，保证提取总特征点数≥ nfeatures。1234567891011121314151617mvScaleFactor.resize(nlevels);mvLevelSigma2.resize(nlevels);mvScaleFactor[0]=1.0f;mvLevelSigma2[0]=1.0f;for(int i=1; i&lt;nlevels; i++)&#123; mvScaleFactor[i]=mvScaleFactor[i-1]*scaleFactor; mvLevelSigma2[i]=mvScaleFactor[i]*mvScaleFactor[i];&#125;mvInvScaleFactor.resize(nlevels);mvInvLevelSigma2.resize(nlevels);for(int i=0; i&lt;nlevels; i++)&#123; mvInvScaleFactor[i]=1.0f/mvScaleFactor[i]; mvInvLevelSigma2[i]=1.0f/mvLevelSigma2[i];&#125; nfeatures: 1000nleves: 8scaleFactor: 1.2iniThFAST: 20minThFAST: 8 mvScaleFactor: 1.0, 1.2, 1.2^2, 1.2^3, 1.2^4, 1.2^5, 1.2^6, 1.2^7mvLevelSigma2: mvScaleFactor[i]*mvScaleFactor[i];mvInvScaleFactor[i]=1.0f/mvScaleFactor[i];mvInvLevelSigma2[i]=1.0f/mvLevelSigma2[i]; 12345678910float factor = 1.0f / scaleFactor;float nDesiredFeaturesPerScale = nfeatures*(1 - factor)/(1 - (float)pow((double)factor, (double)nlevels));int sumFeatures = 0;for( int level = 0; level &lt; nlevels-1; level++ )&#123; mnFeaturesPerLevel[level] = cvRound(nDesiredFeaturesPerScale); sumFeatures += mnFeaturesPerLevel[level]; nDesiredFeaturesPerScale *= factor;&#125;mnFeaturesPerLevel[nlevels-1] = std::max(nfeatures - sumFeatures, 0); 通过等比数列求和来计算初始第0层nDesiredFeaturesPerScale的特征点数 {\rm nfeatures} = \frac{ {\rm nDesiredFeaturesPerScale}\times(1-{\rm factor}^{\rm nlevels})}{1-{\rm factor}}{\rm nDesiredFeaturesPerScale} = \frac{ {\rm nfeatures}\times(1-{\rm factor})}{1-{\rm factor}^{\rm nlevels}}并通过四舍五入来选取每一层的特征点数，最后一层的特征点数要保证总特征点数大于阈值1000 构造描述符生成器12345678910111213141516171819202122const int npoints = 512; const Point* pattern0 = (const Point*)bit_pattern_31_; std::copy(pattern0, pattern0 + npoints, std::back_inserter(pattern)); //This is for orientation // pre-compute the end of a row in a circular patch umax.resize(HALF_PATCH_SIZE + 1); int v, v0, vmax = cvFloor(HALF_PATCH_SIZE * sqrt(2.f) / 2 + 1); int vmin = cvCeil(HALF_PATCH_SIZE * sqrt(2.f) / 2); const double hp2 = HALF_PATCH_SIZE*HALF_PATCH_SIZE; for (v = 0; v &lt;= vmax; ++v) umax[v] = cvRound(sqrt(hp2 - v * v)); // Make sure we are symmetric for (v = HALF_PATCH_SIZE, v0 = 0; v &gt;= vmin; --v) &#123; while (umax[v0] == umax[v0 + 1]) ++v0; umax[v] = v0; ++v0; &#125; 2.2 void operator() 操作符提取关键点和描述符123456// Compute the ORB features and descriptors on an image.// ORB are dispersed on the image using an octree.// Mask is ignored in the current implementation.void operator()( cv::InputArray image, cv::InputArray mask, std::vector&lt;cv::KeyPoint&gt;&amp; keypoints, cv::OutputArray descriptors); 最终生成的特征点列表和描述符都放在引用参数里，ORBextractor没有成员变量保存特征点和描述符，只保存了每一层金字塔的图像 构建图像金字塔123456Mat image = _image.getMat(); assert(image.type() == CV_8UC1 ); // Pre-compute the scale pyramid // 构建图像金字塔 ComputePyramid(image); 计算每层图像的特征点1234// 计算每层图像的兴趣点 vector &lt; vector&lt;KeyPoint&gt; &gt; allKeypoints; // vector&lt;vector&lt;KeyPoint&gt;&gt; ComputeKeyPointsOctTree(allKeypoints); //ComputeKeyPointsOld(allKeypoints); 累加每一层的特征点数量，计算总的特征点数，并建立一个空的描述符矩阵，待填充123456789101112131415Mat descriptors; int nkeypoints = 0; for (int level = 0; level &lt; nlevels; ++level) nkeypoints += (int)allKeypoints[level].size(); if( nkeypoints == 0 ) _descriptors.release(); else &#123; _descriptors.create(nkeypoints, 32, CV_8U); descriptors = _descriptors.getMat(); &#125; _keypoints.clear(); _keypoints.reserve(nkeypoints); 分别统计每一层图像的特征点数，并对每一层金字塔进行高斯滤波，对滤波完的图像和关键点，匹配模式进行描述符的提取，对不同层的特征点的坐标重新定位。描述符的提取，半径为PATCH_SIZE=31123456789101112131415161718192021222324252627282930int offset = 0; for (int level = 0; level &lt; nlevels; ++level) &#123; vector&lt;KeyPoint&gt;&amp; keypoints = allKeypoints[level]; int nkeypointsLevel = (int)keypoints.size(); if(nkeypointsLevel==0) continue; // preprocess the resized image 对图像进行高斯模糊 Mat workingMat = mvImagePyramid[level].clone(); GaussianBlur(workingMat, workingMat, Size(7, 7), 2, 2, BORDER_REFLECT_101); // Compute the descriptors 计算描述子 Mat desc = descriptors.rowRange(offset, offset + nkeypointsLevel); computeDescriptors(workingMat, keypoints, desc, pattern); offset += nkeypointsLevel; // Scale keypoint coordinates if (level != 0) &#123; float scale = mvScaleFactor[level]; //getScale(level, firstLevel, scaleFactor); for (vector&lt;KeyPoint&gt;::iterator keypoint = keypoints.begin(), keypointEnd = keypoints.end(); keypoint != keypointEnd; ++keypoint) keypoint-&gt;pt *= scale; &#125; // And add the keypoints to the output _keypoints.insert(_keypoints.end(), keypoints.begin(), keypoints.end()); &#125; 2.3 ComputePyramid(cv::Mat image) 计算图像金字塔对图像进行线性插值缩小，每次图像的宽和高都缩小1.2倍1234567891011121314151617181920212223242526void ORBextractor::ComputePyramid(cv::Mat image)&#123; for (int level = 0; level &lt; nlevels; ++level) &#123; float scale = mvInvScaleFactor[level]; Size sz(cvRound((float)image.cols*scale), cvRound((float)image.rows*scale)); Size wholeSize(sz.width + EDGE_THRESHOLD*2, sz.height + EDGE_THRESHOLD*2); Mat temp(wholeSize, image.type()), masktemp; mvImagePyramid[level] = temp(Rect(EDGE_THRESHOLD, EDGE_THRESHOLD, sz.width, sz.height)); // Compute the resized image if( level != 0 ) &#123; resize(mvImagePyramid[level-1], mvImagePyramid[level], sz, 0, 0, cv::INTER_LINEAR); copyMakeBorder(mvImagePyramid[level], temp, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, BORDER_REFLECT_101+BORDER_ISOLATED); &#125; else &#123; copyMakeBorder(image, temp, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, BORDER_REFLECT_101); &#125; &#125;&#125; 2.4 ORBextractor::ComputeKeyPointsOctTree 计算特征点四叉树先对每一个网格进行FAST特征点的提取，然后再进行四叉树的建立，根据每一层要求的特征点数量，返回最大响应的特征点，最后计算每一个特征点的主方向，依据灰度质心法。定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 2.5 computeOrientation 计算特征点描述符的方向1keypoint-&gt;angle = IC_Angle(image, keypoint-&gt;pt, umax); 每个特征点的方向采用灰度质心法，即统计半径为15的圆内的灰度质心方向，主要调用IC_Angle函数。 2.6 IC_Angle 计算特征点的主方向12345678910111213141516171819202122232425int m_01 = 0, m_10 = 0; const uchar* center = &amp;image.at&lt;uchar&gt; (cvRound(pt.y), cvRound(pt.x)); // Treat the center line differently, v=0 for (int u = -HALF_PATCH_SIZE; u &lt;= HALF_PATCH_SIZE; ++u) m_10 += u * center[u]; // Go line by line in the circuI853lar patch int step = (int)image.step1(); for (int v = 1; v &lt;= HALF_PATCH_SIZE; ++v) &#123; // Proceed over the two lines int v_sum = 0; int d = u_max[v]; for (int u = -d; u &lt;= d; ++u) &#123; int val_plus = center[u + v*step], val_minus = center[u - v*step]; v_sum += (val_plus - val_minus); m_10 += u * (val_plus + val_minus); &#125; m_01 += v * v_sum; &#125; return fastAtan2((float)m_01, (float)m_10); 先令m_01和m_10都为0，然后计算水平中间线上的均值，注意算均值时，在中心点的左边或者下边距离值是负数。然后依次统计每一条截半径上的水平均值和（累和），以及垂直线上的均值（相减），最后返回tan(m_01,m_10)作为主方向。 3. 初始化Current帧 st=>start: operator()生成特征点和描述符 e=>end: 得到m特征点Vector和描述符Matrix op1=>operation: 参数输入，输入图片矩阵，引用关键点列表，引用描述符矩阵 op2=>operation: 调用ComputePyramid(image)计算图像金字塔，对每一层的图像进行resize(),宽度和高度每次除以1.2然后进行线性插值，保存在成员变量mvImagePyramid里 op3=>operation: 调用ComputeKeyPointsOctTree(allKeypoints)计算特征点四叉树，构建初始网格图，对每一个网格进行特征点的提取 op4=>operation: 调用FAST函数对每一个网格来计算特征点坐标，并进行网格坐标矫正 op5=>operation: 对每一个特征点computeDescriptors(workingMat, keypoints, desc, pattern)计算描述符 st->op1->op2->op3->op4->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: Frame()构造函数生成当前帧 e=>end: 得到mCurrent帧 op1=>operation: 帧ID自加 op2=>operation: 特征提取尺度信息初始化 op3=>operation: 调用ExtractORB(0,imGray)来计算特征点Vector和描述符matrix，0表示単目，1表示双目，提取完的特征点存在mvKeys里面,描述符存在mDescriptors里面，这一步调用了特征提取器的括号运算符 op4=>operation: 对提取的每一个特征点进行矫正去畸变UndistortKeyPoints op5=>operation: ComputeImageBounds(imGray)，计算图片边界，方便进行网格划分 op6=>operation: 将特征点分配到对应的网格AssignFeaturesToGrid() st->op1->op2->op3->op4->op5->op6->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown flowchart.js画流程图]]></title>
    <url>%2F2019%2F05%2F28%2FMarkdown-flowchart.js%E7%94%BB%E6%B5%81%E7%A8%8B%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[Markdown笔记：如何画流程图 Flowchart.js 仅需几行代码即可在 Web 上完成流程图的构建。可以从文字表述中画出简单的 SVG 流程图，也可以画出彩色的图表。 1. 先来看一段入门案例流程图代码在 Markdown 编辑中应该是下面这样的(由于渲染的问题，请把,,,改成三个点号)1234567891011,,,flowst=&gt;start: Starte=&gt;end: Endop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yes or No?io=&gt;inputoutput: catch something...st-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op1,,, 输出结果如图所示: 在markdown语法中，流程图的画法和代码段类似，也就是说，流程图是写在两个,,,之间的。比如说php代码，会是这样一种格式: ,,,php代码段,,, 那么流程图就是这样的: ,,,flow代码段,,,` 2. 语法流程图的语法大体分为两部分: 前面部分用来定义流程图元素； 后面部分用来连接流程图元素，指定流程图的执行走向。 2.1 定义元素阶段的语法1tag=&gt;type: content:&gt;url 上例中下面部分代码都是定义元素部分123456st=&gt;start: Starte=&gt;end: Endop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yes or No?io=&gt;inputoutput: catch something... 说明： tag 是流程图中的标签，在第二段连接元素时会用到。名称可以任意，一般为流程的英文缩写和数字的组合。 type 用来确定标签的类型，=&gt;后面表示类型。由于标签的名称可以任意指定，所以要依赖type来确定标签的类型。 标签有6种类型：start end operation subroutine condition inputoutput。 content 是流程图文本框中的描述内容，: 后面表示内容，中英文均可。特别注意，冒号与文本之间一定要有个空格。 url是一个连接，与框框中的文本相绑定，:&gt;后面就是对应的 url 链接，点击文本时可以通过链接跳转到 url 指定页面。 开始1st=&gt;start: 开始 操作1op1=&gt;operation: 操作、执行说明 条件1cond=&gt;condition: 确认？ 结束1e=&gt;end: 结束 URL（貌似 SF 的编辑器不支持）1e=&gt;点击本结束跳转:&gt;http://https://segmentfault.com/blog/ingood 2.2 连接流程图元素的语法示例代码后面部分 st-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op1 连接流程图元素阶段的语法就简单多了，直接用-&gt;来连接两个元素，几点说明如下：说明： 使用 -&gt; 来连接两个元素 对于condition类型，有yes和no两个分支，如示例中的cond(yes)和cond(no) 每个元素可以制定分支走向，默认向下，也可以用right指向右边，如示例中sub1(right)。 转载声明：本文转载自:https://segmentfault.com/a/1190000006247465?utm_source=tag-newest]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析二]]></title>
    <url>%2F2019%2F05%2F28%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Tracking 线程分析1. Tracking流程图 2. Tracking 成员变量说明2.1 Tracking 状态枚举123456789enum eTrackingState&#123; SYSTEM_NOT_READY=-1, NO_IMAGES_YET=0, NOT_INITIALIZED=1, OK=2, LOST=3 &#125;;eTrackingState mState;eTrackingState mLastProcessedState; 2.2 Tracking 状态枚举 mSensor12// Input sensor:MONOCULAR, STEREO, RGBD int mSensor; mSeneor 传感器类型 2.3 当前帧和当前帧灰度图 mCurrentFrame,mImGray123// Current Frame Frame mCurrentFrame; cv::Mat mImGray; mSeneor 传感器类型 2.4 初始化的时候两帧图像之间的相关变量1234567// Initialization Variables (Monocular)// 初始化时前两帧相关变量std::vector&lt;int&gt; mvIniLastMatches;std::vector&lt;int&gt; mvIniMatches;// 跟踪初始化时前两帧之间的匹配std::vector&lt;cv::Point2f&gt; mvbPrevMatched;std::vector&lt;cv::Point3f&gt; mvIniP3D;Frame mInitialFrame; mSeneor 传感器类型 2.5 Tracking 结果关键帧列表和相对关键帧的位姿列表123456// Lists used to recover the full camera trajectory at the end of the execution.// Basically we store the reference keyframe for each frame and its relative transformationlist&lt;cv::Mat&gt; mlRelativeFramePoses;list&lt;KeyFrame*&gt; mlpReferences;list&lt;double&gt; mlFrameTimes;list&lt;bool&gt; mlbLost; mSeneor 传感器类型 2.6 是否开启地图变量 mbOnlyTracking12// True if local mapping is deactivated and we are performing only localizationbool mbOnlyTracking; mSeneor 传感器类型 2.7 只定位时0地图点是否VO变量12345// In case of performing only localization, this flag is true when there are no matches to// points in the map. Still tracking will continue if there are enough matches with temporal points.// In that case we are doing visual odometry. The system will try to do relocalization to recover// "zero-drift" localization to the map.bool mbVO; mSeneor 传感器类型 2.8 另外两个线程的指针 mpLocalMapper，mpLoopClosing123//Other Thread PointersLocalMapping* mpLocalMapper;LoopClosing* mpLoopClosing; mSeneor 传感器类型 2.9 ORB特征提取器1234567//ORB// orb特征提取器，不管单目还是双目，mpORBextractorLeft都要用到// 如果是双目，则要用到mpORBextractorRight// 如果是单目，在初始化的时候使用mpIniORBextractor而不是mpORBextractorLeft，// mpIniORBextractor属性中提取的特征点个数是mpORBextractorLeft的两倍ORBextractor* mpORBextractorLeft, *mpORBextractorRight;ORBextractor* mpIniORBextractor; mSeneor 传感器类型 2.10 Bow123//BoWORBVocabulary* mpORBVocabulary;KeyFrameDatabase* mpKeyFrameDB; mSeneor 传感器类型 2.11 単目初始器 mpInitializer123// Initalization (only for monocular)// 单目初始器Initializer* mpInitializer; mSeneor 传感器类型 2.12 局部地图1234//Local Map KeyFrame* mpReferenceKF;// 当前关键帧就是参考帧 std::vector&lt;KeyFrame*&gt; mvpLocalKeyFrames; std::vector&lt;MapPoint*&gt; mvpLocalMapPoints; mSeneor 传感器类型 2.13 SLAM 系统指针1System* mpSystem; mSeneor 传感器类型 2.14 显示相关1234//Drawers Viewer* mpViewer; FrameDrawer* mpFrameDrawer; MapDrawer* mpMapDrawer; mSeneor 传感器类型 2.15 系统地图 mpMap12//Map Map* mpMap; mSeneor 传感器类型 2.16 相机参数1234//Calibration matrix cv::Mat mK; cv::Mat mDistCoef; float mbf; mSeneor 传感器类型 2.17 新关键帧插入规则123//New KeyFrame rules (according to fps)int mMinFrames;int mMaxFrames; mSeneor 传感器类型 2.18 深度截断值1234// Threshold close/far points // Points seen as close by the stereo/RGBD sensor are considered reliable // and inserted from just one frame. Far points requiere a match in two keyframes. float mThDepth; mSeneor 传感器类型 2.19 深度图因子12// For RGB-D inputs only. For some datasets (e.g. TUM) the depthmap values are scaled.float mDepthMapFactor;; mSeneor 传感器类型 2.20 当前帧有多少特征点成功匹配12//Current matches in frame int mnMatchesInliers; mSeneor 传感器类型 2.21 上一关键帧、上一帧和重定位信息12345//Last Frame, KeyFrame and Relocalisation Info KeyFrame* mpLastKeyFrame; Frame mLastFrame; unsigned int mnLastKeyFrameId; unsigned int mnLastRelocFrameId; mSeneor 传感器类型 2.22 匀速模型匀速变换矩阵12//Motion Model cv::Mat mVelocity; mSeneor 传感器类型 2.23 相机RGB信息12//Color order (true RGB, false BGR, ignored if grayscale)bool mbRGB; mSeneor 传感器类型 2.24 临时地图点列表1list&lt;MapPoint*&gt; mlpTemporalPoints; mSeneor 传感器类型 共47个成员变量 3. Tracking 类成员函数3.1 构造函数 Tracking()12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 执行完构造函数后mState(NO_IMAGES_YET), mSensor(sensor), mbOnlyTracking(false), mbVO(false), mpORBVocabulary(pVoc),mpKeyFrameDB(pKFDB), mpInitializer(static_cast(NULL)), mpSystem(pSys), mpViewer(NULL),mpFrameDrawer(pFrameDrawer), mpMapDrawer(pMapDrawer), mpMap(pMap), mnLastRelocFrameId(0)等13个变量获得初始值。mK，mDistCoef，mbf，mMinFrames，mMaxFrames，mbRGB，mpORBextractorLeft，mpORBextractorRight，mpIniORBextractor，mThDepth， mDepthMapFactor等12个变量获得具体值。 3.2 抓取图片函数 GrabImageMonocular()1234// Preprocess the input and call Track(). Extract features and performs stereo matching. cv::Mat GrabImageStereo(const cv::Mat &amp;imRectLeft,const cv::Mat &amp;imRectRight, const double &amp;timestamp); cv::Mat GrabImageRGBD(const cv::Mat &amp;imRGB,const cv::Mat &amp;imD, const double &amp;timestamp); cv::Mat GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp); 3.3 设置三个线程指针函数，关联三个线程123void SetLocalMapper(LocalMapping* pLocalMapper);void SetLoopClosing(LoopClosing* pLoopClosing);void SetViewer(Viewer* pViewer); 3.4 矫正相机 ChangeCalibration1234// Load new settings// The focal length should be similar or scale prediction will fail when projecting points// TODO: Modify MapPoint::PredictScale to take into account focal lenghtvoid ChangeCalibration(const string &amp;strSettingPath); 3.5 构造函数12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 3.6 InformOnlyTracking() 设置是否只跟踪12// Use this function if you have deactivated local mapping and you only want to localize the camera. void InformOnlyTracking(const bool &amp;flag); 3.7 Reset() 函数清除所有地图点1void Reset(); 3.8 Track()12// Main tracking function. It is independent of the input sensor.void Track(); 跟踪线程的主函数，独立于传感器类型 3.9 Track初始化函数12345// Map initialization for stereo and RGB-Dvoid StereoInitialization();// Map initialization for monocularvoid MonocularInitialization(); 3.10 构造函数12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 3.11 初始化単目地图1void CreateInitialMapMonocular(); 3.12 检查1void CheckReplacedInLastFrame(); 3.13 构造函数12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 3.14 通过上一参考关键帧来跟踪图像位姿 TrackReferenceKeyFrame()1bool TrackReferenceKeyFrame(); 步骤一：将当前帧的描述子转化为BoW向量123// Compute Bag of Words vector// 步骤1：将当前帧的描述子转化为BoW向量mCurrentFrame.ComputeBoW(); 步骤二：通过特征点的BoW加快当前帧与参考关键帧之间的特征点匹配12345678// We perform first an ORB matching with the reference keyframe // If enough matches are found we setup a PnP solver ORBmatcher matcher(0.7,true); vector&lt;MapPoint*&gt; vpMapPointMatches; // 步骤2：通过特征点的BoW加快当前帧与参考帧之间的特征点匹配 // 特征点的匹配关系由MapPoints进行维护 int nmatches = matcher.SearchByBoW(mpReferenceKF,mCurrentFrame,vpMapPointMatches); 步骤三：检查特征匹配个数是否达到要求12if(nmatches&lt;15) return false; 步骤四：将上一帧的位姿态作为当前帧位姿的初始值，这个时候的位姿都是相对于InitKeyFrame,初始关键帧，即世界坐标系123// 步骤3:将上一帧的位姿态作为当前帧位姿的初始值 mCurrentFrame.mvpMapPoints = vpMapPointMatches; mCurrentFrame.SetPose(mLastFrame.mTcw); // 用上一次的Tcw设置初值，在PoseOptimization可以收敛快一些 步骤五：通过通过优化3D-2D的重投影误差来获得位姿，优化的时候，3D点的坐标是相对于世界坐标系的，所以优化得到的位姿也是相对于世界坐标系的12// 步骤4:通过优化3D-2D的重投影误差来获得位姿 Optimizer::PoseOptimization(&amp;mCurrentFrame); 步骤六：剔除优化后的outlier匹配点（MapPoints）,注意最后一步要求该地图点至少被一个关键帧观察到过,才认为该点是成功匹配点，初始化的时候已经建立了初始的地图点观测信息以及帧之间的连接关系123456789101112131415161718192021// Discard outliers // 步骤5：剔除优化后的outlier匹配点（MapPoints） int nmatchesMap = 0; for(int i =0; i&lt;mCurrentFrame.N; i++) &#123; if(mCurrentFrame.mvpMapPoints[i]) &#123; if(mCurrentFrame.mvbOutlier[i]) &#123; MapPoint* pMP = mCurrentFrame.mvpMapPoints[i]; mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL); mCurrentFrame.mvbOutlier[i]=false; pMP-&gt;mbTrackInView = false; pMP-&gt;mnLastFrameSeen = mCurrentFrame.mnId; nmatches--; &#125; else if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0) nmatchesMap++; &#125; &#125; 步骤七：返回匹配结果是否达到要求1return nmatchesMap&gt;=10; 3.15 更新上一帧1void UpdateLastFrame(); 3.16 通过上一帧来跟踪图像位姿，利用匀速模型1234567891011/** * @brief 根据匀速度模型对上一帧的MapPoints进行跟踪 * * 1. 非单目情况，需要对上一帧产生一些新的MapPoints（临时） * 2. 将上一帧的MapPoints投影到当前帧的图像平面上，在投影的位置进行区域匹配 * 3. 根据匹配对估计当前帧的姿态 * 4. 根据姿态剔除误匹配 * @return 如果匹配数大于10，返回true * @see V-B Initial Pose Estimation From Previous Frame */bool TrackWithMotionModel(); 3.17 跟踪丢失重定位1bool Relocalization(); 3.18 更新局部地图信息，更新局部地图，更新局部3D点，更新局部地图关键帧123void UpdateLocalMap(); // 先调用UpdateLocalKeyFrames()，再调用UpdateLocalPoints()，最后设置mvpReferenceMapPointsvoid UpdateLocalPoints();void UpdateLocalKeyFrames(); 更新局部关键帧信息 UpdateLocalKeyFrames() 步骤1：遍历当前帧的MapPoints，记录所有能观测到当前帧MapPoints的关键帧123456789101112131415161718192021map&lt;KeyFrame*,int&gt; keyframeCounter;//先统计能看到当前帧mappoints的各个关键帧，map的键是关键帧，值是观察到该帧地图点的个数//遍历所有的地图点，看有哪些帧能够观测到该地图点，让该帧的值加一for(int i=0; i&lt;mCurrentFrame.N; i++)&#123; if(mCurrentFrame.mvpMapPoints[i]) &#123; MapPoint* pMP = mCurrentFrame.mvpMapPoints[i]; if(!pMP-&gt;isBad()) &#123; // 能观测到当前帧MapPoints的关键帧 const map&lt;KeyFrame*,size_t&gt; observations = pMP-&gt;GetObservations(); for(map&lt;KeyFrame*,size_t&gt;::const_iterator it=observations.begin(), itend=observations.end(); it!=itend; it++) keyframeCounter[it-&gt;first]++; &#125; else &#123; mCurrentFrame.mvpMapPoints[i]=NULL; &#125; &#125;&#125; 如果keyframeCounter为空，直接结束12if(keyframeCounter.empty()) return; 寻找共视程度最高的关键帧，即和该帧拥有最多共同地图点的关键帧pKFmax12345678910111213141516171819202122232425262728int max=0;KeyFrame* pKFmax= static_cast&lt;KeyFrame*&gt;(NULL);// 步骤2：更新局部关键帧（mvpLocalKeyFrames），添加局部关键帧有三个策略// 先清空局部关键帧mvpLocalKeyFrames.clear();mvpLocalKeyFrames.reserve(3*keyframeCounter.size());// All keyframes that observe a map point are included in the local map. Also check which keyframe shares most points// V-D K1: shares the map points with current frame// 策略1：能观测到当前帧MapPoints的关键帧作为局部关键帧for(map&lt;KeyFrame*,int&gt;::const_iterator it=keyframeCounter.begin(), itEnd=keyframeCounter.end(); it!=itEnd; it++)&#123; KeyFrame* pKF = it-&gt;first; if(pKF-&gt;isBad()) continue; if(it-&gt;second&gt;max) &#123; max=it-&gt;second; pKFmax=pKF; &#125; mvpLocalKeyFrames.push_back(it-&gt;first); // mnTrackReferenceForFrame防止重复添加局部关键帧 pKF-&gt;mnTrackReferenceForFrame = mCurrentFrame.mnId;&#125; 步骤2：与策略1得到的局部关键帧共视程度很高的关键帧作为局部关键帧(最佳共视的10帧，自己的子关键帧，自己的父关键帧) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// Include also some not-already-included keyframes that are neighbors to already-included keyframes// V-D K2: neighbors to K1 in the covisibility graph// 策略2：与策略1得到的局部关键帧共视程度很高的关键帧作为局部关键帧for(vector&lt;KeyFrame*&gt;::const_iterator itKF=mvpLocalKeyFrames.begin(), itEndKF=mvpLocalKeyFrames.end(); itKF!=itEndKF; itKF++)&#123; // Limit the number of keyframes if(mvpLocalKeyFrames.size()&gt;80) break; KeyFrame* pKF = *itKF; // 策略2.1:最佳共视的10帧 const vector&lt;KeyFrame*&gt; vNeighs = pKF-&gt;GetBestCovisibilityKeyFrames(10); for(vector&lt;KeyFrame*&gt;::const_iterator itNeighKF=vNeighs.begin(), itEndNeighKF=vNeighs.end(); itNeighKF!=itEndNeighKF; itNeighKF++) &#123; KeyFrame* pNeighKF = *itNeighKF; if(!pNeighKF-&gt;isBad()) &#123; // mnTrackReferenceForFrame防止重复添加局部关键帧 if(pNeighKF-&gt;mnTrackReferenceForFrame!=mCurrentFrame.mnId) &#123; mvpLocalKeyFrames.push_back(pNeighKF); pNeighKF-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId; break; &#125; &#125; &#125; // 策略2.2:自己的子关键帧 const set&lt;KeyFrame*&gt; spChilds = pKF-&gt;GetChilds(); for(set&lt;KeyFrame*&gt;::const_iterator sit=spChilds.begin(), send=spChilds.end(); sit!=send; sit++) &#123; KeyFrame* pChildKF = *sit; if(!pChildKF-&gt;isBad()) &#123; if(pChildKF-&gt;mnTrackReferenceForFrame!=mCurrentFrame.mnId) &#123; mvpLocalKeyFrames.push_back(pChildKF); pChildKF-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId; break; &#125; &#125; &#125; // 策略2.3:自己的父关键帧 KeyFrame* pParent = pKF-&gt;GetParent(); if(pParent) &#123; // mnTrackReferenceForFrame防止重复添加局部关键帧 if(pParent-&gt;mnTrackReferenceForFrame!=mCurrentFrame.mnId) &#123; mvpLocalKeyFrames.push_back(pParent); pParent-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId; break; &#125; &#125;&#125; 步骤3：更新当前帧的参考关键帧，与自己共视程度最高的关键帧作为参考关键帧 12345if(pKFmax)&#123; mpReferenceKF = pKFmax; mCurrentFrame.mpReferenceKF = mpReferenceKF;&#125; 更新局部3D点信息 UpdateLocalPoints()根据已经更新的局部关键帧mvpLocalKeyFrames的MapPoints，更新mvpLocalMapPoints 步骤一：清空局部Tracking线程mptracker的MapPoints 12// 步骤1：清空局部MapPoints mvpLocalMapPoints.clear(); 步骤二：遍历mvpLocalKeyFrames，提取每一帧的地图点 12// 步骤2：遍历局部关键帧mvpLocalKeyFramesfor(vector&lt;KeyFrame*&gt;::const_iterator itKF=mvpLocalKeyFrames.begin(), itEndKF=mvpLocalKeyFrames.end(); itKF!=itEndKF; itKF++) 步骤三：提取每一帧的地图点 1const vector&lt;MapPoint*&gt; vpMPs = pKF-&gt;GetMapPointMatches(); 步骤四：将每一帧的地图点都加入mvpLocalMapPoints 123456789101112131415// 步骤2：将局部关键帧的MapPoints添加到mvpLocalMapPoints for(vector&lt;MapPoint*&gt;::const_iterator itMP=vpMPs.begin(), itEndMP=vpMPs.end(); itMP!=itEndMP; itMP++) &#123; MapPoint* pMP = *itMP; if(!pMP) continue; // mnTrackReferenceForFrame防止重复添加局部MapPoint if(pMP-&gt;mnTrackReferenceForFrame==mCurrentFrame.mnId) continue; if(!pMP-&gt;isBad()) &#123; mvpLocalMapPoints.push_back(pMP); pMP-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId; &#125; &#125; 3.19 跟踪局部地图 TrackLocalMap() 跟踪局部地图主函数1bool TrackLocalMap(); 步骤一：更新局部关键帧mvpLocalKeyFrames和局部地图点mvpLocalMapPoints UpdateLocalMap(); 步骤二：在局部地图中查找与当前帧匹配的MapPoints SearchLocalPoints(); 步骤三：更新局部所有MapPoints后对位姿再次优化 Optimizer::PoseOptimization(&amp;mCurrentFrame); 步骤四：更新当前帧的MapPoints被观测程度，并统计跟踪局部地图的效果，只有当该地图点被其他帧观测到过，才认为匹配正确 1234567891011121314151617181920212223for(int i=0; i&lt;mCurrentFrame.N; i++) &#123; if(mCurrentFrame.mvpMapPoints[i]) &#123; // 由于当前帧的MapPoints可以被当前帧观测到，其被观测统计量加1 if(!mCurrentFrame.mvbOutlier[i]) &#123; mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound(); if(!mbOnlyTracking) &#123; // 该MapPoint被其它关键帧观测到过 if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0) mnMatchesInliers++; &#125; else // 记录当前帧跟踪到的MapPoints，用于统计跟踪效果 mnMatchesInliers++; &#125; else if(mSensor==System::STEREO) mCurrentFrame.mvpMapPoints[i] = static_cast&lt;MapPoint*&gt;(NULL); &#125; &#125; 步骤五：决定是否跟踪成功，重定位的话特征匹配点数大于50，一般情况下特征匹配点数大于30才认为跟踪成功 1234567if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; mnMatchesInliers&lt;50) return false;if(mnMatchesInliers&lt;30) return false;else return true; 3.20 寻找局部地图点 SearchLocalPoints()更新完局部关键帧和局部地图后，对Local MapPoints进行跟踪，在局部地图中查找在当前帧视野范围内的点，将视野范围内的点和当前帧的特征点进行投影匹配1void SearchLocalPoints(); 步骤一： 1234567891011121314151617181920212223// Do not search map points already matched// 步骤1：遍历当前帧的mvpMapPoints，标记这些MapPoints不参与之后的搜索// 因为当前的mvpMapPoints一定在当前帧的视野中for(vector&lt;MapPoint*&gt;::iterator vit=mCurrentFrame.mvpMapPoints.begin(), vend=mCurrentFrame.mvpMapPoints.end(); vit!=vend; vit++)&#123; MapPoint* pMP = *vit; if(pMP) &#123; if(pMP-&gt;isBad()) &#123; *vit = static_cast&lt;MapPoint*&gt;(NULL); &#125; else &#123; // 更新能观测到该点的帧数加1 pMP-&gt;IncreaseVisible(); // 标记该点被当前帧观测到，为了避免重复添加 pMP-&gt;mnLastFrameSeen = mCurrentFrame.mnId; // 标记该点将来不被投影，因为已经匹配过，mbTrackInView = false 表示不进行投影 pMP-&gt;mbTrackInView = false; &#125; &#125;&#125; 步骤二： 统计哪些mapPoints需要进行重投影，nToMatch统计需要进行重投影的点的个数 123456789101112131415161718192021222324// Project points in frame and check its visibility // 步骤2：将所有局部MapPoints投影到当前帧，判断是否在视野范围内，然后进行投影匹配 for(vector&lt;MapPoint*&gt;::iterator vit=mvpLocalMapPoints.begin(), vend=mvpLocalMapPoints.end(); vit!=vend; vit++) &#123; MapPoint* pMP = *vit; // 已经被当前帧观测到MapPoint不再判断是否能被当前帧观测到 if(pMP-&gt;mnLastFrameSeen == mCurrentFrame.mnId) continue; if(pMP-&gt;isBad()) continue; // Project (this fills MapPoint variables for matching) // 步骤2.1：判断LocalMapPoints中的点是否在在视野内，如果该地图点在视野内，会将该点的mbTrackInView 设置为true，并且会预测它所对应的特征点在金字塔的哪一层，会估计出它在图像的坐标 if(mCurrentFrame.isInFrustum(pMP,0.5)) &#123; // 观测到该点的帧数加1，该MapPoint在某些帧的视野范围内 pMP-&gt;IncreaseVisible(); // 只有在视野范围内的MapPoints才参与之后的投影匹配 nToMatch++; &#125; &#125;``` #### 3.21 判定是否需要插入关键帧 bool NeedNewKeyFrame();1- 步骤一：如果只定位，那么不插入关键帧 // 步骤1：如果用户在界面上选择重定位，那么将不插入关键帧 // 由于插入关键帧过程中会生成MapPoint，因此用户选择重定位后地图上的点云和关键帧都不会再增加 if(mbOnlyTracking) return false; 1- 步骤二：如果局部地图被闭环检测使用，则不插入关键帧 // If Local Mapping is freezed by a Loop Closure do not insert keyframes // 如果局部地图被闭环检测使用，则不插入关键帧 if(mpLocalMapper-&gt;isStopped() || mpLocalMapper-&gt;stopRequested()) return false; 1- 步骤三：如果关键帧比较少，则考虑插入关键帧，或距离上一次重定位超过1s，则考虑插入关键帧 // Do not insert keyframes if not enough frames have passed from last relocalisation // 步骤2：判断是否距离上一次插入关键帧的时间太短 // mCurrentFrame.mnId是当前帧的ID // mnLastRelocFrameId是最近一次重定位帧的ID // mMaxFrames等于图像输入的帧率 // 如果关键帧比较少，则考虑插入关键帧 // 或距离上一次重定位超过1s，则考虑插入关键帧 if(mCurrentFrame.mnIdmMaxFrames) return false;12- 步骤四：查询局部地图管理器是否繁忙 // Local Mapping accept keyframes? // 步骤4：查询局部地图管理器是否繁忙 bool bLocalMappingIdle = mpLocalMapper-&gt;AcceptKeyFrames();12- 步骤五：对于双目或RGBD摄像头，统计总的可以添加的MapPoints数量和跟踪到地图中的MapPoints数量 // 步骤5：对于双目或RGBD摄像头，统计总的可以添加的MapPoints数量和跟踪到地图中的MapPoints数量 int nMap = 0; int nTotal= 0; if(mSensor!=System::MONOCULAR)// 双目或rgbd { for(int i =0; i0 &amp;&amp; mCurrentFrame.mvDepth[i]Observations()&gt;0) nMap++;// 被关键帧观测到的mappoints数，即观测到地图中的MapPoints数量 } } } else { // There are no visual odometry matches in the monocular case nMap=1; nTotal=1; } const float ratioMap = (float)nMap/(float)(std::max(1,nTotal)); 1- 步骤六：设定阈值，判定是否需要插入关键帧 // 步骤6：决策是否需要插入关键帧 // Thresholds // 设定inlier阈值，和之前帧特征点匹配的inlier比例 float thRefRatio = 0.75f; if(nKFs&lt;2) thRefRatio = 0.4f;// 关键帧只有一帧，那么插入关键帧的阈值设置很低 if(mSensor==System::MONOCULAR) thRefRatio = 0.9f; // MapPoints中和地图关联的比例阈值 float thMapRatio = 0.35f; if(mnMatchesInliers&gt;300) thMapRatio = 0.20f; // Condition 1a: More than &quot;MaxFrames&quot; have passed from last keyframe insertion // 很长时间没有插入关键帧 const bool c1a = mCurrentFrame.mnId&gt;=mnLastKeyFrameId+mMaxFrames; // Condition 1b: More than &quot;MinFrames&quot; have passed and Local Mapping is idle // localMapper处于空闲状态 const bool c1b = (mCurrentFrame.mnId&gt;=mnLastKeyFrameId+mMinFrames &amp;&amp; bLocalMappingIdle); // Condition 1c: tracking is weak // 跟踪要跪的节奏，0.25和0.3是一个比较低的阈值 const bool c1c = mSensor!=System::MONOCULAR &amp;&amp; (mnMatchesInliers&lt;nRefMatches*0.25 || ratioMap&lt;0.3f) ; // Condition 2: Few tracked points compared to reference keyframe. Lots of visual odometry compared to map matches. // 阈值比c1c要高，与之前参考帧（最近的一个关键帧）重复度不是太高 const bool c2 = ((mnMatchesInliers&lt;nRefMatches*thRefRatio || ratioMap&lt;thMapRatio) &amp;&amp; mnMatchesInliers&gt;15); if((c1a||c1b||c1c)&amp;&amp;c2) { // If the mapping accepts keyframes, insert keyframe. // Otherwise send a signal to interrupt BA if(bLocalMappingIdle) { return true; } else { mpLocalMapper-&gt;InterruptBA(); if(mSensor!=System::MONOCULAR) { // 队列里不能阻塞太多关键帧 // tracking插入关键帧不是直接插入，而且先插入到mlNewKeyFrames中， // 然后localmapper再逐个pop出来插入到mspKeyFrames if(mpLocalMapper-&gt;KeyframesInQueue()&lt;3) return true; else return false; } else return false; } } else return false; 123#### 3.22 创建新的关键帧 *CreateNewKeyFrame()* void CreateNewKeyFrame();1- 步骤一：将当前帧构造成关键帧 // 步骤1：将当前帧构造成关键帧 KeyFrame* pKF = new KeyFrame(mCurrentFrame,mpMap,mpKeyFrameDB);1- 步骤二：将当前关键帧设置为当前帧的参考关键帧 // 步骤2：将当前关键帧设置为当前帧的参考关键帧 // 在UpdateLocalKeyFrames函数中会将与当前关键帧共视程度最高的关键帧设定为当前帧的参考关键帧 mpReferenceKF = pKF; mCurrentFrame.mpReferenceKF = pKF;1- 步骤三：将该关键帧与其他信息相关联，对于双目，要重新生成地图点 mpLocalMapper-&gt;InsertKeyFrame(pKF); mpLocalMapper-&gt;SetNotStop(false); mnLastKeyFrameId = mCurrentFrame.mnId; mpLastKeyFrame = pKF; 123### 4. 实例化mpTracker在System构造函数中new一个Tracing对象指针mpTracker，方式如下所示： //Initialize the Tracking thread//(it will live in the main thread of execution, the one that called this constructor)mpTracker = new Tracking(this, mpVocabulary, mpFrameDrawer, mpMapDrawer, mpMap, mpKeyFrameDatabase, strSettingsFile, mSensor); 1#### 4.1 读取配置文件，构造相机内参 *mK* cv::FileStorage fSettings(strSettingPath, cv::FileStorage::READ); float fx = fSettings[“Camera.fx”]; float fy = fSettings[“Camera.fy”]; float cx = fSettings[“Camera.cx”]; float cy = fSettings[“Camera.cy”]; // |fx 0 cx| // K = |0 fy cy| // |0 0 1 | cv::Mat K = cv::Mat::eye(3,3,CV_32F); K.at&lt;float&gt;(0,0) = fx; K.at&lt;float&gt;(1,1) = fy; K.at&lt;float&gt;(0,2) = cx; K.at&lt;float&gt;(1,2) = cy; K.copyTo(mK); 1#### 4.2 读取配置文件，构造相机矫正向量 *mDistCoef* // 图像矫正系数 // [k1 k2 p1 p2 k3] cv::Mat DistCoef(4,1,CV_32F); DistCoef.at&lt;float&gt;(0) = fSettings[&quot;Camera.k1&quot;]; DistCoef.at&lt;float&gt;(1) = fSettings[&quot;Camera.k2&quot;]; DistCoef.at&lt;float&gt;(2) = fSettings[&quot;Camera.p1&quot;]; DistCoef.at&lt;float&gt;(3) = fSettings[&quot;Camera.p2&quot;]; const float k3 = fSettings[&quot;Camera.k3&quot;]; if(k3!=0) { DistCoef.resize(5); DistCoef.at&lt;float&gt;(4) = k3; } DistCoef.copyTo(mDistCoef); 1#### 4.3 读取配置文件，构造相机RGB参数 *mbRGB* // 1:RGB 0:BGR int nRGB = fSettings[“Camera.RGB”]; mbRGB = nRGB; if(mbRGB) cout &lt;&lt; &quot;- color order: RGB (ignored if grayscale)&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;- color order: BGR (ignored if grayscale)&quot; &lt;&lt; endl; 1#### 4.4 读取配置文件，加载ORB参数 *nFeatures*、*fScaleFactor*、*nLevels*、*fIniThFAST*、*fMinThFAST* // Load ORB parameters // 每一帧提取的特征点数 1000 int nFeatures = fSettings[&quot;ORBextractor.nFeatures&quot;]; // 图像建立金字塔时的变化尺度 1.2 float fScaleFactor = fSettings[&quot;ORBextractor.scaleFactor&quot;]; // 尺度金字塔的层数 8 int nLevels = fSettings[&quot;ORBextractor.nLevels&quot;]; // 提取fast特征点的默认阈值 20 int fIniThFAST = fSettings[&quot;ORBextractor.iniThFAST&quot;]; // 如果默认阈值提取不出足够fast特征点，则使用最小阈值 8 int fMinThFAST = fSettings[&quot;ORBextractor.minThFAST&quot;]; 1#### 4.5 通过*nFeatures*、*fScaleFactor*、*nLevels*、*fIniThFAST*、*fMinThFAST*构造特征提取器 // tracking过程都会用到mpORBextractorLeft作为特征点提取器 mpORBextractorLeft = new ORBextractor(nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST); // 如果是双目，tracking过程中还会用用到mpORBextractorRight作为右目特征点提取器 if(sensor==System::STEREO) mpORBextractorRight = new ORBextractor(nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST); // 在单目初始化的时候，会用mpIniORBextractor来作为特征点提取器 if(sensor==System::MONOCULAR) mpIniORBextractor = new ORBextractor(2*nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST); 1#### 4.6 读取配置文件，构造相机深度截断阈值和视差因子 *mThDepth*,*mDepthMapFactor* if(sensor==System::STEREO || sensor==System::RGBD) { // 判断一个3D点远/近的阈值 mbf * 35 / fx mThDepth = mbf*(float)fSettings[&quot;ThDepth&quot;]/fx; cout &lt;&lt; endl &lt;&lt; &quot;Depth Threshold (Close/Far Points): &quot; &lt;&lt; mThDepth &lt;&lt; endl; } if(sensor==System::RGBD) { // 深度相机disparity转化为depth时的因子 mDepthMapFactor = fSettings[&quot;DepthMapFactor&quot;]; if(fabs(mDepthMapFactor)&lt;1e-5) mDepthMapFactor=1; else mDepthMapFactor = 1.0f/mDepthMapFactor; } ``` st=>start: 调用构造函数实例化mpTracker e=>end: 得到mCurrentFrame.mTcw op1=>operation: 循环SLAM.TrackMonocular(im,tframe)，对每一帧图像进行tracking op2=>operation: 调用mpTracker->GrabImageMonocular(im,timestamp),抓取每一帧图像 op3=>operation: 将RGB图转换为灰度图mImGray op4=>operation: 利用灰度图构造当前帧mCurrentFrame op5=>operation: 调用track()函数 st->op1->op2->op3->op4->op5->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 调用构造函数实例化 mpTracker e=>end: 得到mpTracker op1=>operation: 读取配置文件，构造相机内参 mK,相机矫正向量 mDistCoef ,相机RGB参数 mbRGB op2=>operation: 读取配置文件，加载ORB参数 nFeatures、fScaleFactor、nLevels、fIniThFAST、fMinThFAST op3=>operation: 构造特征提取器 mpORBextractorLeft、mpIniORBextractor op4=>operation: 读取配置文件, 构造相机深度截断阈值和视差因子 mThDepth、mDepthMapFactor st->op1->op2->op3->op4->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析一]]></title>
    <url>%2F2019%2F05%2F28%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80%2F</url>
    <content type="text"><![CDATA[主函数说明 mono_kitty.cc1. main 入口函数，读取3个文件参数，初始化系统 strVocFile: 字典词包的路径 strSettingFile: 系统中装有一些如相机参数、view窗口的配置文件，格式为YAML strSequence: 数据集路径 2. LoadImages 函数 LoadImages(const string &amp;strPathToSequence, vector &amp;vstrImageFilenames, vector &amp;vTimestamps) 12345678910111213141516171819202122232425262728293031 void LoadImages(const string &amp;strPathToSequence, vector&lt;string&gt; &amp;vstrImageFilenames, vector&lt;double&gt; &amp;vTimestamps)&#123; ifstream fTimes; string strPathTimeFile = strPathToSequence + "/times.txt"; fTimes.open(strPathTimeFile.c_str()); while(!fTimes.eof()) &#123; string s; getline(fTimes,s); if(!s.empty()) &#123; stringstream ss; ss &lt;&lt; s; double t; ss &gt;&gt; t; vTimestamps.push_back(t); &#125; &#125; string strPrefixLeft = strPathToSequence + "/image_0/"; const int nTimes = vTimestamps.size(); vstrImageFilenames.resize(nTimes); for(int i=0; i&lt;nTimes; i++) &#123; stringstream ss; ss &lt;&lt; setfill('0') &lt;&lt; setw(6) &lt;&lt; i; vstrImageFilenames[i] = strPrefixLeft + ss.str() + ".png"; &#125;&#125; 加载数据集函数，函数执行完vstrImageFileNames是一个存有图片具体位置的vector，位置形式如xxx/xxx/000xxx.png，vTimestamps是存有图片时间戳的vector 3. 实例化 SLAM 系统加载图片路径完成后，需要实例化一个SLAM系统对象ORB_SLAM2::System SLAM(argv[1],argv[2],ORB_SLAM2::System::MONOCULAR,true); System.h 包含了7个类，分别是Viewer， FrameDrawer, Map, Tracking, LocalMapping, LoopClosing 的声明，和System 类的定义， 就像描述的那样，这些类组成了一个系统。 1234567class Viewer;class FrameDrawer;class Map;class Tracking;class LocalMapping;class LoopClosing;class System; 成员变量说明3.1 sensor 枚举12345enum eSensor&#123; MONOCULAR=0, STEREO=1, RGBD=2&#125;; 0,1,2 分别代表传感器的类型 3.2 System 构造函数System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eSensor sensor, const bool bUseViewer = true); Monocular System 构造时，读入词包路径，YAML配置文件，设置eSensor类型为Monocular，并启用Viewer线程 3.3 Tracking 函数123456789101112131415// Proccess the given stereo frame. Images must be synchronized and rectified.// Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.// Returns the camera pose (empty if tracking fails).cv::Mat TrackStereo(const cv::Mat &amp;imLeft, const cv::Mat &amp;imRight, const double &amp;timestamp);// Process the given rgbd frame. Depthmap must be registered to the RGB frame.// Input image: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.// Input depthmap: Float (CV_32F).// Returns the camera pose (empty if tracking fails).cv::Mat TrackRGBD(const cv::Mat &amp;im, const cv::Mat &amp;depthmap, const double &amp;timestamp);// Proccess the given monocular frame// Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.// Returns the camera pose (empty if tracking fails).cv::Mat TrackMonocular(const cv::Mat &amp;im, const double &amp;timestamp); 针对不同传感器不同的Tracking。输入图像可以使rgb的也可以是grayscale的（最终读进去都会转化为grayscale的），函数返回值为camera的位姿pose。Tracking 过程是对针对每一幅图像，通过先初始化然后track和优化过程来估计相机误差。 3.4 定位模式函数1234// This stops local mapping thread (map building) and performs only camera tracking.void ActivateLocalizationMode();// This resumes local mapping thread and performs SLAM again.void DeactivateLocalizationMode(); 调用ActivateLocalizationMode()将终止mapping线程，开启定位模式，调用后者重启mapping线程。 3.5 重启与终止函数1234567// Reset the system (clear map)void Reset();// All threads will be requested to finish.// It waits until all threads have finished.// This function must be called before saving the trajectory.void Shutdown(); Reset()函数将清空map，Shutdown()函数可以终止所有线程，在保存相机轨迹之前需要调用此函数。 3.6 SaveTrajectory 函数123456789101112131415161718192021// Save camera trajectory in the TUM RGB-D dataset format.// Only for stereo and RGB-D. This method does not work for monocular.// Call first Shutdown()// See format details at: http://vision.in.tum.de/data/datasets/rgbd-datasetvoid SaveTrajectoryTUM(const string &amp;filename);// Save keyframe poses in the TUM RGB-D dataset format.// This method works for all sensor input.// Call first Shutdown()// See format details at: http://vision.in.tum.de/data/datasets/rgbd-datasetvoid SaveKeyFrameTrajectoryTUM(const string &amp;filename);// Save camera trajectory in the KITTI dataset format.// Only for stereo and RGB-D. This method does not work for monocular.// Call first Shutdown()// See format details at: http://www.cvlibs.net/datasets/kitti/eval_odometry.phpvoid SaveTrajectoryKITTI(const string &amp;filename);// TODO: Save/Load functions// SaveMap(const string &amp;filename);// LoadMap(const string &amp;filename); 把相机轨迹保存成相应数据集的格式，系统调用此函数时先shutdown SLAM系统，mono_kittti中save函数用的是SaveKeyFrameTrajectoryTUM，这个函数看起来像是只能用于TUM数据集，但三种传感器均适合。 4 System private 成员变量说明4.1 eSensor12// Input sensoreSensor mSensor; 输入的传感器类型 4.2 mpVocabulary12// ORB vocabulary used for place recognition and feature matching.ORBVocabulary* mpVocabulary; 用于位置识别和特征匹配的系统词包 4.3 mpKeyFrameDatabase12// KeyFrame database for place recognition (relocalization and loop detection).KeyFrameDatabase* mpKeyFrameDatabase; 用于位置识别，重定位，回环检测的关键帧数据集 4.4 mpMap12// Map structure that stores the pointers to all KeyFrames and MapPoints.Map* mpMap; 存储系统关键帧的指针和地图点的指针 4.5 mpTracker1234// Tracker. It receives a frame and computes the associated camera pose.// It also decides when to insert a new keyframe, create some new MapPoints and// performs relocalization if tracking fails.Tracking* mpTracker; Tracker 接受一帧图像并计算相机位姿，决定什么时候需要插入关键帧，创建地图点并且执行重定位如果跟踪失败。 4.6 mpLocalMapper12// Local Mapper. It manages the local map and performs local bundle adjustment.LocalMapping* mpLocalMapper; 局部地图管理器，mpLocalMapper，管理局部地图并进行局部BA。 4.7 mpLoopCloser123// Loop Closer. It searches loops with every new keyframe. If there is a loop it performs// a pose graph optimization and full bundle adjustment (in a new thread) afterwards.LoopClosing* mpLoopCloser; 回环检测器，每次获取关键帧后都会进行回环检测，如果存在回环的话就执行位姿图的优化并且进行全局BA优化 4.8 mpViewer,mpFrameDrawer,mpMapDrawer12345// The viewer draws the map and the current camera pose. It uses Pangolin.Viewer* mpViewer;FrameDrawer* mpFrameDrawer;MapDrawer* mpMapDrawer; 视图显示 4.9 系统线程12345// System threads: Local Mapping, Loop Closing, Viewer.// The Tracking thread "lives" in the main execution thread that creates the System object.std::thread* mptLocalMapping;std::thread* mptLoopClosing;std::thread* mptViewer; 4.10 Reset flag123// Reset flagstd::mutex mMutexReset;bool mbReset; 4.11 Change mode flags1234// Change mode flagsstd::mutex mMutexMode;bool mbActivateLocalizationMode;bool mbDeactivateLocalizationMode; 5. 实例化SLAM-System构造函数123System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eSensor sensor, const bool bUseViewer):mSensor(sensor),mbReset(false),mbActivateLocalizationMode(false), mbDeactivateLocalizationMode(false) System 构造函数用于实例化一个SALM系统，开启相机跟踪(Tracking)，局部建图(Local Mapping)，回环检测(Loop Closing)，和可视化界面(Viewer)的线程。 5.1 初始形参传递1234mSensor(sensor),mbReset(false),mbActivateLocalizationMode(false),mbDeactivateLocalizationMode(false) sensor是传进来的形参，是前面枚举体中三种传感器的一个，这里为MONOCULAR，它传递给了mSensor，这是一个System类的隐含成员变量，两种变量类型一样。mpViewer是System类的隐含成员变量，Viewer类指针，这里赋空。mbReset，mbActivateLocalizationMode，mbDeactivateLocalizationMode均为bool型，赋false。 5.2 初始化数据库 1 初始化词包 mpVocabulary 123456789101112131415161718//Load ORB Vocabulary cout &lt;&lt; endl &lt;&lt; "Loading ORB Vocabulary. This could take a while..." &lt;&lt; endl; mpVocabulary = new ORBVocabulary(); bool bVocLoad = false; // chose loading method based on file extension if (has_suffix(strVocFile, ".txt")) bVocLoad = mpVocabulary-&gt;loadFromTextFile(strVocFile); else if(has_suffix(strVocFile, ".bin")) bVocLoad = mpVocabulary-&gt;loadFromBinaryFile(strVocFile); else bVocLoad = false; if(!bVocLoad) &#123; cerr &lt;&lt; "Wrong path to vocabulary. " &lt;&lt; endl; cerr &lt;&lt; "Failed to open at: " &lt;&lt; strVocFile &lt;&lt; endl; exit(-1); &#125; cout &lt;&lt; "Vocabulary loaded!" &lt;&lt; endl &lt;&lt; endl; 2 用词包数据库来初始化关键帧数据库（用于重定位和回环检测）mpKeyFrameDatabase 12//Create KeyFrame Database mpKeyFrameDatabase = new KeyFrameDatabase(*mpVocabulary); 3 初始化一个Map类对象 ，该类用于存储指向所有关键帧和地图点的指针 mpMap 12//Create the Map mpMap = new Map(); 4 初始化画图工具，用于可视化 mpFrameDrawer、mpMapDrawer 123//Create Drawers. These are used by the Viewer mpFrameDrawer = new FrameDrawer(mpMap); mpMapDrawer = new MapDrawer(mpMap, strSettingsFile); 5 初始化Tracking线程，主线程，使用this指针（只初始化不启动，启动在main函数里TrackMonocular()启动） 1234//Initialize the Tracking thread//(it will live in the main thread of execution, the one that called this constructor) mpTracker = new Tracking(this, mpVocabulary, mpFrameDrawer, mpMapDrawer, mpMap, mpKeyFrameDatabase, strSettingsFile, mSensor); 6 初始化Local Mapping线程并启动（这里mSensor传入MONOCULAR）mpLocalMapper 123//Initialize the Local Mapping thread and launch mpLocalMapper = new LocalMapping(mpMap, mSensor==MONOCULAR); mptLocalMapping = new thread(&amp;ORB_SLAM2::LocalMapping::Run,mpLocalMapper); 7 初始化Loop Closing线程并启动（这里mSensor传入的不是MONOCULAR）mptLoopClosing 123//Initialize the Loop Closing thread and launchmpLoopCloser = new LoopClosing(mpMap, mpKeyFrameDatabase, mpVocabulary, mSensor!=MONOCULAR);mptLoopClosing = new thread(&amp;ORB_SLAM2::LoopClosing::Run, mpLoopCloser); 8 初始化Viewer线程并启动，也使用了this指针；给Tracking线程设置Viewer 123456//Initialize the Viewer thread and launch mpViewer = new Viewer(this, mpFrameDrawer,mpMapDrawer,mpTracker,strSettingsFile); if(bUseViewer) mptViewer = new thread(&amp;Viewer::Run, mpViewer); mpTracker-&gt;SetViewer(mpViewer); 9 mpTracker，mpLocalMapper，mptLoopClosing三个线程每两个线程之间设置指针相互关联 123456789//Set pointers between threads mpTracker-&gt;SetLocalMapper(mpLocalMapper); mpTracker-&gt;SetLoopClosing(mpLoopCloser); mpLocalMapper-&gt;SetTracker(mpTracker); mpLocalMapper-&gt;SetLoopCloser(mpLoopCloser); mpLoopCloser-&gt;SetTracker(mpTracker); mpLoopCloser-&gt;SetLocalMapper(mpLocalMapper); 6. 循环Tracking12345678910111213141516171819202122232425262728293031323334353637383940414243444546 // Main loop cv::Mat im; for(int ni=0; ni&lt;nImages; ni++) &#123; // Read image from file im = cv::imread(vstrImageFilenames[ni],CV_LOAD_IMAGE_UNCHANGED); double tframe = vTimestamps[ni]; if(im.empty()) &#123; cerr &lt;&lt; endl &lt;&lt; "Failed to load image at: " &lt;&lt; vstrImageFilenames[ni] &lt;&lt; endl; return 1; &#125;#ifdef COMPILEDWITHC11 std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::now();#else std::chrono::monotonic_clock::time_point t1 = std::chrono::monotonic_clock::now();#endif // Pass the image to the SLAM system SLAM.TrackMonocular(im,tframe);#ifdef COMPILEDWITHC11 std::chrono::steady_clock::time_point t2 = std::chrono::steady_clock::now();#else std::chrono::monotonic_clock::time_point t2 = std::chrono::monotonic_clock::now();#endif double ttrack= std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt; &gt;(t2 - t1).count(); vTimesTrack[ni]=ttrack; // Wait to load the next frame double T=0; if(ni&lt;nImages-1) T = vTimestamps[ni+1]-tframe; else if(ni&gt;0) T = tframe-vTimestamps[ni-1]; if(ttrack&lt;T) this_thread::sleep_for(std::chrono::microseconds((int)((T-ttrack)*1e6))); &#125; // Stop all threads SLAM.Shutdown(); 上述分为两步：读图、Tracking，其中有一部分代码（注释 //Wait to load the next frame 后）目的是为了模拟真实时间状况，如果tracking过快，则下一帧可能还没来，所以要“睡” T-ttrack 秒等待装载下一帧图片。每次tracking只处理一帧图片。]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git简单攻略]]></title>
    <url>%2F2019%2F05%2F24%2Fgit%E7%AE%80%E5%8D%95%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[git全局用户申明12git config --global user.name "Your Name"git config --global user.email "email@example.com" 创建管理库1git init 添加文件1git add reamde.md 提交文件到仓库1git commit -m "message" 为什么git提交文件需要add和commit两步呢，因为commit可以一次提交很多次add不同的文件，比如123git add file1.txtgit add file2.txt file3.txtgit commit -m "add 3files" 查看仓库状态1git status 查看文件修改内容1git diff readme.txt 查看提交历史1git log 以便确定回退到哪个版本。 查看命令历史1git reflog 以便确定回到未来的哪个版本。 版本指针HEAD指向的版本就是当前的版本，HEAD^指向前一个版本，HEAD^^指向前前版本，HEAD~100指向第前100个版本。因此，git允许我们在历史之间穿梭。 版本穿梭1git reset --hard commit_id 丢弃工作区的修改1git checkout -- file 命令git checkout -- readme.txt意思就是，把readme.txt文件在工作区的修改全部撤销，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次git commit或git add时的状态。 从暂存区回到工作区1git reset HEAD readme.txt 如果你把文件git add到暂存区，但是还没有git commit到仓库，可以使用git reset HEAD file 将暂存区的修改撤销掉，重新放回到工作区。git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。 小结场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout — file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。 删除文件12git rm test.txtgit commit -m "remove test.txt" 一般情况下，你通常直接在文件管理器中把没用的文件删了，或者用rm命令删了：rm test.txt。这个时候，Git知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了。 现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit，现在，文件就从版本库中被删除了。 另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本：1git checkout -- test.txt 小提示：先手动删除文件，然后使用git rm 和git add效果是一样的。注意：从来没有被添加到版本库就被删除的文件，是无法恢复的！ 添加远程仓库1git remote add origin git@github.com:hahaha/hahaha.git 把本地库的所有内容推送到远程库上1git push -u origin master 把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 提交仓库到到远程1git push origin master 从远程库克隆1git clone git@github.com:hahaha/gitskills.git 现在，假设我们从零开发，那么最好的方式是先创建远程库，然后，从远程库克隆。首先，登陆GitHub，创建一个新的仓库，名字叫gitskills：我们勾选Initialize this repository with a README，这样GitHub会自动为我们创建一个README.md文件。创建完毕后，可以看到README.md文件：现在，远程库已经准备好了，下一步是用命令git clone克隆一个本地库： 注意把Git库的地址换成你自己的，然后进入gitskills目录看看，已经有README.md文件了： 转载申明本文转载自廖雪峰的博客：[https://www.liaoxuefeng.com]]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EKF详解]]></title>
    <url>%2F2019%2F05%2F23%2FEKF%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. 高斯函数\begin{equation}p(x) = \det(2\pi\Sigma)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \}}\label{eq:Gaussion}\end{equation} 所有的高斯技术都共享了基本思想，即置信度用多元正态分布来表示。$x$的密度用两个参数来表示，均值$\mu$和协方差$\Sigma$，均值$\mu$是一个向量，它与状态$x$的维数相同。协方差是对称半正定的二次型。其维数等于状态$x$的维数的二次方。高斯滤波中的参数均值和方差称为矩参数，这是因为均值和方差是概率分布的一阶矩和二阶矩；正态分布的其他矩都是零。 2. 线性高斯系统KF是由Swerling（1950）和Kalman（1960）作为线性高斯系统中的预测和滤波技术而发明的，是用矩来定义的。KF用矩参数来表示置信度：在时刻$t$，置信度用均值$\mu_t$和方差$\Sigma_t$表示、如果除了贝叶斯滤波的马尔科夫假设以外，还具有如下的三个特性，则后验就是高斯的。 状态转移概率$p(x_t | u_t, x_{t-1})$必须是带有随机高斯噪声的参数的线性函数，可有下式表示:\begin{equation}x_t = A_tx_{t-1} + B_tu_t + \varepsilon_t\label{eq:motion}\end{equation}式中，$x_t$和$x_{t-1}$都是状态向量，它们都是$n$维列向量；$u_t$为时刻$t$的控制向量。式(2)中，$A_t$为$n \times n$的矩阵，$B_t$为$n \times m$的矩阵，$n$为状态向量$x_t$的维数，$m$为控制向量$u_t$的维数。式(2)中的随机变量\varepsilon_t是一个高斯随机向量，表示由状态转移引入的不确定性。其维数与状态向量维数相同，均值为0，方差用$R_t$表示。式(2)中的状态转移概率称为线性高斯，反映了它与带有附加高斯噪声的自变量呈线性关系。式(2)定义了状态转移概率$p(x_t | u_t, x_{t-1})$。这个概率可由公式(2)带入到多元正态分布的定义式(1)来得到。后验状态的均值由$A_tx_{t-1} + B_tu_t$给定，方差由$R_t$给定：\begin{equation}p(x_t | u_t, x_{t-1}) = \det(2\pi R_t)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(x_t-A_tx_{t-1} - B_tu_t)^TR_t^{-1}(x_t-A_tx_{t-1} - B_tu_t) \}}\label{eq:status}\end{equation} 观测概率$p(z_t | x_t)$也与带有高斯噪声的自变量呈线性关系：\begin{equation}z_t = C_tx_t + \delta _t\label{eq:project}\end{equation}式中，$C_t$为$k \times n$的矩阵，$k$为观测向量$z_t$的维数；向量$\delta _t$为观测噪声。$\delta _t$服从均值为0、方差为$Q_t$的多变量高斯分布。因此观测概率由下面的多元正态分布给定：\begin{equation}p(z_t | x_t) = \det(2\pi Q_t)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(z_t - C_tx_t)^TQ_t^{-1}(z_t-C_tx_t) \}}\label{eq:measure}\end{equation} 最后，初始置信度必须${\rm bel}(x_0)$必须是正态分布的。这里用$\mu_0$表示初始置信度的均值，用$\Sigma_0$表示协方差：\begin{equation}{\rm bel}(x_0) = p (x_0)= \det(2\pi \Sigma_0)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(x_0 - \mu_0)^T\Sigma_0^{-1}(x_0-\mu_0) \}}\label{eq:initial}\end{equation} 这三个假设足以保证后验${\rm bel}(x_t)$在任何时刻$t$总符合高斯分布。 3. KF算法(Kalman fliter algorithm)KF算法如图所示，KF表示均值为$\mu_t$、方差为$\Sigma_t$的状态量在时刻$t$的置信度{\rm bel}(x_t)。KF的输入是$t-1$时刻的置信度，其均值和方差分别用$\mu_{t-1}$和$\Sigma_{t-1}$表示。为了更新这些参数，KF需要控制向量$u_t$和测量向量$z_t$。输出的是时刻$t$的置信度，均值为$\mu_t$，方差为$\Sigma_t$。 Algorithm Kalman_filter($\mu_{t-1}$,$\Sigma_{t-1}$,$u_t$,$z_t$): 3.3 线性高斯系统]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>EKF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
