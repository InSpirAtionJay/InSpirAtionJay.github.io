<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[最小二乘问题]]></title>
    <url>%2F2019%2F05%2F30%2F%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 非齐次线性最小二乘问题考虑线性系统： \begin{array}{c} Ax = b & \text(A \in R^{ m \times n }(m > n),b \in R^m,x \in R^n) \end{array}的最小二乘解。即求 $ x \in R^n $使得 \begin{Vmatrix} Ax-b \end{Vmatrix} _2 = \min \{ \begin{Vmatrix} Av-b \end{Vmatrix} _2:v \in R^n\}记 X_{LS}=\{ x\in R^n:x是 (1) 的解\}则称$X_{LS}$是最小二乘问题的解集；$X_{LS}$中范数最小者称为最小范数解，并记作$x_{LS}$，即 \begin{Vmatrix} x_{LS} \end{Vmatrix} _2 = \min \{ \begin{Vmatrix} x \end{Vmatrix} _2 : x \in X_{LS}\}命题 1 $x\in X_{LS} \iff A^T(Ax-b)=0$证明 $\forall x,y \in R^n,$有 \begin{Vmatrix} b-A(x+y) \end{Vmatrix} _2^2 = \begin{Vmatrix} b-Ax \end{Vmatrix} _2^2 - 2y^TA^T(b-Ax)+ \begin{Vmatrix} Ay \end{Vmatrix} _2^2因此， x \in X_{LS} \iff \forall y \in R^n,\begin{Vmatrix} Ay \end{Vmatrix} _2^2 - 2y^TA^T(b-Ax)\geq 0 \iff A^T(b-Ax)=0方程$A^T(b-Ax)=0$称为$Ax-b=0$的正规方程。推论 1 $X_{LS}$是凸集； $x_{LS}$是唯一的； $X_{LS} = \{ x_{LS}的充分必要条件是rank(A)=n \}$。 Moore-Pseudo 广义逆为了给出最小二乘的一般表示，需要矩阵的广义逆的概念。 定义 1 $Ａ\in R_{m \times n} $，若$X\in R_{n\times m}$满足 \begin{array}{c} AXA = A ,& XAX=X ,& (AX)^T=AX ,& (XA)^T=XA \end{array}则称$X$是$A$的广义逆，并记作$A^+$。矩阵$A$的广义逆是唯一的，并且可以利用$A$的 SVD 分解进行计算。令$A$的 SVD 分解为 A=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T不难验证： A^+=V\begin{pmatrix}\Sigma_r^{-1} & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}U^T命题 2 最小二乘问题的一般解为 x=A^+b+(I-A^+A)z,z\in R^n最小范数解是 x_{LS}=A^+b证明 由命题1，最小二乘问题(1)的解可以由它的正规方程: A^TAx=A^Tb给出。利用广义逆，可以验证x=A^+b是上式的一个解。另外，由 SVD 分解可证明$N(A^TA)=N(A)$，且 N(A) = \{(I-A^+A)z:z\in R^n\}此外，注意到 [(I-A^+A)z]^TA^+b=z^T(I-A^+A)A^+b=0所以， \begin{Vmatrix} x \end{Vmatrix} _2^2 = \begin{Vmatrix} A^+b \end{Vmatrix} _2^2 + \begin{Vmatrix} (I-A^+A)z \end{Vmatrix} _2^2 \geq \begin{Vmatrix} A^+b \end{Vmatrix} _2^2即：$x_{LS}=A^+b$ 满秩最小二乘问题如果(1)中的矩阵$A$是列满秩的，即$rank(A)=n$，则称它为满秩最小二乘问题。可以通过正规分解法，QR 分解法来求解该最小二乘问题，但最好的方法还是 SVD 分解法。 SVD分解方法由于$rank(A)=n$，所以$A$必有下述形式的 SVD 分解$A=U\begin{pmatrix}\Sigma_n \ 0\end{pmatrix}V^T$，于是，$A^+=V\begin{pmatrix}\Sigma_n^{-1},0 \end{pmatrix}U^T$。所以，问题的解为 x=A^+b=V\begin{pmatrix}\Sigma_n^{-1},0 \end{pmatrix}U^Tb=\frac{u_1^Tb}{\sigma_1}v_1+\frac{u_2^Tb}{\sigma_2}v_2+\cdots+\frac{u_n^Tb}{\sigma_n}v_n = \sum_{j=1}^{n}\frac{u_j^Tb}{\sigma_j}v_j亏秩最小二乘问题此时不可以利用其他方法来求解最小二乘问题，SVD 方法是首选。具体来说，若$rank(A)=r$，则$A$有 SVD 分解: A=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T因此， x=A^+b=V\begin{pmatrix}\Sigma_r^{-1} & \boldsymbol 0 \\ \boldsymbol 0 & 0\end{pmatrix}U^Tb = \sum_{j=1}^{r}\frac{u_j^Tb}{\sigma_j}v_j数值秩的定义和确定方法略 以后再补 2. 齐次最小二乘问题考虑齐次线性方程： \begin{array}{c} Ax = 0 & \text(A \in R^{ m \times n }(m > n),b \in R^m,x \in R^n) \end{array}对应的最小二乘问题是 \begin{Vmatrix} Ax \end{Vmatrix} _2 = \min \{ \begin{Vmatrix} Av \end{Vmatrix} _2:v \in R^n\}显然，$x=0$总是上述最小二乘问题的最小范数解。在实际中，人们通常关心的是它的非零解，而不是零解。因此，总是考虑相应的约束最小二乘问题: \begin{Vmatrix} Ax \end{Vmatrix}_2 = \min \{ \begin{Vmatrix} Av \end{Vmatrix}_2:v\in R^n,\begin{Vmatrix} v \end{Vmatrix}_2 = 1\}或者等价的写成 \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix}_2\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1 \end{array} \right.命题 3 若$rank(A)=r$，则该齐次线性方程的解为 x=\sum_{j=1}^{n-r}s_jv_{r+j},(\sum_{j=1}^{n-r}s_j^2=1)其中，$v_{r+1},v_{r+2},\cdots,v_n$是$A^TA$的零特征值的$n-r$个线性无关的单位特征向量。 证明 问题等价于: \left\{ \begin{array}{l} \min x^TA^TAx\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1 \end{array} \right.因$rank(A^TA)=rank(A)=r$，所以$A^TA$有特征值分解 A^TA=Vdiag(\lambda_1,\lambda_2,\cdots,\lambda_r,0,\cdots,0)V^T其中，$V$是正交矩阵，所以$v_{r+1},v_{r+2},\cdots,v_n$是$A^TAx=0$的$n-r$个相互正交的单位解，因此，上述问题的解为 x=\sum_{j=1}^{n-r}s_jv_{r+j},(\sum_{j=1}^{n-r}s_j^2=1)命题 4 若$rank(A)=r$，则该齐次线性方程的解为 x=\sum_{j=1}^{n-r}s_jv_{r+j},(\sum_{j=1}^{n-r}s_j^2=1)其中，$v_{r+1},v_{r+2},\cdots,v_n$是$A$的$n-r$个零奇异值的右奇异向量。 3. 约束齐次最小二乘问题零约束考虑约束最小二乘问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix} _2^2\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1,Cx=0 \end{array} \right.不妨假设$rank(C)=r &lt; n$，对$C$作 SVD 分解 C=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T令$V_{n-r}=(v_{r+1},v_{r+2},\cdots,v_{n})$为$V$的最后$n-r$个列向量所构成的矩阵，因为$Cx=0$的所有解可以表示为: x=V_{n-r}y,y \in R^{n-r}并且$\begin{Vmatrix} Ax\end{Vmatrix} _2^2=1 \iff \begin{Vmatrix} y\end{Vmatrix} _2^2=1$，这是因为$V_{n-r}$是列正交的。于是，上述问题可以转化为下述最小化问题 \left\{ \begin{array}{l} \min \begin{Vmatrix} AV_{n-r}y \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} y \end{Vmatrix}_2=1 \end{array} \right.这个问题在上一节已经解决。 值约束考虑约束最小二乘问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix} _2^2\\[2ex] subject to\begin{Vmatrix} x \end{Vmatrix}_2=1,x=Cy \end{array} \right.不妨假设$rank(C)=r &lt; n$，对$C$作 SVD 分解 C=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T由 SVD 分解特性可知，矩阵$C$的值空间可以表示为 x = R(C)=\{U_rx'|x'\in R^r\}其中，$U_r$为$U$的前$r$列所构成的矩阵。于是$x=Cy$可以表示为$x=U_rx’$且有$\begin{Vmatrix}x\end{Vmatrix} _2^2=1 \iff \begin{Vmatrix} x’\end{Vmatrix} _2^2=1$，这是因为$U_r$是列正交的。于是，上述问题可以转化为下述最小化问题 \left\{ \begin{array}{l} \min \begin{Vmatrix} AU_rx' \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} x' \end{Vmatrix}_2=1 \end{array} \right.这个问题在上一节已经解决。 模约束考虑约束最小二乘问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} Ax \end{Vmatrix} _2^2\\[2ex] subject to\begin{Vmatrix} Cx \end{Vmatrix}_2=1 \end{array} \right.不妨假设$rank(C)=r &lt; n$，对$C$作 SVD 分解 C=U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}V^T令$x’=V^Tx$，则有 Cx = U\begin{pmatrix}\Sigma_r & \boldsymbol 0 \\ \boldsymbol 0 & 0 \end{pmatrix}x'且$\begin{Vmatrix} Ax \end{Vmatrix} _2=1 \iff \begin{Vmatrix}\Sigma_r &amp; \boldsymbol 0 \ \boldsymbol 0 &amp; 0\end{Vmatrix}x’=1 \iff \begin{Vmatrix} \Sigma_rx’\end{Vmatrix} _2=1 $，其中， x'= \begin{pmatrix} x'_r \\ x'_{n-r}\end{pmatrix}所以， Ax=AVx'=A'x'= \begin{pmatrix} A'_r & A'_{n-r}\end{pmatrix}\begin{pmatrix} x'_r \\ x'_{n-r}\end{pmatrix}=A'_rx'_r+A'_{n-r}x'_{n-r}取$y=\Sigma_rx’_r$，则$x’_r=\Sigma_r^{-1}y$，于是，上述问题可以转化为下述最小化问题 \left\{ \begin{array}{l} \min \begin{Vmatrix} A'_r\Sigma_r^{-1}y+A'_{n-r}x'_{n-r} \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} y \end{Vmatrix}_2=1 \end{array} \right.由于$\min_{x’_{n-r}} \begin{Vmatrix} A’_r\Sigma_r^{-1}y+A’_{n-r}x’_{n-r} \end{Vmatrix}_2^2$的最小化问题的解为$x’_{n-r} = -{A’}_{n-r}^+A’_r\Sigma_r^{-1}y$于是该求解问题转化为如下最小化问题: \left\{ \begin{array}{l} \min \begin{Vmatrix} (A'_r-A'_{n-r}{A'}_{n-r}^+A'_r)\Sigma_r^{-1}y \end{Vmatrix}_2^2\\[2ex] subject to\begin{Vmatrix} y \end{Vmatrix}_2=1 \end{array} \right.这个问题在上一节已经解决。注意，$A^+A$不等于$I$，除非A满秩。]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>最小二乘问题</tag>
        <tag>Math</tag>
        <tag>SVD分解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PnP算法]]></title>
    <url>%2F2019%2F05%2F30%2FPnP%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[PnP算法求解相机位姿PnP(Perspective-n-Point) 是求解3D到2D点对运动的方法。它描述了当我们知道n个3D空间点以及它们的投影位置时,如何估计相机所在的位姿。 1. 直接线性变换(DLT)考虑某个空间点$P$,它的齐次坐标为$P=(X, Y, Z, 1)^T$。在图像$I_1$中,投影到特征点$x_1=(u_1,v_1,1)^T$(以归一化平面齐次坐标表示)。此时相机的位姿$R,t$是未知的。与单应矩阵的求解类似,我们定义增广矩阵$[R|t]$为一个$3\times4$的矩阵,包含了旋转与平移信息。我们把它的展开形式列写如下: s\begin{pmatrix} u_1 \\ v_1 \\ 1 \\ \end{pmatrix} = \begin{pmatrix} t_1 & t_2 & t_3 & t_4 \\ t_5 & t_6 & t_7 & t_8 \\ t_9 & t_{10} & t_{11} & t_{12} \\ \end{pmatrix} \begin{pmatrix} X \\ Y \\ Z \\ \end{pmatrix}用最后一行把$s$消去,得到两个约束:\begin{align*}u_1 &amp;= \frac{t_1X+t_2Y+t_3Z+t_4}{t_9X+t_{10}Y+t_{11}Z+t_{12}}\\v_1 &amp;= \frac{t_5X+t_6Y+t_7Z+t_8}{t_9X+t_{10}Y+t_{11}Z+t_{12}}\end{align*} 为了简化表示,定义$T$的行向量: \begin{array}{c} t_1 = (t_1, t_2, t_3, t_4)^T,& t_2 = (t_5, t_6, t_7, t_8)^T,& t_3 = (t_9, t_{10}, t_{11}, t_{12})^T \end{array}于是有: \left\{ \begin{array}{c} t_1^TP-t_3^TPu_1=0 \\ t_2^TP-t_3^TPv_1=0 \end{array} \right.请注意$t$是待求的变量,可以看到每个特征点提供了两个关于$t$的线性约束。假设一共有$N$个特征点,可以列出线性方程组: \begin{pmatrix} P_1^T & 0 & -u_1P_1^T \\ 0 & P_1^T & -v_1P_1^T \\ \vdots & \vdots & \vdots \\ P_N^T & 0 & -u_NP_N^T \\ 0 & P_N^T & -v_NP_N^T \end{pmatrix}由于 $t$ 一共有12维，考虑到齐次性，共有11个自由度，而每一对特征点对都提供了两个约束方程。因此最少通过6对匹配点，即可实现矩阵$T$的线性求解，这种方法(也)称为直接线性变换(Direct Linear Transform，DLT)。当匹配点大于6对时，(又)可以使用 SVD 等方法对超定方程求最小二乘解。在 DLT 求解中，我们直接将$T$矩阵看成了12个未知数，忽略了它们之间的联系。因为旋转矩阵$R∈SO(3)$，用 DLT 求出的解不一定满足该约束，它是一个一般矩阵。平移向量比较好办，它属于向量空间。对于旋转矩阵$R$，我们必须针对 DLT 估计的$T$的左边$3\times3$的矩阵块，寻找一个最好的旋转矩阵对它进行近似。这可以由QR分解完成，相当于把结果从矩阵空间重新投影到$SE(3)$流形上，转换成旋转和平移两部分。需要解释的是,我们这里的$x_1$使用了归一化平面坐标，去掉了内参矩阵$K$的影响——这是因为内参$K$在SLAM中通常假设为已知。如果内参未知,那么我们也能用 PnP 去估计$K,R,t$三个量。然而由于未知量的增多，效果会差一些。]]></content>
      <categories>
        <category>SFM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>SFM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析三]]></title>
    <url>%2F2019%2F05%2F29%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%89%2F</url>
    <content type="text"><![CDATA[ORBextractor特征提取器1. ORBextractor 成员变量1.1 SCORE 得分常量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 描述子的筛选模式1std::vector&lt;cv::Point&gt; pattern; 用来快速建立256维的描述子 1.3 ORBextractor 特征提取器的控制变量12345int nfeatures; // 需要提取的特征点数目double scaleFactor; // ORB 金字塔相邻两层之间的尺度因子int nlevels; // 金字塔的层数int iniThFAST; // FAST角点提取的初始阈值int minThFAST; // FAST角点用初始阈值提取失败后放松阈值再次提取 1.4 每层金字塔对应的特征点数目Vector mnFeaturesPerLevel1std::vector&lt;int&gt; mnFeaturesPerLevel; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.5 每层金字塔对应的尺度因子Vector mvScaleFactor1std::vector&lt;float&gt; mvScaleFactor; 1.6 每层金字塔对应的尺度因子的倒数Vector mvInvScaleFactor1std::vector&lt;float&gt; mvInvScaleFactor; 1.7 每层金字塔对应的Sigma的平方Vector mvLevelSigma21std::vector&lt;float&gt; mvLevelSigma2; 1.8 每层金字塔对应的Sigma的平方的倒数Vector mvLevelSigma21std::vector&lt;float&gt; mvInvLevelSigma2; 1.9 每层金字塔对应图像Mat mvImagePyramid1std::vector&lt;cv::Mat&gt; mvImagePyramid; 2. ORBextractor 成员函数2.1 ORBextractor 构造函数12ORBextractor(int nfeatures, float scaleFactor, int nlevels, int iniThFAST, int minThFAST); 第一步：算金字塔每层的尺度，然后根据尺度计算每层应该提取多少特征点，这里面涉及了一个等比数列，唤起高中的记忆，还挺有意思的。最后，保证提取总特征点数≥ nfeatures。1234567891011121314151617mvScaleFactor.resize(nlevels);mvLevelSigma2.resize(nlevels);mvScaleFactor[0]=1.0f;mvLevelSigma2[0]=1.0f;for(int i=1; i&lt;nlevels; i++)&#123; mvScaleFactor[i]=mvScaleFactor[i-1]*scaleFactor; mvLevelSigma2[i]=mvScaleFactor[i]*mvScaleFactor[i];&#125;mvInvScaleFactor.resize(nlevels);mvInvLevelSigma2.resize(nlevels);for(int i=0; i&lt;nlevels; i++)&#123; mvInvScaleFactor[i]=1.0f/mvScaleFactor[i]; mvInvLevelSigma2[i]=1.0f/mvLevelSigma2[i];&#125; nfeatures: 1000nleves: 8scaleFactor: 1.2iniThFAST: 20minThFAST: 8 mvScaleFactor: 1.0, 1.2, 1.2^2, 1.2^3, 1.2^4, 1.2^5, 1.2^6, 1.2^7mvLevelSigma2: mvScaleFactor[i]*mvScaleFactor[i];mvInvScaleFactor[i]=1.0f/mvScaleFactor[i];mvInvLevelSigma2[i]=1.0f/mvLevelSigma2[i];12float factor = 1.0f / scaleFactor;float nDesiredFeaturesPerScale = nfeatures*(1 - factor)/(1 - (float)pow((double)factor, (double)nlevels)); 通过等比数列求和来计算初始第0层nDesiredFeaturesPerScale的特征点数 {\rm nfeatures} = \frac{ {\rm nDesiredFeaturesPerScale}\times(1-{\rm factor}^{\rm nlevels})}{1-{\rm factor}}{\rm nDesiredFeaturesPerScale} = \frac{ {\rm nfeatures}\times(1-{\rm factor})}{1-{\rm factor}^{\rm nlevels}}1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点 1.2 ORBextractor 成员变量1enum &#123;HARRIS_SCORE=0, FAST_SCORE=1 &#125;; 定义常量，HARRIS_SCORE=0, FAST_SCORE=1，特征点提取后通过得分进行筛选得到最佳的特征点]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown flowchart.js画流程图]]></title>
    <url>%2F2019%2F05%2F28%2FMarkdown-flowchart.js%E7%94%BB%E6%B5%81%E7%A8%8B%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[Markdown笔记：如何画流程图 Flowchart.js 仅需几行代码即可在 Web 上完成流程图的构建。可以从文字表述中画出简单的 SVG 流程图，也可以画出彩色的图表。 1. 先来看一段入门案例流程图代码在 Markdown 编辑中应该是下面这样的(由于渲染的问题，请把,,,改成三个点号)1234567891011,,,flowst=&gt;start: Starte=&gt;end: Endop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yes or No?io=&gt;inputoutput: catch something...st-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op1,,, 输出结果如图所示: 在markdown语法中，流程图的画法和代码段类似，也就是说，流程图是写在两个,,,之间的。比如说php代码，会是这样一种格式: ,,,php代码段,,, 那么流程图就是这样的: ,,,flow代码段,,,` 2. 语法流程图的语法大体分为两部分: 前面部分用来定义流程图元素； 后面部分用来连接流程图元素，指定流程图的执行走向。 2.1 定义元素阶段的语法1tag=&gt;type: content:&gt;url 上例中下面部分代码都是定义元素部分123456st=&gt;start: Starte=&gt;end: Endop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yes or No?io=&gt;inputoutput: catch something... 说明： tag 是流程图中的标签，在第二段连接元素时会用到。名称可以任意，一般为流程的英文缩写和数字的组合。 type 用来确定标签的类型，=&gt;后面表示类型。由于标签的名称可以任意指定，所以要依赖type来确定标签的类型。 标签有6种类型：start end operation subroutine condition inputoutput。 content 是流程图文本框中的描述内容，: 后面表示内容，中英文均可。特别注意，冒号与文本之间一定要有个空格。 url是一个连接，与框框中的文本相绑定，:&gt;后面就是对应的 url 链接，点击文本时可以通过链接跳转到 url 指定页面。 开始1st=&gt;start: 开始 操作1op1=&gt;operation: 操作、执行说明 条件1cond=&gt;condition: 确认？ 结束1e=&gt;end: 结束 URL（貌似 SF 的编辑器不支持）1e=&gt;点击本结束跳转:&gt;http://https://segmentfault.com/blog/ingood 2.2 连接流程图元素的语法示例代码后面部分 st-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op1 连接流程图元素阶段的语法就简单多了，直接用-&gt;来连接两个元素，几点说明如下：说明： 使用 -&gt; 来连接两个元素 对于condition类型，有yes和no两个分支，如示例中的cond(yes)和cond(no) 每个元素可以制定分支走向，默认向下，也可以用right指向右边，如示例中sub1(right)。 转载声明：本文转载自:https://segmentfault.com/a/1190000006247465?utm_source=tag-newest]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析二]]></title>
    <url>%2F2019%2F05%2F28%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Tracking 线程分析1. Tracking流程图 2. Tracking 成员变量说明2.1 Tracking 状态枚举123456789enum eTrackingState&#123; SYSTEM_NOT_READY=-1, NO_IMAGES_YET=0, NOT_INITIALIZED=1, OK=2, LOST=3 &#125;;eTrackingState mState;eTrackingState mLastProcessedState; 2.2 Tracking 状态枚举 mSensor12// Input sensor:MONOCULAR, STEREO, RGBD int mSensor; mSeneor 传感器类型 2.3 当前帧和当前帧灰度图 mCurrentFrame,mImGray123// Current Frame Frame mCurrentFrame; cv::Mat mImGray; mSeneor 传感器类型 2.4 初始化的时候两帧图像之间的相关变量1234567// Initialization Variables (Monocular)// 初始化时前两帧相关变量std::vector&lt;int&gt; mvIniLastMatches;std::vector&lt;int&gt; mvIniMatches;// 跟踪初始化时前两帧之间的匹配std::vector&lt;cv::Point2f&gt; mvbPrevMatched;std::vector&lt;cv::Point3f&gt; mvIniP3D;Frame mInitialFrame; mSeneor 传感器类型 2.5 Tracking 结果关键帧列表和相对关键帧的位姿列表123456// Lists used to recover the full camera trajectory at the end of the execution.// Basically we store the reference keyframe for each frame and its relative transformationlist&lt;cv::Mat&gt; mlRelativeFramePoses;list&lt;KeyFrame*&gt; mlpReferences;list&lt;double&gt; mlFrameTimes;list&lt;bool&gt; mlbLost; mSeneor 传感器类型 2.6 是否开启地图变量 mbOnlyTracking12// True if local mapping is deactivated and we are performing only localizationbool mbOnlyTracking; mSeneor 传感器类型 2.7 只定位时0地图点是否VO变量12345// In case of performing only localization, this flag is true when there are no matches to// points in the map. Still tracking will continue if there are enough matches with temporal points.// In that case we are doing visual odometry. The system will try to do relocalization to recover// "zero-drift" localization to the map.bool mbVO; mSeneor 传感器类型 2.8 另外两个线程的指针 mpLocalMapper，mpLoopClosing123//Other Thread PointersLocalMapping* mpLocalMapper;LoopClosing* mpLoopClosing; mSeneor 传感器类型 2.9 ORB特征提取器1234567//ORB// orb特征提取器，不管单目还是双目，mpORBextractorLeft都要用到// 如果是双目，则要用到mpORBextractorRight// 如果是单目，在初始化的时候使用mpIniORBextractor而不是mpORBextractorLeft，// mpIniORBextractor属性中提取的特征点个数是mpORBextractorLeft的两倍ORBextractor* mpORBextractorLeft, *mpORBextractorRight;ORBextractor* mpIniORBextractor; mSeneor 传感器类型 2.10 Bow123//BoWORBVocabulary* mpORBVocabulary;KeyFrameDatabase* mpKeyFrameDB; mSeneor 传感器类型 2.11 単目初始器 mpInitializer123// Initalization (only for monocular)// 单目初始器Initializer* mpInitializer; mSeneor 传感器类型 2.12 局部地图1234//Local Map KeyFrame* mpReferenceKF;// 当前关键帧就是参考帧 std::vector&lt;KeyFrame*&gt; mvpLocalKeyFrames; std::vector&lt;MapPoint*&gt; mvpLocalMapPoints; mSeneor 传感器类型 2.13 SLAM 系统指针1System* mpSystem; mSeneor 传感器类型 2.14 显示相关1234//Drawers Viewer* mpViewer; FrameDrawer* mpFrameDrawer; MapDrawer* mpMapDrawer; mSeneor 传感器类型 2.15 系统地图 mpMap12//Map Map* mpMap; mSeneor 传感器类型 2.16 相机参数1234//Calibration matrix cv::Mat mK; cv::Mat mDistCoef; float mbf; mSeneor 传感器类型 2.17 新关键帧插入规则123//New KeyFrame rules (according to fps)int mMinFrames;int mMaxFrames; mSeneor 传感器类型 2.18 深度截断值1234// Threshold close/far points // Points seen as close by the stereo/RGBD sensor are considered reliable // and inserted from just one frame. Far points requiere a match in two keyframes. float mThDepth; mSeneor 传感器类型 2.19 深度图因子12// For RGB-D inputs only. For some datasets (e.g. TUM) the depthmap values are scaled.float mDepthMapFactor;; mSeneor 传感器类型 2.20 当前帧有多少特征点成功匹配12//Current matches in frame int mnMatchesInliers; mSeneor 传感器类型 2.21 上一关键帧、上一帧和重定位信息12345//Last Frame, KeyFrame and Relocalisation Info KeyFrame* mpLastKeyFrame; Frame mLastFrame; unsigned int mnLastKeyFrameId; unsigned int mnLastRelocFrameId; mSeneor 传感器类型 2.22 匀速模型匀速变换矩阵12//Motion Model cv::Mat mVelocity; mSeneor 传感器类型 2.23 相机RGB信息12//Color order (true RGB, false BGR, ignored if grayscale)bool mbRGB; mSeneor 传感器类型 2.24 临时地图点列表1list&lt;MapPoint*&gt; mlpTemporalPoints; mSeneor 传感器类型 共47个成员变量 3. Tracking 类成员函数3.1 构造函数 Tracking()12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 执行完构造函数后mState(NO_IMAGES_YET), mSensor(sensor), mbOnlyTracking(false), mbVO(false), mpORBVocabulary(pVoc),mpKeyFrameDB(pKFDB), mpInitializer(static_cast(NULL)), mpSystem(pSys), mpViewer(NULL),mpFrameDrawer(pFrameDrawer), mpMapDrawer(pMapDrawer), mpMap(pMap), mnLastRelocFrameId(0)等13个变量获得初始值。mK，mDistCoef，mbf，mMinFrames，mMaxFrames，mbRGB，mpORBextractorLeft，mpORBextractorRight，mpIniORBextractor，mThDepth， mDepthMapFactor等12个变量获得具体值。 3.2 抓取图片函数 GrabImageMonocular()1234// Preprocess the input and call Track(). Extract features and performs stereo matching. cv::Mat GrabImageStereo(const cv::Mat &amp;imRectLeft,const cv::Mat &amp;imRectRight, const double &amp;timestamp); cv::Mat GrabImageRGBD(const cv::Mat &amp;imRGB,const cv::Mat &amp;imD, const double &amp;timestamp); cv::Mat GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp); 3.3 设置三个线程指针函数，关联三个线程123void SetLocalMapper(LocalMapping* pLocalMapper);void SetLoopClosing(LoopClosing* pLoopClosing);void SetViewer(Viewer* pViewer); 3.4 矫正相机1234// Load new settings// The focal length should be similar or scale prediction will fail when projecting points// TODO: Modify MapPoint::PredictScale to take into account focal lenghtvoid ChangeCalibration(const string &amp;strSettingPath); 3.5 构造函数12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 3.6 InformOnlyTracking() 设置是否只跟踪12// Use this function if you have deactivated local mapping and you only want to localize the camera. void InformOnlyTracking(const bool &amp;flag); 3.7 Reset() 函数清除所有地图点1void Reset(); 3.8 Track()12// Main tracking function. It is independent of the input sensor.void Track(); 跟踪线程的主函数，独立于传感器类型 3.9 Track初始化函数12345// Map initialization for stereo and RGB-Dvoid StereoInitialization();// Map initialization for monocularvoid MonocularInitialization(); 3.10 构造函数12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 3.11 初始化単目地图1void CreateInitialMapMonocular(); 3.12 检查1void CheckReplacedInLastFrame(); 3.13 构造函数12Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap, KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor); 3.14 通过上一参考关键帧来跟踪图像位姿1bool TrackReferenceKeyFrame(); 3.15 更新上一帧1void UpdateLastFrame(); 3.16 通过上一帧来跟踪图像位姿，利用匀速模型1bool TrackWithMotionModel(); 3.17 跟踪丢失重定位1bool Relocalization(); 3.18 更新局部地图信息，更新局部地图，更新局部3D点，更新局部地图关键帧123void UpdateLocalMap();void UpdateLocalPoints();void UpdateLocalKeyFrames(); 3.19 跟踪局部地图1bool TrackLocalMap(); 3.20 寻找局部地图点1void SearchLocalPoints(); 3.21 判定是否需要插入关键帧1bool NeedNewKeyFrame(); 3.22 创建新的关键帧1void CreateNewKeyFrame(); 4. 实例化mpTracker在System构造函数中new一个Tracing对象指针mpTracker，方式如下所示：1234//Initialize the Tracking thread//(it will live in the main thread of execution, the one that called this constructor)mpTracker = new Tracking(this, mpVocabulary, mpFrameDrawer, mpMapDrawer, mpMap, mpKeyFrameDatabase, strSettingsFile, mSensor); 4.1 读取配置文件，构造相机内参 mK123456789101112131415cv::FileStorage fSettings(strSettingPath, cv::FileStorage::READ); float fx = fSettings["Camera.fx"]; float fy = fSettings["Camera.fy"]; float cx = fSettings["Camera.cx"]; float cy = fSettings["Camera.cy"]; // |fx 0 cx| // K = |0 fy cy| // |0 0 1 | cv::Mat K = cv::Mat::eye(3,3,CV_32F); K.at&lt;float&gt;(0,0) = fx; K.at&lt;float&gt;(1,1) = fy; K.at&lt;float&gt;(0,2) = cx; K.at&lt;float&gt;(1,2) = cy; K.copyTo(mK); 4.2 读取配置文件，构造相机矫正向量 mDistCoef1234567891011121314// 图像矫正系数// [k1 k2 p1 p2 k3]cv::Mat DistCoef(4,1,CV_32F);DistCoef.at&lt;float&gt;(0) = fSettings["Camera.k1"];DistCoef.at&lt;float&gt;(1) = fSettings["Camera.k2"];DistCoef.at&lt;float&gt;(2) = fSettings["Camera.p1"];DistCoef.at&lt;float&gt;(3) = fSettings["Camera.p2"];const float k3 = fSettings["Camera.k3"];if(k3!=0)&#123; DistCoef.resize(5); DistCoef.at&lt;float&gt;(4) = k3;&#125;DistCoef.copyTo(mDistCoef); 4.3 读取配置文件，构造相机RGB参数 mbRGB12345678// 1:RGB 0:BGR int nRGB = fSettings["Camera.RGB"]; mbRGB = nRGB; if(mbRGB) cout &lt;&lt; "- color order: RGB (ignored if grayscale)" &lt;&lt; endl; else cout &lt;&lt; "- color order: BGR (ignored if grayscale)" &lt;&lt; endl; 4.4 读取配置文件，加载ORB参数 nFeatures、fScaleFactor、nLevels、fIniThFAST、fMinThFAST1234567891011// Load ORB parameters// 每一帧提取的特征点数 1000int nFeatures = fSettings["ORBextractor.nFeatures"];// 图像建立金字塔时的变化尺度 1.2float fScaleFactor = fSettings["ORBextractor.scaleFactor"];// 尺度金字塔的层数 8int nLevels = fSettings["ORBextractor.nLevels"];// 提取fast特征点的默认阈值 20int fIniThFAST = fSettings["ORBextractor.iniThFAST"];// 如果默认阈值提取不出足够fast特征点，则使用最小阈值 8int fMinThFAST = fSettings["ORBextractor.minThFAST"]; 4.5 通过nFeatures、fScaleFactor、nLevels、fIniThFAST、fMinThFAST构造特征提取器12345678910// tracking过程都会用到mpORBextractorLeft作为特征点提取器mpORBextractorLeft = new ORBextractor(nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST);// 如果是双目，tracking过程中还会用用到mpORBextractorRight作为右目特征点提取器if(sensor==System::STEREO) mpORBextractorRight = new ORBextractor(nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST);// 在单目初始化的时候，会用mpIniORBextractor来作为特征点提取器if(sensor==System::MONOCULAR) mpIniORBextractor = new ORBextractor(2*nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST); 4.6 读取配置文件，构造相机深度截断阈值和视差因子 mThDepth,mDepthMapFactor12345678910111213141516if(sensor==System::STEREO || sensor==System::RGBD)&#123; // 判断一个3D点远/近的阈值 mbf * 35 / fx mThDepth = mbf*(float)fSettings["ThDepth"]/fx; cout &lt;&lt; endl &lt;&lt; "Depth Threshold (Close/Far Points): " &lt;&lt; mThDepth &lt;&lt; endl;&#125;if(sensor==System::RGBD)&#123; // 深度相机disparity转化为depth时的因子 mDepthMapFactor = fSettings["DepthMapFactor"]; if(fabs(mDepthMapFactor)&lt;1e-5) mDepthMapFactor=1; else mDepthMapFactor = 1.0f/mDepthMapFactor;&#125; st=>start: 调用构造函数实例化mpTracker e=>end: 得到mCurrentFrame.mTcw op1=>operation: 循环SLAM.TrackMonocular(im,tframe)，对每一帧图像进行tracking op2=>operation: 调用mpTracker->GrabImageMonocular(im,timestamp),抓取每一帧图像 op3=>operation: 将RGB图转换为灰度图mImGray op4=>operation: 利用灰度图构造当前帧mCurrentFrame op5=>operation: 调用track()函数 st->op1->op2->op3->op4->op5->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 调用构造函数实例化 mpTracker e=>end: 得到mpTracker op1=>operation: 读取配置文件，构造相机内参 mK,相机矫正向量 mDistCoef ,相机RGB参数 mbRGB op2=>operation: 读取配置文件，加载ORB参数 nFeatures、fScaleFactor、nLevels、fIniThFAST、fMinThFAST op3=>operation: 构造特征提取器 mpORBextractorLeft、mpIniORBextractor op4=>operation: 读取配置文件, 构造相机深度截断阈值和视差因子 mThDepth、mDepthMapFactor st->op1->op2->op3->op4->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB-SLAM2源码分析一]]></title>
    <url>%2F2019%2F05%2F28%2FORB-SLAM2%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80%2F</url>
    <content type="text"><![CDATA[主函数说明 mono_kitty.cc1. main 入口函数，读取3个文件参数，初始化系统 strVocFile: 字典词包的路径 strSettingFile: 系统中装有一些如相机参数、view窗口的配置文件，格式为YAML strSequence: 数据集路径 2. LoadImages 函数 LoadImages(const string &amp;strPathToSequence, vector &amp;vstrImageFilenames, vector &amp;vTimestamps) 12345678910111213141516171819202122232425262728293031 void LoadImages(const string &amp;strPathToSequence, vector&lt;string&gt; &amp;vstrImageFilenames, vector&lt;double&gt; &amp;vTimestamps)&#123; ifstream fTimes; string strPathTimeFile = strPathToSequence + "/times.txt"; fTimes.open(strPathTimeFile.c_str()); while(!fTimes.eof()) &#123; string s; getline(fTimes,s); if(!s.empty()) &#123; stringstream ss; ss &lt;&lt; s; double t; ss &gt;&gt; t; vTimestamps.push_back(t); &#125; &#125; string strPrefixLeft = strPathToSequence + "/image_0/"; const int nTimes = vTimestamps.size(); vstrImageFilenames.resize(nTimes); for(int i=0; i&lt;nTimes; i++) &#123; stringstream ss; ss &lt;&lt; setfill('0') &lt;&lt; setw(6) &lt;&lt; i; vstrImageFilenames[i] = strPrefixLeft + ss.str() + ".png"; &#125;&#125; 加载数据集函数，函数执行完vstrImageFileNames是一个存有图片具体位置的vector，位置形式如xxx/xxx/000xxx.png，vTimestamps是存有图片时间戳的vector 3. 实例化 SLAM 系统加载图片路径完成后，需要实例化一个SLAM系统对象ORB_SLAM2::System SLAM(argv[1],argv[2],ORB_SLAM2::System::MONOCULAR,true); System.h 包含了7个类，分别是Viewer， FrameDrawer, Map, Tracking, LocalMapping, LoopClosing 的声明，和System 类的定义， 就像描述的那样，这些类组成了一个系统。 1234567class Viewer;class FrameDrawer;class Map;class Tracking;class LocalMapping;class LoopClosing;class System; 成员变量说明3.1 sensor 枚举12345enum eSensor&#123; MONOCULAR=0, STEREO=1, RGBD=2&#125;; 0,1,2 分别代表传感器的类型 3.2 System 构造函数System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eSensor sensor, const bool bUseViewer = true); Monocular System 构造时，读入词包路径，YAML配置文件，设置eSensor类型为Monocular，并启用Viewer线程 3.3 Tracking 函数123456789101112131415// Proccess the given stereo frame. Images must be synchronized and rectified.// Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.// Returns the camera pose (empty if tracking fails).cv::Mat TrackStereo(const cv::Mat &amp;imLeft, const cv::Mat &amp;imRight, const double &amp;timestamp);// Process the given rgbd frame. Depthmap must be registered to the RGB frame.// Input image: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.// Input depthmap: Float (CV_32F).// Returns the camera pose (empty if tracking fails).cv::Mat TrackRGBD(const cv::Mat &amp;im, const cv::Mat &amp;depthmap, const double &amp;timestamp);// Proccess the given monocular frame// Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.// Returns the camera pose (empty if tracking fails).cv::Mat TrackMonocular(const cv::Mat &amp;im, const double &amp;timestamp); 针对不同传感器不同的Tracking。输入图像可以使rgb的也可以是grayscale的（最终读进去都会转化为grayscale的），函数返回值为camera的位姿pose。Tracking 过程是对针对每一幅图像，通过先初始化然后track和优化过程来估计相机误差。 3.4 定位模式函数1234// This stops local mapping thread (map building) and performs only camera tracking.void ActivateLocalizationMode();// This resumes local mapping thread and performs SLAM again.void DeactivateLocalizationMode(); 调用ActivateLocalizationMode()将终止mapping线程，开启定位模式，调用后者重启mapping线程。 3.5 重启与终止函数1234567// Reset the system (clear map)void Reset();// All threads will be requested to finish.// It waits until all threads have finished.// This function must be called before saving the trajectory.void Shutdown(); Reset()函数将清空map，Shutdown()函数可以终止所有线程，在保存相机轨迹之前需要调用此函数。 3.6 SaveTrajectory 函数123456789101112131415161718192021// Save camera trajectory in the TUM RGB-D dataset format.// Only for stereo and RGB-D. This method does not work for monocular.// Call first Shutdown()// See format details at: http://vision.in.tum.de/data/datasets/rgbd-datasetvoid SaveTrajectoryTUM(const string &amp;filename);// Save keyframe poses in the TUM RGB-D dataset format.// This method works for all sensor input.// Call first Shutdown()// See format details at: http://vision.in.tum.de/data/datasets/rgbd-datasetvoid SaveKeyFrameTrajectoryTUM(const string &amp;filename);// Save camera trajectory in the KITTI dataset format.// Only for stereo and RGB-D. This method does not work for monocular.// Call first Shutdown()// See format details at: http://www.cvlibs.net/datasets/kitti/eval_odometry.phpvoid SaveTrajectoryKITTI(const string &amp;filename);// TODO: Save/Load functions// SaveMap(const string &amp;filename);// LoadMap(const string &amp;filename); 把相机轨迹保存成相应数据集的格式，系统调用此函数时先shutdown SLAM系统，mono_kittti中save函数用的是SaveKeyFrameTrajectoryTUM，这个函数看起来像是只能用于TUM数据集，但三种传感器均适合。 4 System private 成员变量说明4.1 eSensor12// Input sensoreSensor mSensor; 输入的传感器类型 4.2 mpVocabulary12// ORB vocabulary used for place recognition and feature matching.ORBVocabulary* mpVocabulary; 用于位置识别和特征匹配的系统词包 4.3 mpKeyFrameDatabase12// KeyFrame database for place recognition (relocalization and loop detection).KeyFrameDatabase* mpKeyFrameDatabase; 用于位置识别，重定位，回环检测的关键帧数据集 4.4 mpMap12// Map structure that stores the pointers to all KeyFrames and MapPoints.Map* mpMap; 存储系统关键帧的指针和地图点的指针 4.5 mpTracker1234// Tracker. It receives a frame and computes the associated camera pose.// It also decides when to insert a new keyframe, create some new MapPoints and// performs relocalization if tracking fails.Tracking* mpTracker; Tracker 接受一帧图像并计算相机位姿，决定什么时候需要插入关键帧，创建地图点并且执行重定位如果跟踪失败。 4.6 mpLocalMapper12// Local Mapper. It manages the local map and performs local bundle adjustment.LocalMapping* mpLocalMapper; 局部地图管理器，mpLocalMapper，管理局部地图并进行局部BA。 4.7 mpLoopCloser123// Loop Closer. It searches loops with every new keyframe. If there is a loop it performs// a pose graph optimization and full bundle adjustment (in a new thread) afterwards.LoopClosing* mpLoopCloser; 回环检测器，每次获取关键帧后都会进行回环检测，如果存在回环的话就执行位姿图的优化并且进行全局BA优化 4.8 mpViewer,mpFrameDrawer,mpMapDrawer12345// The viewer draws the map and the current camera pose. It uses Pangolin.Viewer* mpViewer;FrameDrawer* mpFrameDrawer;MapDrawer* mpMapDrawer; 视图显示 4.9 系统线程12345// System threads: Local Mapping, Loop Closing, Viewer.// The Tracking thread "lives" in the main execution thread that creates the System object.std::thread* mptLocalMapping;std::thread* mptLoopClosing;std::thread* mptViewer; 4.10 Reset flag123// Reset flagstd::mutex mMutexReset;bool mbReset; 4.11 Change mode flags1234// Change mode flagsstd::mutex mMutexMode;bool mbActivateLocalizationMode;bool mbDeactivateLocalizationMode; 5. 实例化SLAM-System构造函数123System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eSensor sensor, const bool bUseViewer):mSensor(sensor),mbReset(false),mbActivateLocalizationMode(false), mbDeactivateLocalizationMode(false) System 构造函数用于实例化一个SALM系统，开启相机跟踪(Tracking)，局部建图(Local Mapping)，回环检测(Loop Closing)，和可视化界面(Viewer)的线程。 5.1 初始形参传递1234mSensor(sensor),mbReset(false),mbActivateLocalizationMode(false),mbDeactivateLocalizationMode(false) sensor是传进来的形参，是前面枚举体中三种传感器的一个，这里为MONOCULAR，它传递给了mSensor，这是一个System类的隐含成员变量，两种变量类型一样。mpViewer是System类的隐含成员变量，Viewer类指针，这里赋空。mbReset，mbActivateLocalizationMode，mbDeactivateLocalizationMode均为bool型，赋false。 5.2 初始化数据库 1 初始化词包 mpVocabulary 123456789101112131415161718//Load ORB Vocabulary cout &lt;&lt; endl &lt;&lt; "Loading ORB Vocabulary. This could take a while..." &lt;&lt; endl; mpVocabulary = new ORBVocabulary(); bool bVocLoad = false; // chose loading method based on file extension if (has_suffix(strVocFile, ".txt")) bVocLoad = mpVocabulary-&gt;loadFromTextFile(strVocFile); else if(has_suffix(strVocFile, ".bin")) bVocLoad = mpVocabulary-&gt;loadFromBinaryFile(strVocFile); else bVocLoad = false; if(!bVocLoad) &#123; cerr &lt;&lt; "Wrong path to vocabulary. " &lt;&lt; endl; cerr &lt;&lt; "Failed to open at: " &lt;&lt; strVocFile &lt;&lt; endl; exit(-1); &#125; cout &lt;&lt; "Vocabulary loaded!" &lt;&lt; endl &lt;&lt; endl; 2 用词包数据库来初始化关键帧数据库（用于重定位和回环检测）mpKeyFrameDatabase 12//Create KeyFrame Database mpKeyFrameDatabase = new KeyFrameDatabase(*mpVocabulary); 3 初始化一个Map类对象 ，该类用于存储指向所有关键帧和地图点的指针 mpMap 12//Create the Map mpMap = new Map(); 4 初始化画图工具，用于可视化 mpFrameDrawer、mpMapDrawer 123//Create Drawers. These are used by the Viewer mpFrameDrawer = new FrameDrawer(mpMap); mpMapDrawer = new MapDrawer(mpMap, strSettingsFile); 5 初始化Tracking线程，主线程，使用this指针（只初始化不启动，启动在main函数里TrackMonocular()启动） 1234//Initialize the Tracking thread//(it will live in the main thread of execution, the one that called this constructor) mpTracker = new Tracking(this, mpVocabulary, mpFrameDrawer, mpMapDrawer, mpMap, mpKeyFrameDatabase, strSettingsFile, mSensor); 6 初始化Local Mapping线程并启动（这里mSensor传入MONOCULAR）mpLocalMapper 123//Initialize the Local Mapping thread and launch mpLocalMapper = new LocalMapping(mpMap, mSensor==MONOCULAR); mptLocalMapping = new thread(&amp;ORB_SLAM2::LocalMapping::Run,mpLocalMapper); 7 初始化Loop Closing线程并启动（这里mSensor传入的不是MONOCULAR）mptLoopClosing 123//Initialize the Loop Closing thread and launchmpLoopCloser = new LoopClosing(mpMap, mpKeyFrameDatabase, mpVocabulary, mSensor!=MONOCULAR);mptLoopClosing = new thread(&amp;ORB_SLAM2::LoopClosing::Run, mpLoopCloser); 8 初始化Viewer线程并启动，也使用了this指针；给Tracking线程设置Viewer 123456//Initialize the Viewer thread and launch mpViewer = new Viewer(this, mpFrameDrawer,mpMapDrawer,mpTracker,strSettingsFile); if(bUseViewer) mptViewer = new thread(&amp;Viewer::Run, mpViewer); mpTracker-&gt;SetViewer(mpViewer); 9 mpTracker，mpLocalMapper，mptLoopClosing三个线程每两个线程之间设置指针相互关联 123456789//Set pointers between threads mpTracker-&gt;SetLocalMapper(mpLocalMapper); mpTracker-&gt;SetLoopClosing(mpLoopCloser); mpLocalMapper-&gt;SetTracker(mpTracker); mpLocalMapper-&gt;SetLoopCloser(mpLoopCloser); mpLoopCloser-&gt;SetTracker(mpTracker); mpLoopCloser-&gt;SetLocalMapper(mpLocalMapper); 6. 循环Tracking12345678910111213141516171819202122232425262728293031323334353637383940414243444546 // Main loop cv::Mat im; for(int ni=0; ni&lt;nImages; ni++) &#123; // Read image from file im = cv::imread(vstrImageFilenames[ni],CV_LOAD_IMAGE_UNCHANGED); double tframe = vTimestamps[ni]; if(im.empty()) &#123; cerr &lt;&lt; endl &lt;&lt; "Failed to load image at: " &lt;&lt; vstrImageFilenames[ni] &lt;&lt; endl; return 1; &#125;#ifdef COMPILEDWITHC11 std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::now();#else std::chrono::monotonic_clock::time_point t1 = std::chrono::monotonic_clock::now();#endif // Pass the image to the SLAM system SLAM.TrackMonocular(im,tframe);#ifdef COMPILEDWITHC11 std::chrono::steady_clock::time_point t2 = std::chrono::steady_clock::now();#else std::chrono::monotonic_clock::time_point t2 = std::chrono::monotonic_clock::now();#endif double ttrack= std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt; &gt;(t2 - t1).count(); vTimesTrack[ni]=ttrack; // Wait to load the next frame double T=0; if(ni&lt;nImages-1) T = vTimestamps[ni+1]-tframe; else if(ni&gt;0) T = tframe-vTimestamps[ni-1]; if(ttrack&lt;T) this_thread::sleep_for(std::chrono::microseconds((int)((T-ttrack)*1e6))); &#125; // Stop all threads SLAM.Shutdown(); 上述分为两步：读图、Tracking，其中有一部分代码（注释 //Wait to load the next frame 后）目的是为了模拟真实时间状况，如果tracking过快，则下一帧可能还没来，所以要“睡” T-ttrack 秒等待装载下一帧图片。每次tracking只处理一帧图片。]]></content>
      <categories>
        <category>ORB-SLAM2</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>Tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git简单攻略]]></title>
    <url>%2F2019%2F05%2F24%2Fgit%E7%AE%80%E5%8D%95%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[git全局用户申明12git config --global user.name "Your Name"git config --global user.email "email@example.com" 创建管理库1git init 添加文件1git add reamde.md 提交文件到仓库1git commit -m "message" 为什么git提交文件需要add和commit两步呢，因为commit可以一次提交很多次add不同的文件，比如123git add file1.txtgit add file2.txt file3.txtgit commit -m "add 3files" 查看仓库状态1git status 查看文件修改内容1git diff readme.txt 查看提交历史1git log 以便确定回退到哪个版本。 查看命令历史1git reflog 以便确定回到未来的哪个版本。 版本指针HEAD指向的版本就是当前的版本，HEAD^指向前一个版本，HEAD^^指向前前版本，HEAD~100指向第前100个版本。因此，git允许我们在历史之间穿梭。 版本穿梭1git reset --hard commit_id 丢弃工作区的修改1git checkout -- file 命令git checkout -- readme.txt意思就是，把readme.txt文件在工作区的修改全部撤销，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次git commit或git add时的状态。 从暂存区回到工作区1git reset HEAD readme.txt 如果你把文件git add到暂存区，但是还没有git commit到仓库，可以使用git reset HEAD file 将暂存区的修改撤销掉，重新放回到工作区。git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。 小结场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout — file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。 删除文件12git rm test.txtgit commit -m "remove test.txt" 一般情况下，你通常直接在文件管理器中把没用的文件删了，或者用rm命令删了：rm test.txt。这个时候，Git知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了。 现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit，现在，文件就从版本库中被删除了。 另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本：1git checkout -- test.txt 小提示：先手动删除文件，然后使用git rm 和git add效果是一样的。注意：从来没有被添加到版本库就被删除的文件，是无法恢复的！ 添加远程仓库1git remote add origin git@github.com:hahaha/hahaha.git 把本地库的所有内容推送到远程库上1git push -u origin master 把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 提交仓库到到远程1git push origin master 从远程库克隆1git clone git@github.com:hahaha/gitskills.git 现在，假设我们从零开发，那么最好的方式是先创建远程库，然后，从远程库克隆。首先，登陆GitHub，创建一个新的仓库，名字叫gitskills：我们勾选Initialize this repository with a README，这样GitHub会自动为我们创建一个README.md文件。创建完毕后，可以看到README.md文件：现在，远程库已经准备好了，下一步是用命令git clone克隆一个本地库： 注意把Git库的地址换成你自己的，然后进入gitskills目录看看，已经有README.md文件了： 转载申明本文转载自廖雪峰的博客：[https://www.liaoxuefeng.com]]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EKF详解]]></title>
    <url>%2F2019%2F05%2F23%2FEKF%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. 高斯函数\begin{equation}p(x) = \det(2\pi\Sigma)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \}}\label{eq:Gaussion}\end{equation} 所有的高斯技术都共享了基本思想，即置信度用多元正态分布来表示。$x$的密度用两个参数来表示，均值$\mu$和协方差$\Sigma$，均值$\mu$是一个向量，它与状态$x$的维数相同。协方差是对称半正定的二次型。其维数等于状态$x$的维数的二次方。高斯滤波中的参数均值和方差称为矩参数，这是因为均值和方差是概率分布的一阶矩和二阶矩；正态分布的其他矩都是零。 2. 线性高斯系统KF是由Swerling（1950）和Kalman（1960）作为线性高斯系统中的预测和滤波技术而发明的，是用矩来定义的。KF用矩参数来表示置信度：在时刻$t$，置信度用均值$\mu_t$和方差$\Sigma_t$表示、如果除了贝叶斯滤波的马尔科夫假设以外，还具有如下的三个特性，则后验就是高斯的。 状态转移概率$p(x_t | u_t, x_{t-1})$必须是带有随机高斯噪声的参数的线性函数，可有下式表示:\begin{equation}x_t = A_tx_{t-1} + B_tu_t + \varepsilon_t\label{eq:motion}\end{equation}式中，$x_t$和$x_{t-1}$都是状态向量，它们都是$n$维列向量；$u_t$为时刻$t$的控制向量。式(2)中，$A_t$为$n \times n$的矩阵，$B_t$为$n \times m$的矩阵，$n$为状态向量$x_t$的维数，$m$为控制向量$u_t$的维数。式(2)中的随机变量\varepsilon_t是一个高斯随机向量，表示由状态转移引入的不确定性。其维数与状态向量维数相同，均值为0，方差用$R_t$表示。式(2)中的状态转移概率称为线性高斯，反映了它与带有附加高斯噪声的自变量呈线性关系。式(2)定义了状态转移概率$p(x_t | u_t, x_{t-1})$。这个概率可由公式(2)带入到多元正态分布的定义式(1)来得到。后验状态的均值由$A_tx_{t-1} + B_tu_t$给定，方差由$R_t$给定：\begin{equation}p(x_t | u_t, x_{t-1}) = \det(2\pi R_t)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(x_t-A_tx_{t-1} - B_tu_t)^TR_t^{-1}(x_t-A_tx_{t-1} - B_tu_t) \}}\label{eq:status}\end{equation} 观测概率$p(z_t | x_t)$也与带有高斯噪声的自变量呈线性关系：\begin{equation}z_t = C_tx_t + \delta _t\label{eq:project}\end{equation}式中，$C_t$为$k \times n$的矩阵，$k$为观测向量$z_t$的维数；向量$\delta _t$为观测噪声。$\delta _t$服从均值为0、方差为$Q_t$的多变量高斯分布。因此观测概率由下面的多元正态分布给定：\begin{equation}p(z_t | x_t) = \det(2\pi Q_t)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(z_t - C_tx_t)^TQ_t^{-1}(z_t-C_tx_t) \}}\label{eq:measure}\end{equation} 最后，初始置信度必须${\rm bel}(x_0)$必须是正态分布的。这里用$\mu_0$表示初始置信度的均值，用$\Sigma_0$表示协方差：\begin{equation}{\rm bel}(x_0) = p (x_0)= \det(2\pi \Sigma_0)^{- \frac {1}{2} }\exp{ \{ -\frac{1}{2}(x_0 - \mu_0)^T\Sigma_0^{-1}(x_0-\mu_0) \}}\label{eq:initial}\end{equation} 这三个假设足以保证后验${\rm bel}(x_t)$在任何时刻$t$总符合高斯分布。 3. KF算法(Kalman fliter algorithm)KF算法如图所示，KF表示均值为$\mu_t$、方差为$\Sigma_t$的状态量在时刻$t$的置信度{\rm bel}(x_t)。KF的输入是$t-1$时刻的置信度，其均值和方差分别用$\mu_{t-1}$和$\Sigma_{t-1}$表示。为了更新这些参数，KF需要控制向量$u_t$和测量向量$z_t$。输出的是时刻$t$的置信度，均值为$\mu_t$，方差为$\Sigma_t$。 Algorithm Kalman_filter($\mu_{t-1}$,$\Sigma_{t-1}$,$u_t$,$z_t$): 3.3 线性高斯系统]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>EKF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
